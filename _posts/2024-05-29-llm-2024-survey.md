---
title: ğŸŒŸ ğ‹ğ‹ğŒ ğğ«ğ¨ğ¯ğ¢ğğğ«'ğ¬ ğ‘ğğ¥ğğšğ¬ğ (2024 1H) & ğŸ“ 2024 ğ‹ğ‹ğŒ ğ’ğ®ğ«ğ¯ğğ² (on Training / Data / RAG / Serving / Agent)
description: LLM, Survey
categories: [LLM, Survey]
tags: [LLM, Survey]
# author: foDev_jeong
date: 2024-05-29 24:00:00 +0800
pin: true
mermaid: true
# render_with_liquid: false
image:
  path: /assets/img/llm/LLM_Provider_2024.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: [LLM 2024 Procider]
---

## ğŸŒŸ LLM Provider's Release (2024 1H): A Comprehensive Overview

*Curiosity:* What patterns can we retrieve from the rapid pace of LLM releases in 2024? How do these innovations connect to the broader evolution of the field?

**2024's first half** witnessed an unprecedented surge in LLM releases, with 21 major models from leading providers. This comprehensive overview retrieves insights from release patterns, technical innovations, and market dynamics to understand where the field is heading.

### Release Timeline Overview

```mermaid
gantt
    title LLM Releases 2024 1H Timeline
    dateFormat YYYY-MM-DD
    section Major Releases
    GPT-4o (OpenAI)           :2024-05-13, 1d
    Llama-3 (Meta)            :2024-04-18, 1d
    Claude-3 (Anthropic)      :2024-03-04, 1d
    Gemini-1.5 (Google)       :2024-03-08, 1d
    section Open Source
    Qwen-2 (Alibaba)          :2024-06-07, 1d
    DeepSeek-V2              :2024-05-07, 1d
    Phi-3 (Microsoft)         :2024-04-22, 1d
    section Specialized
    Solar-Mini-ja (Upstage)   :2024-05-22, 1d
    Mistral-Large            :2024-02-26, 1d
```

### 21 LLM Releases: Complete Catalog

| # | Model | Provider | Release Date | Key Features | News | Paper |
|:--|:------|:---------|:-------------|:-------------|:-----|:------|
| 1 | **Qwen-2** | Alibaba Group | 2024.06.07 | Multilingual, large-scale | [Link](https://qwenlm.github.io/blog/qwen2/) | - |
| 2 | **Solar-Mini-ja** | Upstage | 2024.05.22 | Japanese-optimized | [Link](https://www.upstage.ai/feed/tech/solar-mini-chat-ja) | - |
| 3 | **Yi-Large** | 01.AI | 2024.05.13 | Large-scale model | [Link](https://x.com/01AI_Yi/status/1789929378467426794) | - |
| 4 | **Yi-1.5** | 01.AI | 2024.05.13 | Enhanced version | [Link](https://x.com/01AI_Yi/status/1789869537317540016) | [arXiv](https://arxiv.org/abs/2403.04652) |
| 5 | **GPT-4o** | OpenAI | 2024.05.13 | Omni-modal, faster | [Link](https://openai.com/index/hello-gpt-4o/) | - |
| 6 | **Qwen-Max** | Alibaba Group | 2024.05.11 | Maximum performance | [Link](https://qwenlm.github.io/blog/qwen-max-0428/) | - |
| 7 | **DeepSeek-V2** | DeepSeek | 2024.05.07 | Efficient architecture | [Link](https://x.com/deepseek_ai/status/1787478986731429933) | [arXiv](https://arxiv.org/abs/2405.04434) |
| 8 | **Snowflake-Arctic** | Snowflake | 2024.04.24 | Enterprise-focused | [Link](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/) | - |
| 9 | **Phi-3** | Microsoft | 2024.04.22 | Small language model | [Link](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/) | [arXiv](https://arxiv.org/abs/2404.14219) |
| 10 | **Llama-3** | Meta | 2024.04.18 | Open-source leader | [Link](https://ai.meta.com/blog/meta-llama-3/) | - |
| 11 | **Mixtral-8x22B** | Mistral AI | 2024.04.17 | Mixture of experts | [Link](https://mistral.ai/news/mixtral-8x22b/) | - |
| 12 | **Reka-Core** | Reka AI | 2024.04.15 | Multimodal | [Link](https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model) | [arXiv](https://arxiv.org/abs/2404.12387) |
| 13 | **Command-R-Plus** | Cohere | 2024.04.04 | Enterprise RAG | [Link](https://cohere.com/blog/command-r-plus-microsoft-azure) | - |
| 14 | **DBRX** | Databricks | 2024.03.27 | Open-source SOTA | [Link](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm) | - |
| 15 | **Gemini-1.5** | Google | 2024.03.08 | Long context | [Link](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/) | [arXiv](https://arxiv.org/abs/2403.05530) |
| 16 | **Claude-3** | Anthropic | 2024.03.04 | Safety-focused | [Link](https://www.anthropic.com/news/claude-3-family) | - |
| 17 | **Mistral-Large** | Mistral AI | 2024.02.26 | European leader | [Link](https://mistral.ai/news/mistral-large/) | - |
| 18 | **Gemma** | Google | 2024.02.21 | Open models | [Link](https://blog.google/technology/developers/gemma-open-models/) | [arXiv](https://arxiv.org/abs/2403.08295) |
| 19 | **Qwen-1.5** | Alibaba Group | 2024.02.04 | Multilingual | [Link](https://qwenlm.github.io/blog/qwen1.5/) | - |
| 20 | **Solar-Mini** | Upstage | 2024.01.25 | Efficient Korean | [Link](https://www.upstage.ai/feed/product/solarmini-performance-report) | - |
| 21 | **Solar-10.7B** | Upstage | 2023.12.23 | Top pre-trained | [Link](https://www.upstage.ai/feed/press/solar-10-7b-emerges-as-worlds-top-pre-trained-llm) | [arXiv](https://arxiv.org/abs/2312.15166) |

### Provider Distribution

```mermaid
pie title LLM Releases by Provider (2024 1H)
    "Alibaba Group" : 3
    "Upstage" : 3
    "Google" : 2
    "Mistral AI" : 2
    "01.AI" : 2
    "Others" : 9
```

### Key Trends & Insights

*Retrieve:* Analysis of release patterns reveals several key trends:

1. **Open Source Acceleration**: Major releases from Meta (Llama-3), Alibaba (Qwen series), and Databricks (DBRX)
2. **Multimodal Expansion**: GPT-4o, Gemini-1.5, Reka-Core emphasize vision capabilities
3. **Efficiency Focus**: Phi-3, Solar-Mini demonstrate small model excellence
4. **Regional Specialization**: Solar-Mini-ja (Japanese), Qwen series (Chinese)

*Innovate:* These releases show the field moving toward:
- More efficient architectures (DeepSeek-V2, Phi-3)
- Better multilingual support (Qwen, Solar)
- Enterprise-ready solutions (Snowflake Arctic, Command-R-Plus)

1. ğğ°ğğ§-2 (â€‹Alibaba Groupâ€‹, 2024.06.07)
- â€¢ ğŸ“£News: <https://qwenlm.github.io/blog/qwen2/>

2. ğ’ğ¨ğ¥ğšğ«-ğŒğ¢ğ§ğ¢-ğ£ğš (â€‹Upstageâ€‹, 2024.05.22)
- â€¢ ğŸ“£News: <https://www.upstage.ai/feed/tech/solar-mini-chat-ja>

3. ğ˜ğ¢-ğ‹ğšğ«ğ ğ (â€‹01.AIâ€‹, 2024.05.13)
- â€¢ ğŸ“£News: <https://x.com/01AI_Yi/status/1789929378467426794>

4. ğ˜ğ¢-1.5 (â€‹01.AIâ€‹, 2024.05.13)
- â€¢ ğŸ“£News: <https://x.com/01AI_Yi/status/1789869537317540016>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2403.04652>

5. ğ†ğğ“-4ğ¨ (â€‹OpenAIâ€‹, 2024.05.13)
- â€¢ ğŸ“£News: <https://openai.com/index/hello-gpt-4o/>

6. ğğ°ğğ§-ğŒğšğ± (â€‹Alibaba Groupâ€‹, 2024.05.11)
- â€¢ ğŸ“£News: <https://qwenlm.github.io/blog/qwen-max-0428/>

7. ğƒğğğ©ğ’ğğğ¤-ğ•2 (DeepSeek, 2024.05.07)
- â€¢ ğŸ“£News: <https://x.com/deepseek_ai/status/1787478986731429933>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2405.04434>

8. ğ’ğ§ğ¨ğ°ğŸğ¥ğšğ¤ğ-ğ€ğ«ğœğ­ğ¢ğœ (â€‹Snowflakeâ€‹, 2024.04.24)
- â€¢ ğŸ“£News: <https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/>

9. ğğ¡ğ¢-3 (â€‹Microsoftâ€‹, 2024.04.22)
- â€¢ ğŸ“£News: <https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2404.14219>

10. ğ‹ğ¥ğšğ¦ğš-3 (â€‹Meta Facebookâ€‹, 2024.04.18)
- â€¢ ğŸ“£News: <https://ai.meta.com/blog/meta-llama-3/>

11. ğŒğ¢ğ±ğ­ğ«ğšğ¥-8ğ±22ğ (â€‹Mistral AIâ€‹, 2024.04.17)
- â€¢ ğŸ“£News: <https://mistral.ai/news/mixtral-8x22b/>

12. ğ‘ğğ¤ğš-ğ‚ğ¨ğ«ğ (â€‹Reka AIâ€‹â€‹, 2024.04.15)
- â€¢ ğŸ“£News: <https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2404.12387>

13. ğ‚ğ¨ğ¦ğ¦ğšğ§ğ-ğ‘-ğğ¥ğ®ğ¬ (â€‹Cohereâ€‹, 2024.04.04)
- â€¢ ğŸ“£News: <https://cohere.com/blog/command-r-plus-microsoft-azure>

14. ğƒğğ‘ğ— (â€‹Databricksâ€‹, 2024.03.27)
- â€¢ ğŸ“£News: <https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm>

15. ğ†ğğ¦ğ¢ğ§ğ¢-1.5 (â€‹Googleâ€‹, 2024.03.08)
- â€¢ ğŸ“£News: <https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2403.05530>

16. ğ‚ğ¥ğšğ®ğğ-3 (â€‹Anthropicâ€‹, 2024.03.04)
- â€¢ ğŸ“£News: <https://www.anthropic.com/news/claude-3-family>

17. ğŒğ¢ğ¬ğ­ğ«ğšğ¥-ğ‹ğšğ«ğ ğ (â€‹Mistral AIâ€‹, 2024.02.26)
- â€¢ ğŸ“£News: <https://mistral.ai/news/mistral-large/>

18. ğ†ğğ¦ğ¦ğš (â€‹Googleâ€‹, 2024.02.21)
- â€¢ ğŸ“£News: <https://blog.google/technology/developers/gemma-open-models/>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2403.08295>

19. ğğ°ğğ§-1.5 (â€‹Alibaba Groupâ€‹, 2024.02.04)
- â€¢ ğŸ“£News: <https://qwenlm.github.io/blog/qwen1.5/>

20. ğ’ğ¨ğ¥ğšğ«-ğŒğ¢ğ§ğ¢ (â€‹Upstageâ€‹, 2024.01.25)
- â€¢ ğŸ“£News: <https://www.upstage.ai/feed/product/solarmini-performance-report>

21. ğ’ğ¨ğ¥ğšğ«-10.7ğ (â€‹Upstageâ€‹, 2023.12.23)
- â€¢ ğŸ“£News: <https://www.upstage.ai/feed/press/solar-10-7b-emerges-as-worlds-top-pre-trained-llm>
- â€¢ ğŸ“‹arXiv: <https://arxiv.org/abs/2312.15166>


* * *

## ğŸ“ 2024 LLM Survey: Comprehensive Research Overview

*Retrieve:* What are the latest research trends across training, data, RAG, serving, and agents? This section compiles essential survey papers that capture the state of the art.

> **Essential Reading**: These surveys provide comprehensive overviews of rapidly evolving LLM research areas.
{: .prompt-warning }

![ LLM 2024 survey ](/assets/img/llm/llm-2024-survey.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

### Survey Categories Overview

```mermaid
graph TB
    A[2024 LLM Surveys] --> B[Training]
    A --> C[Data]
    A --> D[RAG]
    A --> E[Serving]
    A --> F[Agent]
    
    B --> B1[Self-Evolution]
    B --> B2[Continual Learning]
    B --> B3[Pre-trained Models]
    
    C --> C1[Datasets]
    C --> C2[Data Selection]
    C --> C3[Instruction Tuning]
    
    D --> D1[RALM Survey]
    D --> D2[AIGC RAG]
    D --> D3[LLM RAG]
    
    E --> E1[Inference]
    E --> E2[Invocation Methods]
    E --> E3[Resource Efficiency]
    
    F --> F1[Multimodal Agents]
    F --> F2[Multi-Agents]
    F --> F3[Personal Agents]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
    style E fill:#e7d4f8
    style F fill:#ffe5e5
```

### ğŸ“š Training Surveys

*Retrieve:* How do LLMs evolve and adapt? These surveys explore self-evolution, continual learning, and transfer learning.

| Survey | Date | Focus | arXiv | GitHub |
|:-------|:-----|:------|:------|:-------|
| **Self-Evolution of LLMs** | 2024.04.22 | Autonomous improvement mechanisms | [Link](https://arxiv.org/abs/2404.14387) | [Repo](https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM) |
| **Continual Learning of LLMs** | 2024.04.25 | Lifelong learning approaches | [Link](https://arxiv.org/abs/2404.16789) | [Repo](https://github.com/Wang-ML-Lab/llm-continual-learning-survey) |
| **Continual Learning with PTMs** | 2024.01.29 | Pre-trained model adaptation | [Link](https://arxiv.org/abs/2401.16386) | [Repo](https://github.com/sun-hailong/LAMDA-PILOT) |

### ğŸ“Š Data Surveys

*Innovate:* Data quality and selection are critical for LLM performance. These surveys explore dataset curation and optimization.

| Survey | Date | Focus | arXiv | GitHub |
|:-------|:-----|:------|:------|:-------|
| **Datasets for LLMs** | 2024.02.28 | Comprehensive dataset catalog | [Link](https://arxiv.org/pdf/2402.18041) | [Repo](https://github.com/lmmlzn/Awesome-LLMs-Datasets) |
| **Data Selection for LMs** | 2024.02.26 | Selection strategies | [Link](https://arxiv.org/abs/2402.16827) | [Repo](https://github.com/alon-albalak/data-selection-survey) |
| **Data Selection for Instruction Tuning** | 2024.02.04 | Instruction data curation | [Link](https://arxiv.org/abs/2402.05123) | [Repo](https://github.com/Bolin97/awesome-instruction-selector) |

### ğŸ” RAG Surveys

*Retrieve:* Retrieval-Augmented Generation is transforming how LLMs access knowledge. These surveys cover the latest RAG research.

| Survey | Date | Focus | arXiv | GitHub |
|:-------|:-----|:------|:------|:-------|
| **RAG and RAU Survey** | 2024.04.30 | RALM in NLP | [Link](https://arxiv.org/abs/2404.19543) | [Repo](https://github.com/2471023025/RALM_Survey) |
| **RAG for AIGC** | 2024.02.29 | AI-generated content | [Link](https://arxiv.org/abs/2402.19473) | [Repo](https://github.com/hymie122/RAG-Survey) |
| **RAG for LLMs** | 2023.12.18 | Comprehensive RAG overview | [Link](https://arxiv.org/abs/2312.10997) | [Repo](https://github.com/Tongji-KGLLM/RAG-Survey) |

### âš¡ Serving Surveys

*Innovate:* Efficient inference and serving are crucial for production deployment. These surveys explore optimization strategies.

| Survey | Date | Focus | arXiv | GitHub |
|:-------|:-----|:------|:------|:-------|
| **LLM Inference Unveiled** | 2024.02.26 | Roofline model insights | [Link](https://arxiv.org/abs/2402.16363) | [Repo](https://github.com/hahnyuan/LLM-Viewer) |
| **Effective LLM Service Invocation** | 2024.02.05 | LLMaaS strategies | [Link](https://arxiv.org/abs/2402.03408) | [Repo](https://github.com/W-caner/Effective-strategy-for-LMaas) |
| **Resource-Efficient LLMs** | 2024.01.01 | Efficiency optimization | [Link](https://arxiv.org/abs/2401.00625) | [Repo](https://github.com/tiingweii-shii/Awesome-Resource-Efficient-LLM-Papers) |

### ğŸ¤– Agent Surveys

*Retrieve:* AI agents represent the next frontier. These surveys explore multimodal, multi-agent, and personal agent systems.

| Survey | Date | Focus | arXiv | GitHub |
|:-------|:-----|:------|:------|:-------|
| **Large Multimodal Agents** | 2024.02.23 | Vision-language agents | [Link](https://arxiv.org/abs/2402.15116) | [Repo](https://github.com/jun0wanan/awesome-large-multimodal-agents) |
| **LLM-based Multi-Agents** | 2024.01.21 | Multi-agent systems | [Link](https://arxiv.org/abs/2402.01680) | [Repo](https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers) |
| **Personal LLM Agents** | 2024.01.10 | Personalization & security | [Link](https://arxiv.org/abs/2401.05459) | [Repo](https://github.com/MobileLLM/Personal_LLM_Agents_Survey) |

### Research Trends Summary

```mermaid
graph LR
    A[2024 LLM Research] --> B[Training<br/>3 surveys]
    A --> C[Data<br/>3 surveys]
    A --> D[RAG<br/>3 surveys]
    A --> E[Serving<br/>3 surveys]
    A --> F[Agent<br/>3 surveys]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
    style E fill:#e7d4f8
    style F fill:#ffe5e5
```

### Key Takeaways

*Retrieve:* These 15 comprehensive surveys cover the essential areas of LLM research: training methodologies, data strategies, RAG systems, serving optimization, and agent architectures.

*Innovate:* By studying these surveys, you can retrieve the latest research insights and innovate on your own LLM applications, staying at the forefront of this rapidly evolving field.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about LLM capabilities, retrieve knowledge from these surveys, and innovate by applying cutting-edge techniques to your projects.



> Information about Tokens in LLsM
{: .prompt-Tip}


### Why do we keep talking about "tokens" in LLMs instead of words? 

It happens to be much more efficient to break the words into sub-words (tokens) for model performance!

The typical strategy used in most modern LLMs since GPT-1 is the Byte Pair Encoding (BPE) strategy. The idea is to use, as tokens, sub-word units that appear often in the training data. The algorithm works as follows:

- We start with a character-level tokenization
- we count the pair frequencies
- We merge the most frequent pair
- We repeat the process until the dictionary is as big as we want it to be

The size of the dictionary becomes a hyperparameter that we can adjust based on our training data. For example, GPT-1 has a dictionary size of ~40K merges, GPT-2, GPT-3, and ChatGPT have a dictionary size of ~50K, and Llama 3 128K.

![ Tokens from Words in LLMS ](/assets/img/llm/Tokens-from-Words-in-LLMS.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }
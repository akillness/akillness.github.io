---
title: What are the next big trends in LLM research?
description: LLM Research, Trends
categories: [LLM, Research]
tags: [LLM, Research]
# author: foDev_jeong
date: 2024-05-26 03:23:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## Catch up on all the upcoming trends using my guide! 

💡 The LLM space is experiencing rapid progress, with new papers or releases almost every day.

If you aim to stay updated with the latest advancements, here's a guide on emerging patterns: <https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week10_research_trends.md>

They are: 

#### 🚀Multi-Modal LLMs
- 📕Combine text processing with multimodal components like audio, imagery and videos. Examples: OpenAI Sora, Gemini, LLaVA
---

#### 🚀Open-Source LLMs
- 📕Open-source models provide model weights, and optionally, checkpoints and training data, promoting fairness and transparency. Examples: LLM360, LLaMA, OLMo, Llama-3
---

#### 🚀Domain Specific LLMs
- 📕Domain-specific LLMs are tailored to excel in particular fields for example- code generation or biology, optimizing their performance accordingly. Examples: BioGPT, StarCoder, MathVista
---

#### 🚀LLM Agents
- 📕LLM agents are applications that LLMs combined with modules like planning and memory, to execute complex tasks. Examples: ChemCrow, ToolLLM, OS-Copilot
---

#### 🚀Smaller LLMs (Including Quantized LLMs)
- 📕LLMs with reduced precision or lesser parameters ideal for deployment on devices with limited resources. Examples: BitNet, Gemma 1B, Lit-LLaMA
---

#### 🚀Non-Transformer LLMs
- 📕LLMs that deviate from the standard transformer architecture (for example: incorporating RNNs) and offer solutions to transformer pain-points. Examples: Mamba, RMKV
---


![ LLM Research Trends ](/assets/img/llm/LLM_research_trends.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## 내 가이드를 사용하여 다가오는 모든 트렌드를 따라잡으세요! 

💡 LLM 분야는 거의 매일 새로운 논문이나 발표를 통해 급속한 발전을 이루고 있습니다.

최신 발전 사항을 최신 상태로 유지하려는 경우 새로운 패턴에 대한 가이드가 있습니다. <https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week10_research_trends.md>

그들은: 

#### 🚀멀티모달 LLM
- 📕텍스트 처리를 오디오, 이미지 및 비디오와 같은 다중 모드 구성 요소와 결합합니다. 예: OpenAI Sora, Gemini, LLaVA
---

#### 🚀오픈 소스 LLM
- 📕오픈 소스 모델은 모델 가중치와 선택적으로 체크포인트 및 학습 데이터를 제공하여 공정성과 투명성을 촉진합니다. 예: LLM360, LLaMA, OLMo, Llama-3
---

#### 🚀도메인별 LLM
- 📕도메인별 LLM은 코드 생성 또는 생물학과 같은 특정 분야에서 탁월한 성능을 발휘하도록 맞춤화되어 그에 따라 성능을 최적화합니다. 예: BioGPT, StarCoder, MathVista
---

#### 🚀LLM 에이전트
- 📕LLM 에이전트는 복잡한 작업을 실행하기 위해 LLM이 계획 및 메모리와 같은 모듈과 결합한 애플리케이션입니다. 예: ChemCrow, ToolLLM, OS-Copilot
---

#### 🚀더 작은 LLM(양자화된 LLM 포함)
- 📕정밀도가 낮거나 매개변수가 적은 LLM은 리소스가 제한된 장치에 배포하는 데 적합합니다. 예: BitNet, Gemma 1B, Lit-LLaMA
---

#### 🚀비변압기 LLM
 -📕표준 트랜스포머 아키텍처(예: RNN 통합)에서 벗어나 트랜스포머 문제점에 대한 솔루션을 제공하는 LLM입니다. 예: 맘바, RMKV
---

</details>
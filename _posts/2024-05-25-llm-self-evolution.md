---
title: Self-Evolution in LLMs
description: AGI, Self-Evolution, LLM
categories: [Script, AGI]
tags: [AGI, Self-Evolution]
# author: foDev_jeong
date: 2024-05-25 03:23:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## Self-Evolution in LLMs

ğŸ˜ Self-Evolution in LLMs could be a key piece in unlocking AGI and ASI (Artificial General and Super Intelligence). Here's everything you need to know!

ğŸ’¡ Self-Evolution refers to a paradigm where AI models autonomously acquire, refine, and learn from their own experiences. It's very similar to how humans learn from trial and error, but in this case, the model generates and learns from its own data without constant human supervision.

### ğŸ¤” Why is it better than traditional methods?
- â›³Traditional LLM training methods, such as pre-training on large datasets and fine-tuning for specific tasks, require significant human supervision and can face limitations in scalability and adaptability as tasks become more complex. 

- â›³ Self-evolution offers a more autonomous approach, potentially leading to more efficient learning, scalability, and the ability to tackle sophisticated tasks without the need for intensive human intervention.

- â›³ By learning from its own experiences, an LLM could optimize its learning process, potentially reducing the need for extensive human annotation and supervision, leading to more efficient training and deployment.

- â›³ Self-evolving LLMs may develop a deeper understanding of language and context, leading to more robust performance across a wide range of tasks and domains.

### ğŸ¤” What are some self-evolution method examples?
- â›³ Self-Instruct: The model creates its own tasks, learns from the results, and adjusts responses based on feedback, enhancing its autonomy.
- â›³ Self-Play: The model competes against itself or simulates interactions with an environment to learn and refine strategies autonomously.
- â›³ Self-Improving: Continuous self-assessment allows the model to identify weaknesses and optimize parameters, enhancing its performance over time.
- â›³ Self-Training: The model generates training data from unlabeled sources, leveraging it to improve task-specific performance autonomously.

Read "A Survey on Self-Evolution of Large Language Models" for a complete overview of self-evolution and future directions.

![ Self Evolution ](/assets/img/news/Self-Evolution.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## LLMì˜ ìê¸° ì§„í™”

ğŸ˜ LLMì˜ ìê¸° ì§„í™”ëŠ” AGIì™€ ASI(Artificial General and Super Intelligence)ë¥¼ ì—¬ëŠ” ë° í•µì‹¬ì ì¸ ìš”ì†Œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸° ë‹¹ì‹ ì´ ì•Œì•„ì•¼ í•  ëª¨ë“  ê²ƒì´ ìˆìŠµë‹ˆë‹¤!

ğŸ’¡ ìê¸° ì§„í™”(Self-Evolution)ëŠ” AI ëª¨ë¸ì´ ìì‹ ì˜ ê²½í—˜ì„ ììœ¨ì ìœ¼ë¡œ ìŠµë“í•˜ê³ , ê°œì„ í•˜ê³ , í•™ìŠµí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì„ ë§í•©ë‹ˆë‹¤. ì¸ê°„ì´ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ í•™ìŠµí•˜ëŠ” ë°©ì‹ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ì§€ë§Œ, ì´ ê²½ìš° ëª¨ë¸ì€ ì§€ì†ì ì¸ ì¸ê°„ì˜ ê°ë… ì—†ì´ ìì²´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤.

### ğŸ¤” ì „í†µì ì¸ ë°©ë²•ë³´ë‹¤ ë‚˜ì€ ì´ìœ ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?
- â›³ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ì‚¬ì „ í›ˆë ¨ ë° íŠ¹ì • ì‘ì—…ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì •ê³¼ ê°™ì€ ê¸°ì¡´ LLM í›ˆë ¨ ë°©ë²•ì€ ìƒë‹¹í•œ ì‚¬ëŒì˜ ê°ë…ì´ í•„ìš”í•˜ë©° ì‘ì—…ì´ ë”ìš± ë³µì¡í•´ì§ì— ë”°ë¼ í™•ì¥ì„±ê³¼ ì ì‘ì„±ì˜ í•œê³„ì— ì§ë©´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- â›³ ìê¸° ì§„í™”ëŠ” ë³´ë‹¤ ììœ¨ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•˜ì—¬ ì ì¬ì ìœ¼ë¡œ ë³´ë‹¤ íš¨ìœ¨ì ì¸ í•™ìŠµ, í™•ì¥ì„± ë° ì§‘ì¤‘ì ì¸ ì¸ê°„ ê°œì… ì—†ì´ ì •êµí•œ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- â›³ LLMì€ ìì²´ ê²½í—˜ì„ í†µí•´ í•™ìŠµí•¨ìœ¼ë¡œì¨ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ ìµœì í™”í•˜ì—¬ ê´‘ë²”ìœ„í•œ ì¸ê°„ ì£¼ì„ ë° ê°ë…ì˜ í•„ìš”ì„±ì„ ì¤„ì—¬ ë³´ë‹¤ íš¨ìœ¨ì ì¸ êµìœ¡ ë° ë°°í¬ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- â›³ ìŠ¤ìŠ¤ë¡œ ì§„í™”í•˜ëŠ” LLMì€ ì–¸ì–´ì™€ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë” ê¹Šì€ ì´í•´ë¥¼ ê°œë°œí•˜ì—¬ ê´‘ë²”ìœ„í•œ ì‘ì—…ê³¼ ë„ë©”ì¸ì—ì„œ ë³´ë‹¤ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ¤” ìê¸° ì§„í™” ë°©ë²•ì˜ ì˜ˆëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?
- â›³ ìê¸° ì§€ì‹œ: ëª¨ë¸ì€ ìì²´ ì‘ì—…ì„ ìƒì„±í•˜ê³ , ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³ , í”¼ë“œë°±ì— ë”°ë¼ ì‘ë‹µì„ ì¡°ì •í•˜ì—¬ ììœ¨ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- â›³ ì…€í”„ í”Œë ˆì´: ëª¨ë¸ì€ ìì²´ì ìœ¼ë¡œ ê²½ìŸí•˜ê±°ë‚˜ í™˜ê²½ê³¼ì˜ ìƒí˜¸ ì‘ìš©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ììœ¨ì ìœ¼ë¡œ ì „ëµì„ í•™ìŠµí•˜ê³  êµ¬ì²´í™”í•©ë‹ˆë‹¤.
- â›³ ìì²´ ê°œì„ : ì§€ì†ì ì¸ ìì²´ í‰ê°€ë¥¼ í†µí•´ ëª¨ë¸ì€ ì•½ì ì„ ì‹ë³„í•˜ê³  ë§¤ê°œë³€ìˆ˜ë¥¼ ìµœì í™”í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- â›³ ìê°€ í•™ìŠµ: ì´ ëª¨ë¸ì€ ë ˆì´ë¸”ì´ ì§€ì •ë˜ì§€ ì•Šì€ ì›ë³¸ì—ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ì‘ì—…ë³„ ì„±ëŠ¥ì„ ììœ¨ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ë° í™œìš©í•©ë‹ˆë‹¤.

"A Survey on Self-Evolution of Large Language Models"ì—ì„œ ìê¸° ì§„í™”ì™€ ë¯¸ë˜ ë°©í–¥ì— ëŒ€í•œ ì „ì²´ ê°œìš”ë¥¼ ì½ì–´ë³´ì„¸ìš”.

</details>
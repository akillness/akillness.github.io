---
title: Want to build your first ğ—Ÿğ—Ÿğ—  ğ—½ğ—¿ğ—¼ğ—·ğ—²ğ—°ğ˜ but don't know where to start?
description: LLM, System
categories:
- LLM & Language Models
tags:
- system
- llmops
- llm
- language-model
date: 2024-07-30 11:00:00 +0800
---
![ Architecture of LLM System ](/assets/img/llm/architecture-of-llm-system.gif){: .light .shadow .rounded-10 w='1212' h='668' }

## If you want to ğ—¹ğ—²ğ—®ğ—¿ğ—» in a ğ˜€ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²ğ—± ğ˜„ğ—®ğ˜† to ğ—¯ğ˜‚ğ—¶ğ—¹ğ—± ğ—Ÿğ—Ÿğ—  ğ˜€ğ˜†ğ˜€ğ˜ğ—²ğ—ºğ˜€ using good ğ—Ÿğ—Ÿğ— ğ—¢ğ—½ğ˜€ principles... 
 
We want to announce that we just ğ—¿ğ—²ğ—¹ğ—²ğ—®ğ˜€ğ—²ğ—± ğŸ´ ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º ğ—¹ğ—²ğ˜€ğ˜€ğ—¼ğ—»ğ˜€ for the ğ—›ğ—®ğ—»ğ—±ğ˜€-ğ—¼ğ—» ğ—Ÿğ—Ÿğ— ğ˜€ ğ—°ğ—¼ğ˜‚ğ—¿ğ˜€ğ—² that will put you on the right track â†“ 
 
. 
 
Within the ğŸ´ ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º ğ—¹ğ—²ğ˜€ğ˜€ğ—¼ğ—»ğ˜€, you will ğ—´ğ—¼ ğ˜€ğ˜ğ—²ğ—½-ğ—¯ğ˜†-ğ˜€ğ˜ğ—²ğ—½ through the ğ˜ğ—µğ—²ğ—¼ğ—¿ğ˜†, ğ˜€ğ˜†ğ˜€ğ˜ğ—²ğ—º ğ—±ğ—²ğ˜€ğ—¶ğ—´ğ—», and ğ—°ğ—¼ğ—±ğ—² to learn how to build a: 
 
### â†’ ğ—¿ğ—²ğ—®ğ—¹-ğ˜ğ—¶ğ—ºğ—² ğ˜€ğ˜ğ—¿ğ—²ğ—®ğ—ºğ—¶ğ—»ğ—´ ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—² (deployed on AWS) that uses Bytewax as the stream engine to listen to financial news, cleans & embeds the documents, and loads them to a vector DB 
 
### â†’ ğ—³ğ—¶ğ—»ğ—²-ğ˜ğ˜‚ğ—»ğ—¶ğ—»ğ—´ ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—² (deployed as a serverless continuous training) that fine-tunes an LLM on financial data using QLoRA, monitors the experiments using an experiment tracker and saves the best model to a model registry 
 
### â†’ ğ—¶ğ—»ğ—³ğ—²ğ—¿ğ—²ğ—»ğ—°ğ—² ğ—½ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—² built in LangChain (deployed as a serverless RESTful API) that loads the fine-tuned LLM from the model registry and answers financial questions using RAG (leveraging the vector DB populated with financial news) 
 
We will also show you how to ğ—¶ğ—»ğ˜ğ—²ğ—´ğ—¿ğ—®ğ˜ğ—² various ğ˜€ğ—²ğ—¿ğ˜ƒğ—²ğ—¿ğ—¹ğ—²ğ˜€ğ˜€ ğ˜ğ—¼ğ—¼ğ—¹ğ˜€, such as: 
- Comet ML as your ML Platform; 
- Qdrant as your vector DB; 
- Beam as your infrastructure. 
 
 
## ğ—ªğ—µğ—¼ ğ—¶ğ˜€ ğ˜ğ—µğ—¶ğ˜€ ğ—³ğ—¼ğ—¿? 
 
The series targets MLE, DE, DS, or SWE who want to learn to engineer LLM systems using LLMOps good principles. 
 
## ğ—›ğ—¼ğ˜„ ğ˜„ğ—¶ğ—¹ğ—¹ ğ˜†ğ—¼ğ˜‚ ğ—¹ğ—²ğ—®ğ—¿ğ—»? 
 
The series contains 4 hands-on video lessons and the open-source code you can access on GitHub. 
 
## ğ—–ğ˜‚ğ—¿ğ—¶ğ—¼ğ˜‚ğ˜€? 
 
Check out the 8 Medium lessons of the Hands-on LLMs course and start building your own LLMs system: 

> The Hands-on LLMs Course ğŸ‘‰ <https://medium.com/decodingml/hands-on-llms/home>
{: .prompt-info}


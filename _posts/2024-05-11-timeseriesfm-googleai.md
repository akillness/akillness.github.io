---
title: The weights of our Time Series Foundation Model (TimesFM) on Hugging Face
description: FoundationModel, Huggingface
categories: [News, FoundationModel]
tags: [Study, Transformer, Huggingface]
author: Google AI
date: 2024-05-10 15:41:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


# What's New? ( from [Google AI](https://twitter.com/GoogleAI))

We’re excited to release the weights of our Time Series Foundation Model (TimesFM) on Hugging Face! 

To access, visit our HuggingFace <https://huggingface.co/google/timesfm-1.0-200m> & GitHub <https://github.com/google-research/timesfm> repositories.

Learn more ↓
#TimesFM #TimeSeries #Forecasting #FoundationModels


TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. Learn more → <https://goo.gle/480VRlm>


![Times Foundation Model](/assets/img/news/timesFM.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }
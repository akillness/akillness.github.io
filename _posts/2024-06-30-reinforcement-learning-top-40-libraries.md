---
title: Reinforcing Reinforcement Learning Terms, Policies, Models and Top 40 Libraries ğŸ“š
description: ReinforecementLearning, Library
categories: [Study, ReinforcementLearning]
tags: [Course, ReinforementLearning]
# author: foDev_jeong
date: 2024-06-30 20:10:00 +0800
# pin: true
# math: true
mermaid: true
# image:
#   path: /assets/img/cover/programming.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [2024 programming curriculum by honglab]
---

## Reinforcement Learning: Terms, Policies, Models, and Top 40 Libraries

*Curiosity:* What is reinforcement learning? How do agents learn to make better decisions through interaction with environments?

**Reinforcement Learning (RL)** is a type of machine learning where an agent interacts with an environment, receives feedback, and makes better decisions over time through trial and error.

### RL Overview

*Retrieve:* Understanding reinforcement learning fundamentals.

```mermaid
graph LR
    A[Agent] --> B[Action]
    B --> C[Environment]
    C --> D[State]
    C --> E[Reward]
    D --> A
    E --> A
    A --> F[Policy Update]
    F --> A
    
    style A fill:#e1f5ff
    style C fill:#fff3cd
    style E fill:#d4edda
```

### Key Terms in RL

*Retrieve:* Essential RL terminology.

| Term | Symbol | Description | Purpose |
|:-----|:-------|:------------|:--------|
| **Environment** | - | System the agent interacts with | â¬†ï¸ Learning context |
| **Agent** | - | Autonomous entity | â¬†ï¸ Decision maker |
| **Feedback** | - | Rewards or penalties | â¬†ï¸ Learning signal |
| **State** | S | Current situation | â¬†ï¸ Context |
| **Policy** | Ï€ | Strategy for actions | â¬†ï¸ Decision rule |
| **Value** | V | Expected long-term return | â¬†ï¸ State evaluation |
| **Q-Value** | Q | Long-term return of action | â¬†ï¸ Action evaluation |
| **Model** | - | Environment simulation | â¬†ï¸ Planning | 

â€”â€”â€”â€”â€”â€”â€”â€”â€”

### Model/Policy Classifications

*Retrieve:* Different approaches to RL.

**Model-Free vs Model-Based**:

| Type | Description | Use Case |
|:-----|:------------|:---------|
| **Model-Based** | Uses environment model | â¬†ï¸ When model available |
| **Model-Free** | Trial-and-error learning | â¬†ï¸ When model unknown |

**On-Policy vs Off-Policy**:

| Type | Description | Learning Source |
|:-----|:------------|:----------------|
| **On-Policy** | Learns from current policy | â¬†ï¸ Current actions |
| **Off-Policy** | Learns from different policy | â¬†ï¸ Other policy data |

â€”â€”â€”â€”â€”â€”â€”â€”â€”

### Well-Known RL Models

*Retrieve:* Popular RL algorithms and their characteristics.

| Model | Type | Description | Advantage |
|:------|:-----|:------------|:----------|
| **Q-Learning** | Model-free | Q-table for best actions | â¬†ï¸ Simple, effective |
| **SARSA** | Model-based | Updates based on next state-action | â¬†ï¸ On-policy learning |
| **DQN** | Model-free | Deep networks for Q-function | â¬†ï¸ Handles large states |
| **DDPG** | Model-free | Deep deterministic policy | â¬†ï¸ Continuous actions |

**DDPG Advantage**: Handles complex environments and large state spaces better than traditional RL algorithms. 

â€”â€”â€”â€”â€”â€”â€”â€”â€”

### RL Applications

*Innovate:* Diverse applications of reinforcement learning.

| Category | Applications | Impact |
|:---------|:-------------|:-------|
| **Robotics** | Robot control, manipulation | â¬†ï¸ Automation |
| **Transportation** | Autonomous vehicles, traffic control | â¬†ï¸ Safety, efficiency |
| **Healthcare** | Treatment optimization | â¬†ï¸ Patient outcomes |
| **Finance** | Trading, portfolio management | â¬†ï¸ Returns |
| **Gaming** | Game AI, strategy | â¬†ï¸ Entertainment |
| **Energy** | Smart grids, management | â¬†ï¸ Efficiency |
| **Business** | Marketing, recommendations | â¬†ï¸ Revenue |
| **Technology** | NLP, cybersecurity | â¬†ï¸ Capabilities |
| **Industry** | Manufacturing, automation | â¬†ï¸ Productivity |
| **Research** | Space exploration, agriculture | â¬†ï¸ Innovation |

â€”â€”â€”â€”â€”â€”â€”â€”â€”

### Top 40 Python RL Libraries

*Retrieve:* Comprehensive list of reinforcement learning libraries.

| Library | Framework | Focus | Use Case |
|:--------|:----------|:------|:---------|
| **Gym** | OpenAI | Environments | â¬†ï¸ Standard environments |
| **Stable-Baselines** | TensorFlow/PyTorch | Algorithms | â¬†ï¸ Easy implementation |
| **Ray RLlib** | Ray | Distributed RL | â¬†ï¸ Scalability |
| **TF-Agents** | TensorFlow | Agents | â¬†ï¸ TensorFlow integration |
| **Acme** | JAX | Research | â¬†ï¸ Advanced research |
| **Tianshou** | PyTorch | Algorithms | â¬†ï¸ PyTorch ecosystem |
| **CleanRL** | PyTorch | Clean code | â¬†ï¸ Learning |
| **PettingZoo** | Multi-agent | Multi-agent RL | â¬†ï¸ Multi-agent |
| **Dopamine** | TensorFlow | Research | â¬†ï¸ Google research |
| **MushroomRL** | Python | Algorithms | â¬†ï¸ Research |

**Complete List** (40 libraries):
Gym, Baselines, Dopamine, TensorLayer, FinRL, Stable-Baselines, ReAgent, Acme, PARL, TF-Agents, TensorFlow, PyTorchRL, Keras-RL, Garage, TensorForce, RLax, Coach, RFRL, Rliable, ViZDoom, Ray RLlib, ReAgent (Horizon), ChainerRL, MushroomRL, TRFL, CleanRL, Tianshou, MAgent, rl-baselines3-zoo, PettingZoo, RLlib, RoboRL, H-baselines, DI-engine, and more.

### Key Takeaways

*Retrieve:* Reinforcement learning enables agents to learn through environment interaction, with various algorithms (Q-Learning, DQN, DDPG) and applications across robotics, gaming, finance, and more.

*Innovate:* By leveraging Python RL libraries like Gym, Stable-Baselines, and Ray RLlib, you can build RL systems for diverse applications, from game AI to autonomous vehicles, using proven algorithms and frameworks.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about reinforcement learning, retrieve insights from RL terms, models, and libraries, and innovate by building RL applications that solve real-world problems.

**Next Steps**:
- Choose an RL library
- Start with simple environments
- Implement basic algorithms
- Build your RL application

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

â­† ğ‘ğğ ğ¢ğ¬ğ­ğğ« ğŸğ¨ğ« ğ…ğ«ğğ ğğ§ğ¥ğ¢ğ§ğ ğ‡ğšğ§ğğ¬-ğ¨ğ§ ğƒğšğ­ğš ğ’ğœğ¢ğğ§ğœğ ğ“ğ®ğ­ğ¨ğ«ğ¢ğšğ¥ (ğ„ğ§ğ ğ­ğ¨ ğ„ğ§ğ ğğ«ğ¨ğ£ğğœğ­): <https://www.maryammiradi.com/sonar>

![ Reinforcement Learning Python Libraries ](/assets/img/blog/ReinforcementLearning_Library.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

RLì€ ì—ì´ì „íŠ¸ê°€ í™˜ê²½ê³¼ ìƒí˜¸ ì‘ìš©í•˜ê³ , í”¼ë“œë°±ì„ ë°›ê³ , ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë” ë‚˜ì€ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ê³„ í•™ìŠµì˜ í•œ ìœ í˜•ì…ë‹ˆë‹¤.

â€”â€”â€”â€”â€”â€”â€”â€”â€”

## ğŸ“ RLì—ì„œ ì‚¬ìš©ë˜ëŠ” ìš©ì–´:

- âŒ˜ í™˜ê²½: ì—ì´ì „íŠ¸ê°€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ì‹œìŠ¤í…œ ë˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤. 

- âŒ˜ ì—ì´ì „íŠ¸(Agent): í™˜ê²½ê³¼ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ììœ¨ì ì¸ ê°œì²´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

- âŒ˜ í”¼ë“œë°±: ì—ì´ì „íŠ¸ê°€ ì¡°ì¹˜(ë³´ìƒ ë˜ëŠ” í˜ë„í‹°)ë¥¼ ì·¨í•œ í›„ í™˜ê²½ì—ì„œ ì—ì´ì „íŠ¸ì—ê²Œ ì œê³µí•˜ëŠ” ì •ë³´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

- âŒ˜ ìƒíƒœ(S): í™˜ê²½ì—ì„œ ë°˜í™˜ë˜ëŠ” í˜„ì¬ ìƒí™©ì…ë‹ˆë‹¤.

- âŒ˜ ì •ì±…(Ï€): ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.

- âŒ˜ ê°€ì¹˜ (V) : ì˜ˆìƒë˜ëŠ” ì¥ê¸° ìˆ˜ìµ 

- âŒ˜ Q-Value (Q): ì£¼ì–´ì§„ í˜„ì¬ í–‰ë™ì˜ ì¥ê¸° ìˆ˜ìµ 

- âŒ˜ ëª¨ë¸: í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. 

â€”â€”â€”â€”â€”â€”â€”â€”â€”

## ğŸ“– RLì˜ ëª¨ë¸/ì •ì±…:

ëª¨ë¸ í”„ë¦¬(Model-Free) vs ëª¨ë¸ ê¸°ë°˜(Model-Based):

- à¹ ìƒíƒœ ê³µê°„ê³¼ ì•¡ì…˜ ê³µê°„ì´ ì»¤ì§€ëŠ” ëª¨ë¸ ê¸°ë°˜ ì‘í’ˆ
- à¹ Model-free ì•Œê³ ë¦¬ì¦˜ì€ ì§€ì‹ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ì‹œí–‰ì°©ì˜¤ì— ì˜ì¡´í•©ë‹ˆë‹¤.

ì˜¨-í´ë¦¬ì‹œ(On-Policy) vs ì˜¤í”„-í´ë¦¬ì‹œ(Off-Policy):

- à¹ On-policy ì—ì´ì „íŠ¸ëŠ” í˜„ì¬ ì •ì±…ì—ì„œ íŒŒìƒëœ í˜„ì¬ ì‘ì—…ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. 
- à¹ Off-policy ì¹´ìš´í„° íŒŒíŠ¸ëŠ” ë‹¤ë¥¸ ì •ì±…ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

â€”â€”â€”â€”â€”â€”â€”â€”â€”

## ğŸ¤– ì˜ ì•Œë ¤ì§„ RL ëª¨ë¸:

- âŠ Q-ëŸ¬ë‹:

Q-í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ì—¬ ìƒíƒœì— ëŒ€í•œ ìµœìƒì˜ ì‘ì—…ì„ ì €ì¥í•˜ëŠ” ëª¨ë¸ ì—†ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

- â‹ êµ­ê°€-í–‰ë™-ë³´ìƒ-êµ­ê°€-í–‰ë™(SARSA):

ë³´ìƒ ë° ë‹¤ìŒ ìƒíƒœ-í–‰ë™ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒíƒœ-í–‰ë™ ê°’ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ëª¨ë¸ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

- âŒ ë”¥ Q ë„¤íŠ¸ì›Œí¬(DQN):

ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ Q-functionì„ ê·¼ì‚¬í™”í•˜ëŠ” ëª¨ë¸ ì—†ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

- â ì‹¬ì¸µ ê²°ì •ë¡ ì  ì •ì±… ê·¸ë˜ë””ì–¸íŠ¸(DDPG):

DDPGëŠ” ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ RL ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ë” ë³µì¡í•œ í™˜ê²½ê³¼ ëŒ€ê·œëª¨ ìƒíƒœ ê³µê°„ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. 

â€”â€”â€”â€”â€”â€”â€”â€”â€”

## ğŸ› ï¸ ë‹¤ìŒì€ ê°•í™” í•™ìŠµ(RL)ì˜ ëª‡ ê°€ì§€ ì‘ìš© ë¶„ì•¼ì…ë‹ˆë‹¤.

- Â» ë¡œë³´í‹±ìŠ¤
- Â» ììœ¨ ì£¼í–‰ ì°¨ëŸ‰
- Â» í—¬ìŠ¤ì¼€ì–´
- Â» ê¸ˆìœµ
- Â» ë…¸ë¦„
- Â» ì—ë„ˆì§€ ê´€ë¦¬
- Â» ë§ˆì¼€íŒ… ë° ê´‘ê³ 
- Â» ìì—°ì–´ ì²˜ë¦¬
- Â» ì œì¡°ì—…
- Â» ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ
- Â» ê³µê¸‰ë§ ìµœì í™”
- Â» ì¶”ì²œ ì‹œìŠ¤í…œ
- Â» ê°œì¸í™” ì‹œìŠ¤í…œ
- Â» êµí†µ ì‹ í˜¸ ì œì–´
- Â» êµìœ¡ ë° í›ˆë ¨
- Â» ë†ì—…
- Â» ì‚°ì—… ìë™í™”
- Â» ìš°ì£¼ íƒì‚¬
- Â» ì‚¬ì´ë²„ ë³´ì•ˆ
- Â» ê°€ìƒ ë¹„ì„œ

</details>
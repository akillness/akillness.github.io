---
title: GPT4o Release !!
description: GPT4o, Release, News
categories: [Script, GPT4o]
tags: [GPT4o, LLM]
# author: foDev_jeong
date: 2024-05-14 10:00:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---

## ğŸ¤¯ OpenAI's new multimodal LLM can understand and generate across text, audio, and vision in real-time.

### ğŸ’¬ğŸ—£ï¸ğŸ‘€ Here is what we know so far:

#### Details

- OpenAI announced a new GPT-4o model, which performs better than GPT-4, but most importantly, it's going to be free for all users! ğŸš€
â €
- Updated interface and PC application with voice control and screen-sharing capabilities have been introduced ğŸ¤
â €
- Natively multimodal: for now, text, images, and voice generation are done by ONE model ğŸ—£ï¸
â €
- Developers are not forgotten either, because there will be API support: 2x faster, 50% cheaper, and 5x higher rate limits API vs. GPT4 ğŸ’°
â €
- Voice mode has been greatly improved: now you can interrupt the model generation at any time, instead of waiting until the end. OpenAI also managed to bring speech generation to the real-time level, and most importantly, to make ChatGPT voice really alive! ğŸ¶
â €
- There is also an interactive mode, where you can simultaneously share the image from your camera and communicate with ChatGPT about it! ğŸ’¬


> Summary
- ğŸ“¥ Input: Text, Text + Image, Text + Audio, Text + Video, Audio (based on the examples)
- ğŸ“¤Output: Image, Image + Text, Text, Audio (based on the examples)
- ğŸŒ 88.7% on MMLU; 90.2% on HumanEval
- ğŸ§ < 5% WER for Western European languages in transcription
- ğŸ–¼ï¸ 69.1% on MMU; 92.8% on DocVQA
- âš¡ Up to 50% cheaper (probably due to tokenization improvements) and 2x faster than GPT-4 Turbo
- ğŸ¤ Near real-time audio with 320ms on average, similar to human conversation
- ğŸ”¡ New tokenizer with a 200k token vocabulary (previously 100k vocabulary) leading to 1.1x - 4.4x fewer tokens needed across 20 languages
{: .prompt-info }

Blog: <https://openai.com/index/hello-gpt-4o/>

The multimodal achievement and latency are impressive. ğŸ”¥ But I'm not worried about open-source AI. Open Source is stronger than ever and equally good for enterprises and companies use cases where you don't need a 200ms latency with voice input. âœ…


![ GPT4o Released ](/assets/img/llm/GPT4o.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

* * * 


## ğŸ¤¯ OpenAI ì˜ ìƒˆë¡œìš´ ë©€í‹°ëª¨ë‹¬ LLMì€ í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤, ë¹„ì „ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

### ğŸ’¬ğŸ—£ï¸ğŸ‘€ ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” ê²ƒì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.


#### ìì„¸íˆ 
- OpenAIëŠ” GPT-4ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚œ ìƒˆë¡œìš´ GPT-4o ëª¨ë¸ì„ ë°œí‘œí–ˆì§€ë§Œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ëª¨ë“  ì‚¬ìš©ìì—ê²Œ ë¬´ë£Œë¡œ ì œê³µëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤! ğŸš€
â €
- ìŒì„± ì œì–´ ë° í™”ë©´ ê³µìœ  ê¸°ëŠ¥ì´ ìˆëŠ” ì—…ë°ì´íŠ¸ëœ ì¸í„°í˜ì´ìŠ¤ ë° PC ì‘ìš© í”„ë¡œê·¸ë¨ì´ ë„ì…ğŸ¤ë˜ì—ˆìŠµë‹ˆë‹¤
â €
- ê¸°ë³¸ì ìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬: í˜„ì¬ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë° ìŒì„± ìƒì„±ì€ í•˜ë‚˜ì˜ ëª¨ë¸ğŸ—£ï¸ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
â €
- GPT4ğŸ’°ì— ë¹„í•´ 2ë°° ë” ë¹ ë¥´ê³ , 50% ë” ì €ë ´í•˜ê³ , 5ë°° ë” ë†’ì€ ì†ë„ ì œí•œ APIë¥¼ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— ê°œë°œìë„ ìŠì§€ ì•ŠìŠµë‹ˆë‹¤
â €
- ìŒì„± ëª¨ë“œê°€ í¬ê²Œ ê°œì„ ë˜ì–´ ì´ì œ ëª¨ë¸ ìƒì„±ì´ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì–¸ì œë“ ì§€ ëª¨ë¸ ìƒì„±ì„ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. OpenAIëŠ” ë˜í•œ ìŒì„± ìƒì„±ì„ ì‹¤ì‹œê°„ ìˆ˜ì¤€ìœ¼ë¡œ ëŒì–´ì˜¬ë ¸ìœ¼ë©° ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ChatGPT ìŒì„±ì„ ì‹¤ì œë¡œ ìƒìƒí•˜ê²Œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤! ğŸ¶
â €
- ì¹´ë©”ë¼ì˜ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ê³µìœ í•˜ê³  ChatGPTì™€ ì†Œí†µí•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ëª¨ë“œë„ ìˆìŠµë‹ˆë‹¤! ğŸ’¬
â €

> ìš”ì•½
- ğŸ“¥ ì…ë ¥: í…ìŠ¤íŠ¸, í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ + ì˜¤ë””ì˜¤, í…ìŠ¤íŠ¸ + ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤(ì˜ˆì œ ê¸°ë°˜)
- ğŸ“¤ì¶œë ¥: ì´ë¯¸ì§€, ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸, í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤(ì˜ˆì œ ê¸°ë°˜)
- ğŸŒ MMLUì—ì„œ 88.7%; HumanEvalì—ì„œ 90.2%
- ğŸ§< 5% WER for Western European languages in transcription
- ğŸ–¼ï¸ 69.1% on MMU; 92.8% on DocVQA
- âš¡ Up to 50% cheaper (probably due to tokenization improvements) and 2x faster than GPT-4 Turbo
- ğŸ¤ Near real-time audio with 320ms on average, similar to human conversation
- ğŸ”¡ New tokenizer with a 200k token vocabulary (previously 100k vocabulary) leading to 1.1x - 4.4x fewer tokens needed across 20 languages
{: .prompt-info }

Blog: <https://openai.com/index/hello-gpt-4o/>

The multimodal achievement and latency are impressive. ğŸ”¥ But I'm not worried about open-source AI. Open Source is stronger than ever and equally good for enterprises and companies use cases where you don't need a 200ms latency with voice input. âœ…
---
title: 🐳🐳MultiPly in-the-wild Multi-Pax from Mono🐳🐳
description: Paper, MultiPly, 3DRecon
categories: [Paper, MultiPly]
tags: [Monocular, 3DRecon, MultiPly]
# author: foDev_jeong
date: 2024-06-04 19:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

{% include embed/youtube.html id='r9giQPUp1Gw' %}

## 👉ETH (+Microsoft) announced MultiPly, a novel framework to reconstruct multiple people in 3D from monocular in-the-wild videos.

It's the new SOTA over the publicly available datasets and in-the-wild videos. Source Code announced, coming💙

𝐇𝐢𝐠𝐡𝐥𝐢𝐠𝐡𝐭𝐬:
- ✅Multiple detailed 3D humans from in-the-wild
- ✅Novel robust instance segmentation approach 
- ✅Clean separation between interacting people
- ✅Accurate confidence-guided optimization
- ✅Temporal/spatial coherent 3D reconstructions

👉Discussion <https://t.me/AI_DeepLearning>


> 🧙Paper Authors: Zeren Jiang∗1 Chen Guo∗1 Manuel Kaufmann1 Tianjian Jiang1 Julien Valentin2 Otmar Hilliges1 Jie Song1
 1ETH Zurich 2Microsoft
- 1️⃣Read the Full Paper here: <https://arxiv.org/pdf/2406.01595>
- 2️⃣Project Page: <https://eth-ait.github.io/MultiPly/>
- 3️⃣Code: Coming 🔜 (<https://github.com/eth-ait/MultiPly>)
{: .prompt-info }


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

## 👉ETH(+해시태그#Microsoft )는 단안 비디오에서 여러 사람을 3D로 재구성하는 새로운 프레임워크인 MultiPly를 발표했습니다. 

공개적으로 사용 가능한 데이터 세트와 야생 비디오에 대한 새로운 SOTA입니다. 소스 코드 발표 예정💙

하이라이트:
- ✅야생에서 온 여러 개의 상세한 3D 인간
- ✅새롭고 강력한 인스턴스 세분화 접근 방식 
- ✅상호 작용하는 사람들 간의 깨끗한 분리
- ✅정확한 신뢰도 기반 최적화
- ✅시간적/공간적 일관성 있는 3D 재구성

</details>
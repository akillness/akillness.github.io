---
title: All about transformer background knowledge including RNN
description: Transformer, RNN, Knowledge
categories:
- Tutorials & Learning
tags:
- tutorial
- transformer
- learning
date: 2024-06-28 00:10:00 +0800
---
# Step to explain Transformer 
> Dataset : <https://github.com/NoCodeProgram/deepLearning/tree/main/rnn>

## RNN Studying Repository
> Repository : <https://github.com/akillness/SPTTC/tree/main/practice/myRNN>
{: .prompt-info}

**Contents of table**
- RNN Intro
- RNN Implementation
- RNN Classification
- RNN Generation
- Word Embedding


## Transformer Studying Repository
> Repository : <https://github.com/akillness/SPTTC/tree/main/practice/myTransformer>
{: .prompt-info}

**Contents of table**
- Self-Attention
- Multi-Head Attention
- Layer Norm & Encoder
- Embedding Layer

> Test Tokenizer according to Model : <https://tiktokenizer.vercel.app/?model=gpt2>
{: .prompt-tip}

- Positional Encoding Layer
- Transformer Encoder

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Explaining about Transformer by talker programming without code </summary>

{% include embed/youtube.html id='34gBoeY62zE' %}

</details>
---
title: TRAG meets GNNs
description: Paper, GNN-RAG, LLM
categories: [Paper, GNN-RAG]
tags: [AI, LLM, GNN-RAG]
# author: foDev_jeong
date: 2024-06-03 15:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

## TRAG meets GNNs: Integrating graphs into a modern workflow.

Knowledge Graphs (KGs) are a powerful way to represent factual knowledge, but querying them with natural language is challenging. 

And Graph Neural Networks (GNNs) excel at reasoning over KGs, something Large Language Models (LLMs) are still struggling with.

There has been a lot of work in combining these two approaches lately, but it doesn't feel like we've found the right recipe yet. 

By leaning into the popular Retrieval-augmented Generation (RAG) trend, GNN-RAG tries to change this.

> The idea is for the GNN to handle the complex graph structure, while the LLM leverages its language understanding to produce the final answer. 


## ğŸ¤” Vanilla-RAG struggles with structured knowledge sources like knowledge graphs. GNN-RAG is a very neat idea to fix this!


### â›³ Vanilla-RAG struggles with structured inputs like KGs because it relies heavily on LLMs for retrieval, which are not adept at handling the complex graph information inherent in KGs. This leads to suboptimal performance, especially on multi-hop and multi-entity questions that require traversing multiple relationships in the graph.

### â›³ GNN-RAG integrates the strengths of both LLMs and and Graph Neural Networks (GNNs) to solve this issue:
- ğŸ’¡ GNN: Excels at processing and reasoning over graph structures. It reasons over a dense KG subgraph to retrieve answer candidates for a given question.
- ğŸ’¡LLM: Leverages its natural language processing abilities to further reason over the information provided by the GNN.

ğŸ‘‰ Here's the workflow:
- ğŸ”º A GNN processes the KG to identify and retrieve candidate answers.
- ğŸ”ºThe shortest paths connecting question entities to answer candidates in the KG are extracted to represent reasoning paths.
- ğŸ”ºThese paths are verbalized and provided as input to the LLM for final reasoning and answer generation.


#### GNN-RAG achieves state-of-the-art performance on two major KGQA benchmarks, even outperforming GPT-4 in some cases. 

> GNN-RAG achieves state-of-the-art results on two widely used KGQA benchmarks, WebQSP and ComplexWebQuestions (CWQ) and outperforms existing methods, including GPT-4, particularly on multi-hop and multi-entity questions.
{: .prompt-tip }

It particularly seems to shine on challenging multi-hop and multi-entity questions. 

> ğŸ§™Paper Authors: Costas Mavromatis, George Karypis
1Minnesota University 
- 1ï¸âƒ£Read the Full Paper here: <https://arxiv.org/abs/2405.20139>
- 2ï¸âƒ£Project Page: <https://medium.com/@techsachin/gnn-rag-combining-llms-language-abilities-with-gnns-reasoning-in-rag-style-d72200da376c>
- 3ï¸âƒ£Code: <https://github.com/cmavro/GNN-RAG>
{: .prompt-info }

![ GNN-RAG architecture ](/assets/img/paper/GNN-RAG.png){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

##  RAGì™€ GNNì˜ ë§Œë‚¨: ê·¸ë˜í”„ë¥¼ ìµœì‹  ì›Œí¬í”Œë¡œìš°ì— í†µí•©í•©ë‹ˆë‹¤.

ì§€ì‹ ê·¸ë˜í”„(KG)ëŠ” ì‚¬ì‹¤ì— ì…ê°í•œ ì§€ì‹ì„ í‘œí˜„í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì´ì§€ë§Œ ìì—°ì–´ë¡œ ì¿¼ë¦¬í•˜ëŠ” ê²ƒì€ ì–´ë µìŠµë‹ˆë‹¤. 

ê·¸ë¦¬ê³  ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” KGë³´ë‹¤ ì¶”ë¡ í•˜ëŠ” ë° íƒì›”í•©ë‹ˆë‹¤.

ìµœê·¼ ì´ ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ê²°í•©í•˜ëŠ” ë° ë§ì€ ì‘ì—…ì´ ìˆì—ˆì§€ë§Œ ì•„ì§ ì˜¬ë°”ë¥¸ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

GNN-RAGëŠ” ì¸ê¸° ìˆëŠ” RAG(Retrieval-augmented Generation) ì¶”ì„¸ì— ê¸°ëŒ€ì–´ ì´ë¥¼ ë°”ê¾¸ë ¤ê³  í•©ë‹ˆë‹¤.

> ì•„ì´ë””ì–´ëŠ” GNNì´ ë³µì¡í•œ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°˜ë©´, LLMì€ ì–¸ì–´ ì´í•´ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 

## ğŸ¤” Vanilla-RAGëŠ” ì§€ì‹ ê·¸ë˜í”„ì™€ ê°™ì€ êµ¬ì¡°í™”ëœ ì§€ì‹ ì†ŒìŠ¤ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. GNN-RAGëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë§¤ìš° ê¹”ë”í•œ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤!

### â›³ Vanilla-RAGëŠ” KGì— ë‚´ì¬ëœ ë³µì¡í•œ ê·¸ë˜í”„ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ëŠ¥ìˆ™í•˜ì§€ ì•Šì€ LLMì— í¬ê²Œ ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì— KGì™€ ê°™ì€ êµ¬ì¡°í™”ëœ ì…ë ¥ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì„±ëŠ¥ì´ ìµœì í™”ë˜ì§€ ì•Šìœ¼ë©°, íŠ¹íˆ ê·¸ë˜í”„ì—ì„œ ì—¬ëŸ¬ ê´€ê³„ë¥¼ ìˆœíšŒí•´ì•¼ í•˜ëŠ” ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.

### â›³ GNN-RAGëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ LLMê³¼ ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì˜ ê°•ì ì„ í†µí•©í•©ë‹ˆë‹¤.
- ğŸ’¡ GNN: ê·¸ë˜í”„ êµ¬ì¡°ì— ëŒ€í•œ ì²˜ë¦¬ ë° ì¶”ë¡ ì— íƒì›”í•©ë‹ˆë‹¤. ì¡°ë°€í•œ KG í•˜ìœ„ ê·¸ë˜í”„ë¥¼ í†µí•´ ì¶”ë¡ í•˜ì—¬ ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í›„ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ğŸ’¡LLM: ìì—°ì–´ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ GNNì—ì„œ ì œê³µí•˜ëŠ” ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.

ğŸ‘‰ ì›Œí¬í”Œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
- ğŸ”º GNNì€ KGë¥¼ ì²˜ë¦¬í•˜ì—¬ í›„ë³´ ë‹µë³€ì„ ì‹ë³„í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ğŸ”ºKGì˜ í›„ë³´ìì—ê²Œ ë‹µë³€í•˜ê¸° ìœ„í•´ ì§ˆë¬¸ ì—”í„°í‹°ë¥¼ ì—°ê²°í•˜ëŠ” ìµœë‹¨ ê²½ë¡œê°€ ì¶”ì¶œë˜ì–´ ì¶”ë¡  ê²½ë¡œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- ğŸ”ºì´ëŸ¬í•œ ê²½ë¡œëŠ” ì–¸ì–´í™”ë˜ì–´ ìµœì¢… ì¶”ë¡  ë° ë‹µë³€ ìƒì„±ì„ ìœ„í•´ LLMì— ì…ë ¥ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.

### GNN-RAGëŠ” ë‘ ê°€ì§€ ì£¼ìš” KGQA ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ê²½ìš°ì— ë”°ë¼ GPT-4ë¥¼ ëŠ¥ê°€í•˜ê¸°ë„ í•©ë‹ˆë‹¤. 

> GNN-RAGëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë‘ ê°€ì§€ KGQA ë²¤ì¹˜ë§ˆí¬ì¸ WebQSP ë° ComplexWebQuestions(CWQ)ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ê³  íŠ¹íˆ ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì—ì„œ GPT-4ë¥¼ í¬í•¨í•œ ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.
{: .prompt-tip }

íŠ¹íˆ ë„ì „ì ì¸ ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì— ë¹›ì„ ë°œí•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

</details>
---
title: TRAG meets GNNs
description: Paper, GNN-RAG, LLM
categories: [Paper, GNN-RAG]
tags: [AI, LLM, GNN-RAG]
# author: foDev_jeong
date: 2024-06-03 15:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

## TRAG meets GNNs: Integrating graphs into a modern workflow.

Knowledge Graphs (KGs) are a powerful way to represent factual knowledge, but querying them with natural language is challenging. 

And Graph Neural Networks (GNNs) excel at reasoning over KGs, something Large Language Models (LLMs) are still struggling with.

There has been a lot of work in combining these two approaches lately, but it doesn't feel like we've found the right recipe yet. 

By leaning into the popular Retrieval-augmented Generation (RAG) trend, GNN-RAG tries to change this.

> The idea is for the GNN to handle the complex graph structure, while the LLM leverages its language understanding to produce the final answer. 

#### GNN-RAG achieves state-of-the-art performance on two major KGQA benchmarks, even outperforming GPT-4 in some cases. 

It particularly seems to shine on challenging multi-hop and multi-entity questions. 

> ğŸ§™Paper Authors: Costas Mavromatis, George Karypis
1Minnesota University 
- 1ï¸âƒ£Read the Full Paper here: <https://arxiv.org/abs/2405.20139>
- 2ï¸âƒ£Project Page: <https://medium.com/@techsachin/gnn-rag-combining-llms-language-abilities-with-gnns-reasoning-in-rag-style-d72200da376c>
- 3ï¸âƒ£Code: <https://github.com/cmavro/GNN-RAG>
{: .prompt-info }

![ GNN-RAG architecture ](/assets/img/paper/GNN-RAG.png){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

##  RAGì™€ GNNì˜ ë§Œë‚¨: ê·¸ë˜í”„ë¥¼ ìµœì‹  ì›Œí¬í”Œë¡œìš°ì— í†µí•©í•©ë‹ˆë‹¤.

ì§€ì‹ ê·¸ë˜í”„(KG)ëŠ” ì‚¬ì‹¤ì— ì…ê°í•œ ì§€ì‹ì„ í‘œí˜„í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì´ì§€ë§Œ ìì—°ì–´ë¡œ ì¿¼ë¦¬í•˜ëŠ” ê²ƒì€ ì–´ë µìŠµë‹ˆë‹¤. 

ê·¸ë¦¬ê³  ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” KGë³´ë‹¤ ì¶”ë¡ í•˜ëŠ” ë° íƒì›”í•©ë‹ˆë‹¤.

ìµœê·¼ ì´ ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ê²°í•©í•˜ëŠ” ë° ë§ì€ ì‘ì—…ì´ ìˆì—ˆì§€ë§Œ ì•„ì§ ì˜¬ë°”ë¥¸ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

GNN-RAGëŠ” ì¸ê¸° ìˆëŠ” RAG(Retrieval-augmented Generation) ì¶”ì„¸ì— ê¸°ëŒ€ì–´ ì´ë¥¼ ë°”ê¾¸ë ¤ê³  í•©ë‹ˆë‹¤.

> ì•„ì´ë””ì–´ëŠ” GNNì´ ë³µì¡í•œ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°˜ë©´, LLMì€ ì–¸ì–´ ì´í•´ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 

#### GNN-RAGëŠ” ë‘ ê°€ì§€ ì£¼ìš” KGQA ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ê²½ìš°ì— ë”°ë¼ GPT-4ë¥¼ ëŠ¥ê°€í•˜ê¸°ë„ í•©ë‹ˆë‹¤. 

íŠ¹íˆ ë„ì „ì ì¸ ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì— ë¹›ì„ ë°œí•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

</details>
---
title: TRAG meets GNNs
description: Paper, GNN-RAG, LLM
categories: [Paper, GNN-RAG]
tags: [AI, LLM, GNN-RAG]
# author: foDev_jeong
date: 2024-06-03 15:00:00 +0800
# pin: true
mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

## GNN-RAG: Integrating Graphs into Modern RAG Workflows

*Curiosity:* How can we combine Knowledge Graphs with LLMs for better question answering? What happens when GNNs handle graph reasoning while LLMs handle language understanding?

**GNN-RAG** integrates Graph Neural Networks (GNNs) with Retrieval-Augmented Generation (RAG) to solve Knowledge Graph Question Answering (KGQA). The idea: GNN handles complex graph structure, while LLM leverages language understanding for final answers.

> **Resources**:
> - **ğŸ“„ Paper**: <https://arxiv.org/abs/2405.20139>
> - **ğŸŒ Project Page**: <https://medium.com/@techsachin/gnn-rag-combining-llms-language-abilities-with-gnns-reasoning-in-rag-style-d72200da376c>
> - **ğŸ’» Code**: <https://github.com/cmavro/GNN-RAG>
{: .prompt-info}

### The Challenge

*Retrieve:* Knowledge Graphs are powerful but challenging to query with natural language.

| Component | Strength | Limitation |
|:----------|:---------|:-----------|
| **Knowledge Graphs** | Powerful factual representation | âš ï¸ Hard to query with NL |
| **GNNs** | Excel at graph reasoning | âš ï¸ Limited language understanding |
| **LLMs** | Strong language understanding | âš ï¸ Struggle with graph reasoning |

**Problem**: Vanilla RAG struggles with structured knowledge sources like KGs. 


### Why Vanilla RAG Struggles

*Retrieve:* Vanilla RAG's limitations with Knowledge Graphs.

**Issues**:
- Relies heavily on LLMs for retrieval
- LLMs not adept at handling complex graph information
- Suboptimal performance on multi-hop questions
- Struggles with multi-entity questions
- Requires traversing multiple relationships

**Impact**: Poor performance on structured knowledge sources.

### GNN-RAG Solution

*Innovate:* Combining GNNs and LLMs for optimal performance.

**Division of Labor**:
- **GNN**: Processes graph structures, reasons over dense KG subgraphs, retrieves answer candidates
- **LLM**: Leverages NLP abilities, reasons over GNN-provided information, generates final answers

### Workflow

*Retrieve:* GNN-RAG's step-by-step process.

```mermaid
graph TB
    A[Question] --> B[GNN Processing]
    B --> C[KG Subgraph]
    C --> D[Candidate Answers]
    D --> E[Shortest Paths]
    E --> F[Reasoning Paths]
    F --> G[Verbalization]
    G --> H[LLM Reasoning]
    H --> I[Final Answer]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style H fill:#d4edda
    style I fill:#f8d7da
```

**Steps**:
1. **GNN Processing**: Processes KG to identify candidate answers
2. **Path Extraction**: Extracts shortest paths connecting question entities to candidates
3. **Verbalization**: Converts paths to natural language
4. **LLM Reasoning**: Final reasoning and answer generation

### Performance

*Retrieve:* GNN-RAG achieves SOTA on major benchmarks.

**Benchmarks**:
- WebQSP
- ComplexWebQuestions (CWQ)

**Results**:
- âœ… State-of-the-art performance
- âœ… Outperforms GPT-4 in some cases
- âœ… Particularly strong on multi-hop questions
- âœ… Excellent on multi-entity questions

### Architecture Comparison

| Approach | Graph Reasoning | Language Understanding | Performance |
|:---------|:----------------|:----------------------|:------------|
| **Vanilla RAG** | âŒ Weak | âœ… Strong | âš ï¸ Suboptimal |
| **GNN-RAG** | âœ… Strong | âœ… Strong | âœ… SOTA |

### Key Takeaways

*Retrieve:* GNN-RAG combines GNNs' graph reasoning with LLMs' language understanding, achieving SOTA on KGQA benchmarks by letting each component handle what it does best.

*Innovate:* By using GNNs for graph processing and LLMs for language understanding, GNN-RAG demonstrates how specialized components can work together to solve complex problems that neither can handle alone.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about Knowledge Graph Question Answering, retrieve insights from GNN-RAG's hybrid approach, and innovate by applying similar techniques to your structured knowledge applications.

**Next Steps**:
- Read the full paper
- Explore the code repository
- Try GNN-RAG on your KGs
- Adapt for your use cases 

*Curiosity:* What insights can we retrieve from this? How does this connect to innovation in the field?

> GNN-RAG achieves state-of-the-art results on two widely used KGQA benchmarks, WebQSP and ComplexWebQuestions (CWQ) and outperforms existing methods, including GPT-4, particularly on multi-hop and multi-entity questions.
{: .prompt-tip }

It particularly seems to shine on challenging multi-hop and multi-entity questions. 

> ğŸ§™Paper Authors: Costas Mavromatis, George Karypis
1Minnesota University 
- 1ï¸âƒ£Read the Full Paper here: <https://arxiv.org/abs/2405.20139>
- 2ï¸âƒ£Project Page: <https://medium.com/@techsachin/gnn-rag-combining-llms-language-abilities-with-gnns-reasoning-in-rag-style-d72200da376c>
- 3ï¸âƒ£Code: <https://github.com/cmavro/GNN-RAG>
{: .prompt-info }

![ GNN-RAG architecture ](/assets/img/paper/GNN-RAG.png){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

##  RAGì™€ GNNì˜ ë§Œë‚¨: ê·¸ë˜í”„ë¥¼ ìµœì‹  ì›Œí¬í”Œë¡œìš°ì— í†µí•©í•©ë‹ˆë‹¤.

ì§€ì‹ ê·¸ë˜í”„(KG)ëŠ” ì‚¬ì‹¤ì— ì…ê°í•œ ì§€ì‹ì„ í‘œí˜„í•˜ëŠ” ê°•ë ¥í•œ ë°©ë²•ì´ì§€ë§Œ ìì—°ì–´ë¡œ ì¿¼ë¦¬í•˜ëŠ” ê²ƒì€ ì–´ë µìŠµë‹ˆë‹¤. 

ê·¸ë¦¬ê³  ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” KGë³´ë‹¤ ì¶”ë¡ í•˜ëŠ” ë° íƒì›”í•©ë‹ˆë‹¤.

ìµœê·¼ ì´ ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ê²°í•©í•˜ëŠ” ë° ë§ì€ ì‘ì—…ì´ ìˆì—ˆì§€ë§Œ ì•„ì§ ì˜¬ë°”ë¥¸ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

GNN-RAGëŠ” ì¸ê¸° ìˆëŠ” RAG(Retrieval-augmented Generation) ì¶”ì„¸ì— ê¸°ëŒ€ì–´ ì´ë¥¼ ë°”ê¾¸ë ¤ê³  í•©ë‹ˆë‹¤.

> ì•„ì´ë””ì–´ëŠ” GNNì´ ë³µì¡í•œ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°˜ë©´, LLMì€ ì–¸ì–´ ì´í•´ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 

## ğŸ¤” Vanilla-RAGëŠ” ì§€ì‹ ê·¸ë˜í”„ì™€ ê°™ì€ êµ¬ì¡°í™”ëœ ì§€ì‹ ì†ŒìŠ¤ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. GNN-RAGëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë§¤ìš° ê¹”ë”í•œ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤!

### â›³ Vanilla-RAGëŠ” KGì— ë‚´ì¬ëœ ë³µì¡í•œ ê·¸ë˜í”„ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ëŠ¥ìˆ™í•˜ì§€ ì•Šì€ LLMì— í¬ê²Œ ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì— KGì™€ ê°™ì€ êµ¬ì¡°í™”ëœ ì…ë ¥ì— ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì„±ëŠ¥ì´ ìµœì í™”ë˜ì§€ ì•Šìœ¼ë©°, íŠ¹íˆ ê·¸ë˜í”„ì—ì„œ ì—¬ëŸ¬ ê´€ê³„ë¥¼ ìˆœíšŒí•´ì•¼ í•˜ëŠ” ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.

### â›³ GNN-RAGëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ LLMê³¼ ê·¸ë˜í”„ ì‹ ê²½ë§(GNN)ì˜ ê°•ì ì„ í†µí•©í•©ë‹ˆë‹¤.
- ğŸ’¡ GNN: ê·¸ë˜í”„ êµ¬ì¡°ì— ëŒ€í•œ ì²˜ë¦¬ ë° ì¶”ë¡ ì— íƒì›”í•©ë‹ˆë‹¤. ì¡°ë°€í•œ KG í•˜ìœ„ ê·¸ë˜í”„ë¥¼ í†µí•´ ì¶”ë¡ í•˜ì—¬ ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í›„ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ğŸ’¡LLM: ìì—°ì–´ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ GNNì—ì„œ ì œê³µí•˜ëŠ” ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.

ğŸ‘‰ ì›Œí¬í”Œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
- ğŸ”º GNNì€ KGë¥¼ ì²˜ë¦¬í•˜ì—¬ í›„ë³´ ë‹µë³€ì„ ì‹ë³„í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ğŸ”ºKGì˜ í›„ë³´ìì—ê²Œ ë‹µë³€í•˜ê¸° ìœ„í•´ ì§ˆë¬¸ ì—”í„°í‹°ë¥¼ ì—°ê²°í•˜ëŠ” ìµœë‹¨ ê²½ë¡œê°€ ì¶”ì¶œë˜ì–´ ì¶”ë¡  ê²½ë¡œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- ğŸ”ºì´ëŸ¬í•œ ê²½ë¡œëŠ” ì–¸ì–´í™”ë˜ì–´ ìµœì¢… ì¶”ë¡  ë° ë‹µë³€ ìƒì„±ì„ ìœ„í•´ LLMì— ì…ë ¥ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.

### GNN-RAGëŠ” ë‘ ê°€ì§€ ì£¼ìš” KGQA ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ë©° ê²½ìš°ì— ë”°ë¼ GPT-4ë¥¼ ëŠ¥ê°€í•˜ê¸°ë„ í•©ë‹ˆë‹¤. 

> GNN-RAGëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë‘ ê°€ì§€ KGQA ë²¤ì¹˜ë§ˆí¬ì¸ WebQSP ë° ComplexWebQuestions(CWQ)ì—ì„œ ìµœì²¨ë‹¨ ê²°ê³¼ë¥¼ ë‹¬ì„±í•˜ê³  íŠ¹íˆ ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì—ì„œ GPT-4ë¥¼ í¬í•¨í•œ ê¸°ì¡´ ë°©ë²•ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.
{: .prompt-tip }

íŠ¹íˆ ë„ì „ì ì¸ ë‹¤ì¤‘ í™‰ ë° ë‹¤ì¤‘ ì—”í„°í‹° ì§ˆë¬¸ì— ë¹›ì„ ë°œí•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. 

</details>
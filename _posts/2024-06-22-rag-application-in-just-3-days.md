---
title: ğŸ”Š Create your own LLM RAG application in just 3 days using this hands-on roadmap
  crafted from the best free resources!
description: RAG, Applicaition
categories:
- LLM & Language Models
- RAG & Retrieval Systems
tags:
- rag
- application-development
- llm
- language-model
date: 2024-06-22 20:10:00 +0800
mermaid: true
---
## Build Your RAG Application in 3 Days: A Hands-On Roadmap

*Curiosity:* How can we build a production-ready RAG application quickly? What's the fastest path from basics to advanced RAG implementation?

**RAG (Retrieval Augmented Generation)** has emerged as an extremely popular LLM application. Its appeal lies in its lightweight design and the simplicity of integrating it with any foundational LLM.

> **ğŸ“– Complete Roadmap**: <https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/resources/RAG_roadmap.md>
{: .prompt-info}

### 3-Day Learning Path

```mermaid
gantt
    title RAG Learning Roadmap (3 Days)
    dateFormat YYYY-MM-DD
    section Day 1
    RAG Basics           :a1, 2024-01-01, 1d
    Components           :a2, after a1, 1d
    section Day 2
    Advanced RAG         :b1, 2024-01-02, 1d
    Build Application    :b2, after b1, 1d
    section Day 3
    Evaluation           :c1, 2024-01-03, 1d
    Challenges           :c2, after c1, 1d
```

**Time Commitment**: 2-3 hours per day

### Day 1: Introduction to RAG

*Retrieve:* Understand RAG fundamentals and core components.

**Learning Objectives**:
- âœ… What is Retrieval Augmented Generation?
- âœ… Key components: Ingestion, Retrieval, Synthesis
- âœ… Pipeline components: Chunking, Embedding, Indexing, Top-k Retrieval, Generation

**Topics Covered**:

| Topic | Description | Key Concepts |
|:------|:------------|:-------------|
| **RAG Basics** | What is RAG? | Retrieval + Generation |
| **Ingestion** | Data preparation | Document loading, preprocessing |
| **Retrieval** | Information retrieval | Vector search, similarity |
| **Synthesis** | Answer generation | LLM integration, context |

**RAG Pipeline**:

```mermaid
graph LR
    A[Documents] --> B[Chunking]
    B --> C[Embedding]
    C --> D[Indexing]
    D --> E[Vector DB]
    
    F[Query] --> G[Embedding]
    G --> H[Top-k Retrieval]
    E --> H
    H --> I[Synthesis]
    I --> J[Answer]
    
    style A fill:#e1f5ff
    style E fill:#fff3cd
    style I fill:#d4edda
    style J fill:#f8d7da
```

**Key Components**:
- **Chunking**: Split documents into manageable pieces
- **Embedding**: Convert text to vectors
- **Indexing**: Store in vector database
- **Top-k Retrieval**: Find most relevant chunks
- **Generation**: Create answer from context

### Day 2: Advanced RAG + Build Your Own System

*Innovate:* Learn advanced techniques and build a complete RAG application.

**Learning Objectives**:
- âœ… Advanced RAG optimizations
- âœ… Build RAG system with LangChain and OpenAI
- âœ… Implement advanced retrieval techniques

**Advanced Techniques**:

| Technique | Description | Benefit |
|:----------|:------------|:--------|
| **Self-Querying Retrieval** | LLM-generated queries | â¬†ï¸ Better retrieval |
| **Parent Document Retriever** | Hierarchical retrieval | â¬†ï¸ Context preservation |
| **Hybrid Search** | Semantic + keyword | â¬†ï¸ Retrieval quality |
| **Compressors** | Context compression | â¬‡ï¸ Token usage |
| **HyDE** | Hypothetical documents | â¬†ï¸ Query understanding |

**Building RAG System**:

```python
# Example: Building RAG with LangChain
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# 1. Load and chunk documents
from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
documents = text_splitter.split_documents(load_documents())

# 2. Create embeddings and vector store
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents, embeddings)

# 3. Create retrieval chain
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)

# 4. Query
result = qa_chain.run("What is RAG?")
print(result)
```

**Advanced RAG Architecture**:

```mermaid
graph TB
    A[Query] --> B[Query Rewriting]
    B --> C[Hybrid Search]
    C --> D[Semantic Search]
    C --> E[Keyword Search]
    D --> F[Retrieval]
    E --> F
    F --> G[Re-ranking]
    G --> H[Context Compression]
    H --> I[LLM Generation]
    I --> J[Answer]
    
    style A fill:#e1f5ff
    style C fill:#fff3cd
    style I fill:#d4edda
    style J fill:#f8d7da
```

### Day 3: RAG Evaluation and Challenges

*Retrieve:* Learn how to evaluate RAG systems and address common challenges.

**Learning Objectives**:
- âœ… Evaluation metrics (TruEra, RAGas)
- âœ… RAG pain points and solutions
- âœ… Production best practices

**Evaluation Metrics**:

| Metric | Framework | Purpose |
|:-------|:----------|:--------|
| **Faithfulness** | RAGas | Factual accuracy |
| **Answer Relevancy** | RAGas | Answer quality |
| **Context Precision** | RAGas | Retrieval quality |
| **Context Recall** | RAGas | Coverage |
| **TruEra Metrics** | TruEra | Comprehensive evaluation |

**Evaluation Example**:

```python
from ragas import evaluate
from datasets import Dataset

# Prepare evaluation dataset
dataset = Dataset.from_dict({
    "question": ["What is RAG?"],
    "contexts": [["RAG is retrieval augmented generation..."]],
    "answer": ["RAG combines retrieval and generation..."],
    "ground_truth": ["RAG is a technique that..."]
})

# Evaluate
results = evaluate(
    dataset=dataset,
    metrics=["faithfulness", "answer_relevancy", "context_precision"]
)
print(results)
```

**Common RAG Challenges**:

| Challenge | Description | Solution |
|:----------|:------------|:---------|
| **Poor Retrieval** | Irrelevant context | Better embeddings, hybrid search |
| **Context Window** | Limited tokens | Compression, summarization |
| **Hallucination** | Incorrect facts | Better retrieval, fact-checking |
| **Latency** | Slow responses | Caching, optimization |
| **Scalability** | Large datasets | Efficient indexing, sharding |

### Complete Roadmap Structure

```mermaid
graph TB
    A[3-Day RAG Roadmap] --> B[Day 1: Basics]
    A --> C[Day 2: Advanced + Build]
    A --> D[Day 3: Evaluation]
    
    B --> B1[RAG Introduction]
    B --> B2[Components]
    B --> B3[Pipeline]
    
    C --> C1[Advanced Techniques]
    C --> C2[Build System]
    C --> C3[LangChain + OpenAI]
    
    D --> D1[Evaluation Metrics]
    D --> D2[Challenges]
    D --> D3[Solutions]
    
    E[Optional Resources] --> A
    F[Research Papers] --> A
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
```

### Additional Resources

**Optional Reading**:
- RAG research papers
- Advanced techniques
- Best practices
- Case studies

**2024 RAG Research Papers**:
- Latest RAG improvements
- Novel architectures
- Evaluation methods
- Production deployments

### Key Takeaways

*Retrieve:* This 3-day roadmap provides a structured path from RAG basics to building and evaluating production-ready applications.

*Innovate:* By following this roadmap, you'll learn advanced RAG techniques, build your own system, and understand how to evaluate and optimize RAG applications.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about RAG, retrieve knowledge through the structured roadmap, and innovate by building your own RAG applications.

**Next Steps**:
- Follow the 3-day roadmap
- Build your RAG system
- Evaluate and optimize
- Deploy to production

![ 3 Day RAG Roadmap ](/assets/img/llm/RAG_Roadmap_3_days.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## RAG(Retrieval Augmented Generation)ëŠ” LLM ë¶„ì•¼ì—ì„œ ë§¤ìš° ì¸ê¸° ìˆëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. 

ì´ ê²Œì„ì˜ ë§¤ë ¥ì€ ê²½ëŸ‰ ì„¤ê³„ì™€ ê¸°ë³¸ LLMê³¼ í†µí•©í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì— ìˆìŠµë‹ˆë‹¤.

ğŸ’¡ ì´ 3ì¼ ê°€ì´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ RAGì˜ ì§„í™”í•˜ëŠ” í™˜ê²½ê³¼ ìµœì‹  ê°œë°œì— ëŒ€í•´ ì•Œì•„ë³´ì„¸ìš”! ë§¤ì¼ 2-3 ì‹œê°„ì„ ìì›ì— íˆ¬ìí•˜ì‹­ì‹œì˜¤.

ğŸ¥ ê¸°ë³¸ ì‚¬í•­ë¶€í„° ì‹œì‘í•˜ì—¬ ê³ ê¸‰ ì•„ì´ë””ì–´ë¡œ ì´ë™í•˜ê³ , LangChainì„ ì‚¬ìš©í•˜ì—¬ ì•±ì„ ë¹Œë“œí•˜ê³ , í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. ë˜í•œ ì´ ë¶„ì•¼ì˜ ìµœì‹  ì—°êµ¬ë¥¼ ë”°ë¼ì¡ì„ ìˆ˜ ìˆëŠ” ë¦¬ì†ŒìŠ¤ë„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

### â›³ 1ì¼ì°¨: RAG ì†Œê°œ
- ğŸ‘‰ ê²€ìƒ‰ ì¦ê°• ìƒì„±ì´ë€ ë¬´ì—‡ì…ë‹ˆê¹Œ?
- ğŸ‘‰ RAGì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ: Ingestion, Retrieval, Synthesis
- ğŸ‘‰ RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ: ì²­í¬, ì„ë² ë”©, ì¸ë±ì‹±, Top-k ê²€ìƒ‰ ë° ìƒì„±

### â›³ 2ì¼ì°¨: ê³ ê¸‰ RAG + ë‚˜ë§Œì˜ RAG ì‹œìŠ¤í…œ êµ¬ì¶•í•˜ê¸°
- ğŸ‘‰ ê³ ê¸‰ RAG ìµœì í™”: Self Querying Retrieval, Parent Document ğŸ‘‰ Retriever, Hybrid Search, Compressors, HyDE ë“±
- ğŸ‘‰ LangChain ë° OpenAIë¡œ ìì²´ RAG ì‹œìŠ¤í…œ êµ¬ì¶•
ê³ ê¸‰ RAG ì‘ìš© í”„ë¡œê·¸ë¨ êµ¬ì¶•ì„ ìœ„í•œ ë¦¬ì†ŒìŠ¤

### â›³3ì¼ì°¨: RAG í‰ê°€ ë° ê³¼ì œ
- ğŸ‘‰TruEra ë° RAGasì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í‰ê°€ ì§€í‘œ
- ğŸ‘‰RAGì˜ ë¬¸ì œì  ë° í•´ê²° ë°©ë²•

ğŸ¥ğŸ¥ë¡œë“œë§µì—ëŠ” ë‹¤ìŒ ë‚´ìš©ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: Optional Reading Resources & Top 2024 RAG research papers

</details>
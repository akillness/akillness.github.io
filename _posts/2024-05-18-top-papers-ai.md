---
title: Top Papers in Computer Vision, NLP, Speech, Multimodal AI, Core ML, RecSys, and Graph ML 
description: Vision Models, ELO, Compare
categories: [Script, Papers]
tags: [Papers]
# author: foDev_jeong
date: 2024-05-18 18:20:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## ğŸ“ Top Papers in Computer Vision, NLP, Speech, Multimodal AI, Core ML, RecSys, and Graph ML â€¢ 

> Distilled AI : https://aman.ai/papers/
> aman AI : https://aman.ai/

ğŸ‘‰ğŸ¼ Iâ€™ve put together a summary of key papers in í•´ì‹œíƒœê·¸#AI and segregated them into (i) need-to-know and (ii) good-to-know.

ğŸ”¹ Vision
- Image Classification (CNN architectures such as AlexNet, VGGNet, InceptionNet, ResNet to Transformer architectures such as ViT, DeiT, BEiT, MAE)
- Object Detection (YOLO v1-v8, Fast/er R-CNN, Mask R-CNN, CenterNet, Pix2Seq, DETR, Detic, Focal Loss)
- Semantic/Instance Segmentation (U-Net, Mask R-CNN, Segment Anything)
- NeRF (InstantNeRF, BlockNeRF)
- SSL Contrastive Learning (SimCLR, MoCo, DINO v1 & v2)

ğŸ”¹ NLP
- Transformers (original paper)
- Semantic Representation Encoders (BERT and its variants: RoBERTa, DistillBERT, ELECTRA, XLNet, MPNet, ALBERT)
- Autoregressive Decoders (GPT-n, Llama 1/2/3, Alpaca, Vicuna)
- Augmented LMs (RAG, Toolformer, HuggingGPT, Gorilla)
- Supervised Fine-tuning (Instruction tuning/FLAN, LIMA, LESS)
- LLM Alignment (RLHF/InstructGPT, PPO, DPO, KTO, GPO, IPO)
- Encoder + Decoder Architectures (T0, T5, BART)
- Machine Translation (M2M-100, NLLB-200)
- Contrastive Learning (SNCSE, InfoNCE, Sentence-BERT)
- Prompting (CoT, Auto-CoT, Self-Consistency, ToT, GoT, ReAct, APE, ART)
- PEFT (Prefix-tuning, Adapters, LoRA, LLaMA-Adapter v1 and v2, QLoRA, QA-LoRA, DoRA, NOLA)

ğŸ”¹ Speech
- SSL Pre-Training (WavLM, AudioMAE, HuBERT)
- Automatic Speech Recognition/Keyword Spotting (GMM-HMM, DNN-HMM, all-neural architectures such as LAS/Whisper, streaming architectures such as RNN-T/Transformer-T)
- Speaker Identification (i/d/x-vectors, GE2E loss, AAM loss)
- Text-to-Speech (HiFi-GAN, Tacotron v1 and v2, Voicebox)
- Text-to-Audio/Music (MusicGen, AudioGen)

ğŸ”¹ Multimodal
- SSL Pre-Training (ViLT, MLIM, UNiTER, LXMERT, VisualBERT, Data2Vec v1 and v2, I-Code, VL-BEIT, ImageBind)
- V+L Prompting (Flamingo, Frozen, InstructBLIP)
- Text-to-Image (DALL-E 1/2/3, Imagen, Latent Diffusion, Make-A-Scene, Make-a-Video)
- Translation (SeamlessM4T)
- Contrastive Learning (InfoNCE, CLIP, CLAP, AudioCLIP)

ğŸ”¹ Core ML
- Training Regularizer (Dropout)
- Training/Inference Efficiency (ZeRO, ZeRO-Infinity, FlashAttention, FlashAttention-2)
- Training Stability (Batch/Layer/Group/Instance Norm, Residual/Skip Connections)
- Explainable AI (Guided Backprop, Grad-CAM, CAV, Influence functions, Representer points, TracIn)

ğŸ”¹ RecSys
- ML-based Collaborative Filtering (Factorization Machines)
- DL-based Algorithms (Collaborative Deep Learning, Wide & Deep, DNNs for YouTube Recommendations, Product-based DNNs, NCF, Deep & Cross v1 and v2, DeepFM, Deep Interest Network, Behavior Sequence Transformer)

ğŸ”¹ Graph ML
- Factorization-based Algorithms LLE (LLE, LAP, HOPE)
- Random Walk-based Algorithms (Node2vec)
- Deep Learning-based Algorithms (SDNE, GraphSAGE, EGNN, GCN, GAT)


![ Top Papers ](/assets/img/news/AI_Papers_link.gif){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## ğŸ“ ì»´í“¨í„° ë¹„ì „, NLP, ìŒì„±, ë©€í‹°ëª¨ë‹¬ AI, Core ML, RecSys ë° Graph ML ë¶„ì•¼ì˜ ì£¼ìš” ë…¼ë¬¸ â€¢ 

> Distilled AI : https://aman.ai/papers/
> aman AI : https://aman.ai/
> 
ğŸ‘‰ğŸ¼ í•´ì‹œíƒœê·¸#AI ì˜ ì£¼ìš” ë…¼ë¬¸ì„ ìš”ì•½í•˜ì—¬ (i) ì•Œì•„ì•¼ í•  ì‚¬í•­ê³¼ (ii) ì•Œì•„ë‘ë©´ ì¢‹ì€ ë‚´ìš©ìœ¼ë¡œ êµ¬ë¶„í–ˆìŠµë‹ˆë‹¤.

ğŸ”¹ ì‹œë ¥
- ì´ë¯¸ì§€ ë¶„ë¥˜(AlexNet, VGGNet, InceptionNet, ResNetê³¼ ê°™ì€ CNN ì•„í‚¤í…ì²˜ì—ì„œ ViT, DeiT, BEiT, MAEì™€ ê°™ì€ Transformer ì•„í‚¤í…ì²˜ê¹Œì§€)
- ë¬¼ì²´ ê°ì§€(YOLO v1-v8, Fast/er R-CNN, Mask R-CNN, CenterNet, Pix2Seq, DETR, Detic, Focal Loss)
- ì˜ë¯¸ë¡ ì /ì¸ìŠ¤í„´ìŠ¤ ë¶„í• (U-Net, Mask R-CNN, Segment Anything)
- NeRF (InstantNeRF, BlockNeRF)
- SSL ëŒ€ì¡° í•™ìŠµ(SimCLR, MoCo, DINO v1 ë° v2)

ğŸ”¹ NLP (ì˜ì–´)
- ë³€ì••ê¸° (ì›ë³¸ ìš©ì§€)
- ì˜ë¯¸ë¡ ì  í‘œí˜„ ì¸ì½”ë”(BERT ë° ê·¸ ë³€í˜•: RoBERTa, DistillBERT, ELECTRA, XLNet, MPNet, ALBERT)
- ìë™ íšŒê·€ ë””ì½”ë”(GPT-n, Llama 1/2/3, Alpaca, Vicuna)
- ì¦ê°• LM(RAG, Toolformer, HuggingGPT, Gorilla)
- ê°ë… ë¯¸ì„¸ ì¡°ì •(ëª…ë ¹ íŠœë‹/FLAN, LIMA, LESS)
- LLM ì–¼ë¼ì¸ë¨¼íŠ¸ (RLHF/InstructGPT, PPO, DPO, KTO, GPO, IPO)
- ì¸ì½”ë” + ë””ì½”ë” ì•„í‚¤í…ì²˜(T0, T5, BART)
- ê¸°ê³„ ë²ˆì—­ (M2M-100, NLLB-200)
- ëŒ€ì¡° í•™ìŠµ(SNCSE, InfoNCE, Sentence-BERT)
- í”„ë¡¬í”„íŠ¸(CoT, Auto-CoT, Self-Consistency, ToT, GoT, ReAct, APE, ART)
- PEFT(ì ‘ë‘ì‚¬ íŠœë‹, ì–´ëŒ‘í„°, LoRA, LLaMA-ì–´ëŒ‘í„° v1 ë° v2, QLoRA, QA-LoRA, DoRA, NOLA)

ğŸ”¹ ì—°ì„¤
- SSL ì‚¬ì „ êµìœ¡(WavLM, AudioMAE, HuBERT)
- ìë™ ìŒì„± ì¸ì‹/í‚¤ì›Œë“œ ìŠ¤í¬íŒ…(GMM-HMM, DNN-HMM, LAS/Whisperì™€ ê°™ì€ ì „ì²´ ì‹ ê²½ ì•„í‚¤í…ì²˜, RNN-T/Transformer-Tì™€ ê°™ì€ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜)
- í™”ì ì‹ë³„(i/d/x-ë²¡í„°, GE2E ì†ì‹¤, AAM ì†ì‹¤)
- í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜(HiFi-GAN, Tacotron v1 ë° v2, Voicebox)
- í…ìŠ¤íŠ¸-ì˜¤ë””ì˜¤/ìŒì•…(MusicGen, AudioGen)

ğŸ”¹ ë³µí•©
- SSL ì‚¬ì „ í•™ìŠµ(ViLT, MLIM, UNiTER, LXMERT, VisualBERT, Data2Vec v1 ë° v2, I-Code, VL-BEIT, ImageBind)
- V+L í”„ë¡¬í”„íŠ¸ (Flamingo, Frozen, InstructBLIP)
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€(DALL-E 1/2/3, ì˜ìƒ, ì ì¬ í™•ì‚°, Make-A-Scene, Make-A-Video)
- ë²ˆì—­(SeamlessM4T)
- ëŒ€ì¡° í•™ìŠµ(InfoNCE, CLIP, CLAP, AudioCLIP)

ğŸ”¹ ì½”ì–´ ML
- êµìœ¡ ì •ê·œí™”ê¸°(ë“œë¡­ì•„ì›ƒ)
- í›ˆë ¨/ì¶”ë¡  íš¨ìœ¨ì„±(ZeRO, ZeRO-Infinity, FlashAttention, FlashAttention-2)
- í•™ìŠµ ì•ˆì •ì„±(ë°°ì¹˜/ë ˆì´ì–´/ê·¸ë£¹/ì¸ìŠ¤í„´ìŠ¤ í‘œì¤€, ì”ì°¨/ìŠ¤í‚µ ì—°ê²°)
- ì„¤ëª… ê°€ëŠ¥í•œ AI(ìœ ë„ ë°±í”„ë¡­, Grad-CAM, CAV, ì˜í–¥ë ¥ ê¸°ëŠ¥, ë°œí‘œì í¬ì¸íŠ¸, TracIn)

ğŸ”¹ ë ˆí¬ì‹œìŠ¤
- ML ê¸°ë°˜ í˜‘ì—… í•„í„°ë§(Factorization Machine)
- DL ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ (Collaborative Deep Learning, Wide & Deep, YouTube Recommendationsìš© DNN, ì œí’ˆ ê¸°ë°˜ DNN, NCF, Deep & Cross v1 ë° v2, DeepFM, Deep Interest Network, Behavior Sequence Transformer)

ğŸ”¹ ê·¸ë˜í”„ ML
- ì¸ìˆ˜ë¶„í•´ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ LLE(LLE, LAP, HOPE)
- ëœë¤ ì›Œí¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜(Node2vec)
- ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ (SDNE, GraphSAGE, EGNN, GCN, GAT)

</details>
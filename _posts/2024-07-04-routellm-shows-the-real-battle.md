---
title: Forget GPT-4o vs. Llama 3
description: Data Analytics, Python
categories: [LLM, RouteLLM]
tags: [Data Analytics, RouteLLM]
# author: foDev_jeong
date: 2024-07-04 20:10:00 +0800
# pin: true
# math: true
# mermaid: true
# image:
#   path: /assets/img/cover/programming.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [2024 programming curriculum by honglab]
---

## Open Source RouteLLM Shows the Real Battle is in Query Routing. 

The LLM landscape is heating up, but the real game-changer isn't just which model is "best". 

UC Berkeley researchers have unveiled RouteLLM, an open-source framework that cleverly routes your queries to the right model for the job. 

This means massive cost savings (think 85%+) without sacrificing the quality you expect. It's time to rethink how we deploy LLMs and prioritize intelligent routing.

Dive into the paper, try their demo, and see how open source is leading the way to a more efficient AI future. 

- Demo: <https://816388d8af31950a69.gradio.live/>
- Code: <https://github.com/lm-sys/RouteLLM>
- Paper: <https://arxiv.org/abs/2406.18665>
- ğŸ¤—Hugging Face: <https://huggingface.co/routellm>

![ RouteLLM Shows the Real Battle ](/assets/img/llm/RouteLLM_Shows_the_Real_Battle.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## ì˜¤í”ˆ ì†ŒìŠ¤ RouteLLMì€ ì‹¤ì œ ì „íˆ¬ê°€ ì¿¼ë¦¬ ë¼ìš°íŒ…ì— ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

LLM í™˜ê²½ì´ ëœ¨ê±°ì›Œì§€ê³  ìˆì§€ë§Œ ì§„ì •í•œ íŒë„ë¥¼ ë°”ê¾¸ëŠ” ê²ƒì€ ì–´ë–¤ ëª¨ë¸ì´ "ìµœê³ "ì¸ì§€ ë¿ë§Œì´ ì•„ë‹™ë‹ˆë‹¤.

UC Berkeley ì—°êµ¬ì›ë“¤ì€ ì¿¼ë¦¬ë¥¼ ì‘ì—…ì— ì í•©í•œ ëª¨ë¸ë¡œ êµë¬˜í•˜ê²Œ ë¼ìš°íŒ…í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì¸ RouteLLMì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤.

ì´ëŠ” ê¸°ëŒ€í•˜ëŠ” í’ˆì§ˆì„ ì €í•˜ì‹œí‚¤ì§€ ì•Šìœ¼ë©´ì„œ ì—„ì²­ë‚œ ë¹„ìš© ì ˆê°(85% ì´ìƒ)ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ì œ LLMì„ ë°°í¬í•˜ê³  ì§€ëŠ¥í˜• ë¼ìš°íŒ…ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì§€ì •í•˜ëŠ” ë°©ë²•ì„ ë‹¤ì‹œ ìƒê°í•´ ë³¼ ë•Œì…ë‹ˆë‹¤.

ë…¼ë¬¸ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ë°ëª¨ë¥¼ ì‹œë„í•˜ì—¬ ì˜¤í”ˆ ì†ŒìŠ¤ê°€ ì–´ë–»ê²Œ ë³´ë‹¤ íš¨ìœ¨ì ì¸ AI ë¯¸ë˜ë¥¼ ì„ ë„í•˜ëŠ”ì§€ ì•Œì•„ë³´ì„¸ìš”.

</details>
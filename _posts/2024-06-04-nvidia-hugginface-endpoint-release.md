---
title: The release of NVIDIA NIM on Hugging Face Inference Endpoints
description: NVIDIA, EndPoint
categories: [LLM, Cookbook]
tags: [AI, NVIDIA, Endpoint]
# author: foDev_jeong
date: 2024-06-04 02:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

## Yesterday at COMPUTEX, Jensen Huang announced the release of NVIDIA NIM on Hugging Face Inference Endpoints!

ğŸš€ NVIDIA NIM are inference services designed to streamline and accelerate the deployment of generative AI models. ğŸ‘€

- 1ï¸âƒ£ 1-click deployment from Hugging Face Hub to Inference Endpoints
- ğŸ†• Starting with Llama 3 8B and Llama 3 70B on AWS, GCP
- ğŸš€ Up to 9000 tokens/sec for Llama 3 8B
- ğŸ”œ Adding Mixtral 8x22B, Phi-3, and Gemma and more soon

Learn More: <https://developer.nvidia.com/blog/nvidia-collaborates-with-hugging-face-to-simplify-generative-ai-model-deployments>


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

##  ì–´ì œ COMPUTEXì—ì„œ Jensen Huang ëŠ” Hugging Face ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ NVIDIA NIMì˜ ì¶œì‹œë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤!

ğŸš€ NVIDIA NIMì€ ìƒì„±í˜• AI ëª¨ë¸ì˜ ë°°í¬ë¥¼ ê°„ì†Œí™”í•˜ê³  ê°€ì†í™”í•˜ë„ë¡ ì„¤ê³„ëœ ì¶”ë¡  ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ğŸ‘€

- 1ï¸âƒ£ Hugging Face Hubì—ì„œ Inference Endpointsë¡œ 1-í´ë¦­ ë°°í¬
- ğŸ†• AWSì˜ Llama 3 8B ë° Llama 3 70Bë¶€í„° GCP
- ğŸš€ ìµœëŒ€ 9000 í† í°/ì´ˆ (Llama 3 8B)
- ğŸ”œ Mixtral 8x22B, Phi-3 ë° Gemma ë“±ì´ ê³§ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.

ìì„¸íˆë³´ê¸°: <https://developer.nvidia.com/blog/nvidia-collaborates-with-hugging-face-to-simplify-generative-ai-model-deployments>

</details>
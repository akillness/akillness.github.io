---
title: LLama Factory is one of the best Open-source tools
description: LLM, Llama
categories:
- LLM & Language Models
tags:
- llm
- llama
- opensource
date: 2024-05-01 19:57:00 +0800
mermaid: true
image:
  path: /assets/img/news/Llama-factory.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt:
  - LlaMA-Factory is one of the best open-source tools out there
---
> [LLM Finetuning](https://github.com/lxe/simple-llm-finetuner?tab=readme-ov-file)
{: .prompt-tip}

## LlaMA-Factory: The Best Open-Source LLM Fine-Tuning Tool

*Curiosity:* How can we make LLM fine-tuning accessible to everyone? What tools enable low-code, GUI-based fine-tuning for practitioners at all levels?

**LlaMA-Factory** is one of the best open-source tools for fine-tuning LLMs, especially if you're new to fine-tuning and prefer a GUI-based or low-code approach. With 17k+ GitHub stars, it's become the go-to solution for efficient, user-friendly LLM customization.

### Why LlaMA-Factory?

```mermaid
graph TB
    A[LlaMA-Factory] --> B[GUI-Based]
    A --> C[Low-Code]
    A --> D[Comprehensive]
    
    B --> B1[Easy Setup]
    B --> B2[Visual Interface]
    B --> B3[Single GPU Support]
    
    C --> C1[Few Clicks]
    C --> C2[Pre-configured]
    C --> C3[Minimal Coding]
    
    D --> D1[Multiple Methods]
    D --> D2[Many Models]
    D --> D3[Full Pipeline]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
```

### Key Features Overview

| Feature Category | Capabilities | Impact |
|:-----------------|:-------------|:-------|
| **Model Support** | LLaMA, Mistral, Qwen, Gemma, etc. | â­â­â­ Wide compatibility |
| **Tuning Methods** | SFT, RLHF, PPO, DPO, ORPO | â­â­â­ Comprehensive |
| **PEFT & Quantization** | LoRA, QLoRA, Freeze-tuning | â­â­â­ Efficient |
| **Advanced Algorithms** | GaLore, DoRA, LongLoRA, etc. | â­â­ Cutting-edge |
| **Monitoring** | TensorBoard, Wandb, MLflow | â­â­ Professional |
| **Deployment** | OpenAI API, Gradio, vLLM | â­â­â­ Production-ready |

### ğŸŒ Diverse LLM Support

*Retrieve:* LlaMA-Factory supports a wide range of models, making it versatile for different use cases.

| Model Family | Versions Supported | Use Cases |
|:-------------|:-------------------|:----------|
| **LLaMA** | All versions (1, 2, 3) | General-purpose, research |
| **Mistral** | Mistral, Mixtral-MoE | Efficient, multilingual |
| **Qwen** | Qwen series | Chinese, multilingual |
| **Gemma** | Gemma models | Google's open models |
| **Others** | Various architectures | Specialized tasks |

### ğŸ›  Comprehensive Tuning Methods

*Innovate:* LlaMA-Factory offers a complete suite of fine-tuning approaches.

| Method | Description | Best For |
|:-------|:------------|:---------|
| **Continuous Pre-training** | Further pre-training on domain data | Domain adaptation |
| **Supervised Fine-Tuning (SFT)** | Task-specific training | Instruction following |
| **Reward Modeling** | Preference learning | Alignment |
| **PPO** | Proximal Policy Optimization | RLHF |
| **DPO** | Direct Preference Optimization | Efficient alignment |
| **ORPO** | Online Reinforcement Policy Optimization | Advanced RLHF |

### ğŸ” PEFT Methods & Quantization

*Retrieve:* Efficient fine-tuning options for resource-constrained environments.

```mermaid
graph LR
    A[Fine-Tuning Options] --> B[Full Tuning]
    A --> C[PEFT Methods]
    A --> D[Quantization]
    
    B --> B1[32-bit Full]
    
    C --> C1[16-bit Freeze]
    C --> C2[16-bit LoRA]
    C --> C3[QLoRA]
    
    D --> D1[2-bit QLoRA]
    D --> D2[4-bit QLoRA]
    D --> D3[8-bit QLoRA]
    
    style A fill:#e1f5ff
    style C fill:#fff3cd
    style D fill:#d4edda
```

| Method | Precision | Memory | Speed | Quality |
|:-------|:----------|:-------|:------|:--------|
| **Full Tuning** | 32-bit | High | Slow | Best |
| **Freeze Tuning** | 16-bit | Medium | Medium | Good |
| **LoRA** | 16-bit | Low | Fast | Good |
| **QLoRA 8-bit** | 8-bit | Very Low | Very Fast | Good |
| **QLoRA 4-bit** | 4-bit | Minimal | Fastest | Acceptable |

### ğŸ“ˆ Advanced Fine-Tuning Approaches

*Innovate:* State-of-the-art algorithms for improved performance and efficiency.

| Algorithm | Purpose | Benefit |
|:----------|:--------|:--------|
| **GaLore** | Gradient Low-Rank Projection | Memory efficiency |
| **BAdam** | Block-wise Adam | Optimized training |
| **DoRA** | Weight-Decomposed Low-Rank Adaptation | Better performance |
| **LongLoRA** | Efficient long context | Extended context |
| **Mixture-of-Depths** | Dynamic computation | Efficiency |
| **LoRA+** | Enhanced LoRA | Better adaptation |
| **LoftQ** | LoRA Fine-Tuning aware Quantization | Quantization-aware |
| **Agent Tuning** | Agent-specific optimization | Agent applications |

### ğŸ§â€â™€ï¸ Practical Optimization Tricks

*Retrieve:* Proven techniques to enhance fine-tuning outcomes.

| Technique | Purpose | Impact |
|:----------|:--------|:-------|
| **FlashAttention-2** | Memory-efficient attention | â¬†ï¸ Speed, â¬‡ï¸ Memory |
| **Unsloth** | Faster training | â¬†ï¸ 2-5x speedup |
| **RoPE Scaling** | Extended context | â¬†ï¸ Context length |
| **NEFTune** | Noise-enhanced training | â¬†ï¸ Performance |

### ğŸ“Š Experiment Monitoring

*Retrieve:* Professional monitoring tools for tracking training progress.

| Tool | Purpose | Features |
|:-----|:---------|:---------|
| **LlamaBoard** | Built-in dashboard | Real-time metrics |
| **TensorBoard** | TensorFlow visualization | Comprehensive logging |
| **Wandb** | Weights & Biases | Experiment tracking |
| **MLflow** | ML lifecycle management | Model versioning |

### ğŸš€ Deployment Options

*Innovate:* Multiple deployment strategies for production use.

```mermaid
graph TB
    A[Fine-Tuned Model] --> B[OpenAI-Style API]
    A --> C[Gradio UI]
    A --> D[CLI with vLLM]
    
    B --> B1[Production API]
    C --> C1[Interactive Demo]
    D --> D1[High Performance]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
```

| Deployment Method | Use Case | Performance |
|:------------------|:---------|:------------|
| **OpenAI-Style API** | Production services | Standard |
| **Gradio UI** | Demos, testing | Interactive |
| **vLLM Worker** | High-throughput | âš¡ Fastest |

### Quick Start Example

```python
# LlaMA-Factory makes fine-tuning simple
# GUI-based approach - no code needed!

# Or programmatically:
from llamafactory import ModelFactory

# Load model
factory = ModelFactory()

# Configure fine-tuning
config = {
    "model_name": "llama-3-8b",
    "method": "lora",
    "rank": 8,
    "target_modules": ["q_proj", "v_proj"]
}

# Fine-tune
factory.fine_tune(
    model_path="llama-3-8b",
    data_path="training_data.json",
    config=config
)
```

### GitHub Repository

**â­ 17k+ Stars**: <https://github.com/hiyouga/LLaMA-Factory>

**Why It's Popular**:
- User-friendly GUI
- Comprehensive features
- Active community
- Regular updates
- Excellent documentation

### Key Takeaways

*Retrieve:* LlaMA-Factory provides a comprehensive, user-friendly solution for LLM fine-tuning, supporting multiple models, methods, and deployment options.

*Innovate:* By leveraging LlaMA-Factory's GUI and advanced features, you can efficiently fine-tune models for your specific use cases without extensive coding.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about fine-tuning, retrieve knowledge through LlaMA-Factory's tools, and innovate by creating specialized models for your applications.

**Next Steps**:
- Explore the GitHub repository
- Try the GUI interface
- Experiment with different methods
- Deploy your fine-tuned models

ğŸš¨ I share #genai content daily, follow along for the latest updates! #llms #finetuning ( from [Aishwarya Naresh Reganti](https://www.linkedin.com/in/areganti/recent-activity/all/))

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

### ğŸŠ LLMì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ ì²˜ìŒì´ê³  GUI ê¸°ë°˜ ë˜ëŠ” ë¡œìš° ì½”ë“œ ì ‘ê·¼ ë°©ì‹ì„ ì„ í˜¸í•˜ëŠ” ê²½ìš° LlaMA-FactoryëŠ” ìµœê³ ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤!

ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¯¸ì„¸ ì¡°ì • ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ë³´ì•˜ê³  LlaMA Factoryë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì •ë§ ì¦ê±°ì› ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì¹œí™”ì ì¸ GUI ì˜µì…˜(ë‹¨ì¼ GPU ì‚¬ìš© ì‚¬ë¡€ì— ì í•©)ì´ ìˆì–´ ëª‡ ë²ˆì˜ í´ë¦­ë§Œìœ¼ë¡œ ë§¤ìš° ì‰½ê²Œ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ë¥¸ ë©‹ì§„ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

+ ğŸŒ ë‹¤ì–‘í•œ LLM ì§€ì› 
  + LLaMA, Mistral, Mixtral-MoE, Qwen, Gemma ë“±ì˜ ëª¨ë“  ë²„ì „ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤. 

+ ğŸ›  íŠœë‹ ë°©ë²•
  + ì§€ì†ì ì¸ ì‚¬ì „ í•™ìŠµ, ì§€ë„ ë¯¸ì„¸ ì¡°ì •, ë³´ìƒ ëª¨ë¸ë§, PPO, DPO ë° ORPO(Online Reinforcement Policy Optimization)ë¥¼ í¬í•¨í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •ì„ ìœ„í•œ í¬ê´„ì ì¸ í†µí•© ë°©ë²• ì œí’ˆêµ°ì„ ì œê³µí•©ë‹ˆë‹¤. 

+ ğŸ” PEFT ë°©ë²• & ì–‘ìí™”
  + 32ë¹„íŠ¸ í’€ íŠœë‹ ë° 16ë¹„íŠ¸ ë™ê²° íŠœë‹, 16ë¹„íŠ¸ LoRA ë° 2/4/8ë¹„íŠ¸ QLoRA ë“±ê³¼ ê°™ì€ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” PEFT ì ‘ê·¼ ë°©ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤! 

+ ğŸ“ˆ ê³ ê¸‰ ë¯¸ì„¸ ì¡°ì • ì ‘ê·¼ ë°©ì‹
  + GaLore, BAdam, DoRA, LongLoRA Mixture-of-Depths, LoRA+, LoftQ ë° Agent Tuningê³¼ ê°™ì€ ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì•Œê³ ë¦¬ì¦˜ì€ ë¯¸ì„¸ ì¡°ì • ì¤‘ì— ëª¨ë¸ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.

+ ğŸ§ â™€ï¸ ì‹¤ìš©ì ì¸ íŠ¸ë¦­
  + FlashAttention-2, Unsloth, RoPE ìŠ¤ì¼€ì¼ë§, NEFTune ë“±ì„ í¬í•¨í•œ ë¯¸ì„¸ ì¡°ì • ê²°ê³¼ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì‹¤ìš©ì ì¸ íŠ¸ë¦­ê³¼ ê¸°ìˆ ì„ í†µí•©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¸ë¦­ì€ ì¼ë°˜ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

+ ğŸ“Š ì‹¤í—˜ ëª¨ë‹ˆí„°
  + LlamaBoard, TensorBoard, Wandb(ê°€ì¤‘ì¹˜ ë° í¸í–¥), MLflow ë“±ì„ í¬í•¨í•œ ì—¬ëŸ¬ ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ë„êµ¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. 

+ ğŸš€ ë” ë¹ ë¥¸ ì¶”ë¡ 
  + vLLM ì‘ì—…ìë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI ìŠ¤íƒ€ì¼ API, Gradio UI ë° CLIë¥¼ í†µí•´ ë” ë¹ ë¥¸ ì¶”ë¡ ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íš¨ìœ¨ì ì¸ ì¶”ë¡  ê¸°ëŠ¥ì„ í†µí•´ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ ì›í™œí•˜ê²Œ ë°°í¬í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

GitHub ì €ì¥ì†Œì—ëŠ” ì´ë¯¸ ì•½ 17ê°œì˜ ë³„ì´ ìˆìŠµë‹ˆë‹¤! ì—¬ê¸°ì—ì„œ í™•ì¸í•˜ì‹­ì‹œì˜¤ : <https://github.com/hiyouga/LLaMA-Factory?tab=readme-ov-file>

</details>
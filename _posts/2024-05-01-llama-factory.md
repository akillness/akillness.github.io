---
title: LLama Factory is one of the best Open-source tools
description: LLM, LLama
categories: [LLM, LLama]
tags: [LLM, LLama, Opensource]
# author: foDev_jeong
date: 2024-05-01 19:57:00 +0800
# mermaid: true
# render_with_liquid: false
image:
  path: /assets/img/news/Llama-factory.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: [LlaMA-Factory is one of the best open-source tools out there]
---

### 🎊 If you're new to fine-tuning LLMs and prefer a GUI based or low-code approach, LlaMA-Factory is one of the best open-source tools out there!

I've been trying out different open-source fine-tuning tools, and I really enjoyed using LlaMA Factory. It has a user-friendly GUI option (suitable for single GPU use-cases) which makes fine-tuning super easy with just a few clicks.

Some other cool features include:

+ 🌐 Diverse LLM Support 
  + Supports a wide range of models, including all versions of LLaMA, Mistral, Mixtral-MoE, Qwen, Gemma and more. 

+ 🛠 Tuning Methods
  + Offers a comprehensive suite of integrated methods for fine-tuning, including continuous pre-training, supervised fine-tuning, reward modeling, PPO , DPO, and ORPO (Online Reinforcement Policy Optimization). 

+ 🔎 PEFT methods & Quantization
  + Supports 32-bit full-tuning and popular PEFT approaches like 16-bit freeze-tuning, 16-bit LoRA, and 2/4/8-bit QLoRA and many more! 

+ 📈 Advanced Fine-Tuning Approaches
  + Implements advanced algorithms such as GaLore, BAdam, DoRA , LongLoRA Mixture-of-Depths, LoRA+, LoftQ and Agent Tuning. These algorithms contribute to improved model performance and efficiency during fine-tuning.

+ 🧝‍♀️ Practical Tricks
  + Incorporates practical tricks and techniques to enhance fine-tuning outcomes, including FlashAttention-2, Unsloth, RoPE scaling, NEFTune and many more. These tricks help address common challenges and optimize model performance in various scenarios.

+ 📊 Experiment Monitors
  + Supports multiple experiment monitoring tools, including LlamaBoard, TensorBoard, Wandb (Weights & Biases), MLflow, and more. 

+ 🚀 Faster Inference
  + Facilitates faster inference through OpenAI-style API, Gradio UI, and CLI with vLLM worker. This enables seamless deployment and usage of fine-tuned models in real-world applications with efficient inference capabilities.

The GitHub repo already has about 17k stars! Go check it out here: <https://lnkd.in/eWW6PgGY>

🚨 I share #genai content daily, follow along for the latest updates! #llms #finetuning ( from [Aishwarya Naresh Reganti](https://www.linkedin.com/in/areganti/recent-activity/all/))


* * *


### 🎊 LLM을 미세 조정하는 것이 처음이고 GUI 기반 또는 로우 코드 접근 방식을 선호하는 경우 LlaMA-Factory는 최고의 오픈 소스 도구 중 하나입니다!

다양한 오픈 소스 미세 조정 도구를 사용해 보았고 LlaMA Factory를 사용하는 것이 정말 즐거웠습니다. 사용자 친화적인 GUI 옵션(단일 GPU 사용 사례에 적합)이 있어 몇 번의 클릭만으로 매우 쉽게 미세 조정할 수 있습니다.

다른 멋진 기능은 다음과 같습니다.

+ 🌐 다양한 LLM 지원 
  + LLaMA, Mistral, Mixtral-MoE, Qwen, Gemma 등의 모든 버전을 포함한 다양한 모델을 지원합니다. 

+ 🛠 튜닝 방법
  + 지속적인 사전 학습, 지도 미세 조정, 보상 모델링, PPO, DPO 및 ORPO(Online Reinforcement Policy Optimization)를 포함하여 미세 조정을 위한 포괄적인 통합 방법 제품군을 제공합니다. 

+ 🔎 PEFT 방법 & 양자화
  + 32비트 풀 튜닝 및 16비트 동결 튜닝, 16비트 LoRA 및 2/4/8비트 QLoRA 등과 같은 널리 사용되는 PEFT 접근 방식을 지원합니다! 

+ 📈 고급 미세 조정 접근 방식
  + GaLore, BAdam, DoRA, LongLoRA Mixture-of-Depths, LoRA+, LoftQ 및 Agent Tuning과 같은 고급 알고리즘을 구현합니다. 이러한 알고리즘은 미세 조정 중에 모델 성능과 효율성을 개선하는 데 기여합니다.

+ 🧝 ♀️ 실용적인 트릭
  + FlashAttention-2, Unsloth, RoPE 스케일링, NEFTune 등을 포함한 미세 조정 결과를 향상시키기 위해 실용적인 트릭과 기술을 통합합니다. 이러한 트릭은 일반적인 문제를 해결하고 다양한 시나리오에서 모델 성능을 최적화하는 데 도움이 됩니다.

+ 📊 실험 모니터
  + LlamaBoard, TensorBoard, Wandb(가중치 및 편향), MLflow 등을 포함한 여러 실험 모니터링 도구를 지원합니다. 

+ 🚀 더 빠른 추론
  + vLLM 작업자를 사용하여 OpenAI 스타일 API, Gradio UI 및 CLI를 통해 더 빠른 추론을 용이하게 합니다. 이를 통해 효율적인 추론 기능을 통해 실제 애플리케이션에서 미세 조정된 모델을 원활하게 배포하고 사용할 수 있습니다.

GitHub 저장소에는 이미 약 17개의 별이 있습니다! 여기에서 확인하십시오 : <https://lnkd.in/eWW6PgGY>
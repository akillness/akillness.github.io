---
title: AutoML Applications, Advantages and Top 30 Libraries ğŸ“š
description: Paper, Libraries, AutoML
categories:
- Development & Tools
tags:
- libraries
- automl
- development-tools
- tools
date: 2024-06-02 23:00:00 +0800
image:
  path: /assets/img/news/AutoML_Top_30_Libraries.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt:
  - AutoML Advantages and Top 30 Libraries
---
AutoML transforms ML workflows, boosting efficiency and innovation. 

* * *

## Application in Data Science

#### 1. Exploratory Data Analysis (EDA)
- â­’ Initial Model Benchmarking
- â­’ Feature Importance

#### 2. Model Development
- â­’ Rapid Prototyping
- â­’ Hyperparameter Tuning

#### 3. Model Selection
- â­’ Comparison of Algorithms

#### 4. Deployment and Production
- â­’ Automated Pipeline Creation
- â­’ Continuous Model Improvement

* * *

### Key Advantages

- âœº Rapid Development: Accelerates the creation and deployment of models.

- âœº Accessibility: Makes machine learning approachable for non-experts.

- âœº Optimized Performance: Enhances model efficacy.

- âœº Error Reduction: Decreases manual errors in model selection and tuning.

- âœº Scalability & Resource Efficiency: Manages large datasets and optimizes computational resources.

- âœº Innovation: Explores more configurations and algorithms.

- âœº Adaptability: Quickly adjusts to new data, ensuring sustained model performance.

* * *

### Python Libraries

#### ğŸ“šAuto-Sklearn 
> Automates scikit-learn model selection and training.

#### ğŸ“šTPOT
> Uses genetic algorithms to optimize machine learning pipelines.

#### ğŸ“šH2O AutoML
> Automates all steps of the machine learning process.

#### ğŸ“šAutoKeras
> Simplifies the use of deep learning models.

#### ğŸ“šMLBox
> Fast data reading and distributed preprocessing.

#### ğŸ“šAuto-ViML
> Minimal coding for high-performance models.

#### ğŸ“šTransmogrifAI
> Automates workflows on Apache Spark.

#### ğŸ“šFLAML
> Finds accurate models with minimal computational cost.

#### ğŸ“šLudwig
> Builds models using configuration files, no coding required.

#### ğŸ“šGAMA
> Flexible AutoML pipeline support.

#### ğŸ“šHyperoptSklearn
> Hyperparameter tuning for sklearn pipelines.

#### ğŸ“šAutoGluon
> Simplifies deep learning tasks.

#### ğŸ“šNNI
> Comprehensive feature engineering and model tuning tools.

#### ğŸ“šPyCaret
> Low-code library that automates the ML workflow.

#### ğŸ“šMerlion
> Focuses on time series machine learning.

#### ğŸ“šZenML
> Builds production-ready MLOps pipelines.

#### ğŸ“šAuto-PyTorch
> Automated architecture and hyperparameter optimization for PyTorch.

#### ğŸ“šStatsforecast
> Fast forecasting for statistical models.

#### ğŸ“šAdanet
> Automates learning of neural networks.

#### ğŸ“šIgel
> Enables model operations without coding.

#### ğŸ“šMLJAR Supervised
> Automates ML tasks on tabular data.

#### ğŸ“šKeras Tuner
> Hyperparameter tuning for Keras.

#### ğŸ“šLazy Predict
> Quickly builds and compares basic models.

#### ğŸ“šSparseML
> Creates smaller, faster neural networks.

#### ğŸ“šPySR
> Python and Julia-based symbolic regression.

#### ğŸ“šMetarank
> Personalizes rankings with machine learning.

#### ğŸ“šAutoML-Zero
> Evolves ML algorithms from scratch.

#### ğŸ“šAutoML for Images
> Specializes in automating image data workflows.

#### ğŸ“šNNI
> Integrates with ML frameworks for comprehensive automation.

#### ğŸ“šAutoGL
> Tackles graph-based problems with automation.


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

AutoMLì€ ML ì›Œí¬í”Œë¡œë¥¼ í˜ì‹ í•˜ì—¬ íš¨ìœ¨ì„±ê³¼ í˜ì‹ ì„ ì´‰ì§„í•©ë‹ˆë‹¤. 

* * *

## ë°ì´í„° ê³¼í•™ì˜ ì‘ìš©

#### 1. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
- â­’ ì´ˆê¸° ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹
- â­’ ê¸°ëŠ¥ ì¤‘ìš”ë„

#### 2. ëª¨ë¸ ê°œë°œ
- â­’ ì‹ ì†í•œ í”„ë¡œí†  íƒ€ì´í•‘
- â­’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

#### 3. ëª¨ë¸ ì„ íƒ
- â­’ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ

#### 4. ë°°í¬ ë° ìƒì‚°
- â­’ ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ ìƒì„±
- â­’ ì§€ì†ì ì¸ ëª¨ë¸ ê°œì„ 

* * *

#### í•µì‹¬ ì¥ì 

- âœº ì‹ ì†í•œ ê°œë°œ: ëª¨ë¸ì˜ ìƒì„± ë° ë°°í¬ë¥¼ ê°€ì†í™”í•©ë‹ˆë‹¤.

- âœº ì ‘ê·¼ì„±: ë¹„ì „ë¬¸ê°€ë„ ê¸°ê³„ í•™ìŠµì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- âœº ìµœì í™”ëœ ì„±ëŠ¥: ëª¨ë¸ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

- âœº ì˜¤ë¥˜ ê°ì†Œ: ëª¨ë¸ ì„ íƒ ë° íŠœë‹ì—ì„œ ìˆ˜ë™ ì˜¤ë¥˜ë¥¼ ì¤„ì…ë‹ˆë‹¤.

- âœº í™•ì¥ì„± ë° ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±: ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ë¥¼ ê´€ë¦¬í•˜ê³  ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.

- âœº í˜ì‹ : ë” ë§ì€ êµ¬ì„±ê³¼ ì•Œê³ ë¦¬ì¦˜ì„ íƒìƒ‰í•©ë‹ˆë‹¤.

- âœº ì ì‘ì„±: ìƒˆë¡œìš´ ë°ì´í„°ì— ë¹ ë¥´ê²Œ ì ì‘í•˜ì—¬ ì§€ì†ì ì¸ ëª¨ë¸ ì„±ëŠ¥ì„ ë³´ì¥í•©ë‹ˆë‹¤.

* * *

### Python ë¼ì´ë¸ŒëŸ¬ë¦¬

#### ğŸ“šAuto-Sklearn
> scikit-learn ëª¨ë¸ ì„ íƒ ë° í•™ìŠµì„ ìë™í™”í•©ë‹ˆë‹¤.

#### ğŸ“šTPOT
> ìœ ì „ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ê³„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ìµœì í™”í•©ë‹ˆë‹¤.

#### ğŸ“šH2O AutoML
> ê¸°ê³„ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ìë™í™”í•©ë‹ˆë‹¤.

#### ğŸ“šAutoKeras
> ë”¥ ëŸ¬ë‹ ëª¨ë¸ì˜ ì‚¬ìš©ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.

#### ğŸ“šMLBox 
> ë¹ ë¥¸ ë°ì´í„° ì½ê¸° ë° ë¶„ì‚° ì „ì²˜ë¦¬.

#### ğŸ“šAuto-ViML
> ê³ ì„±ëŠ¥ ëª¨ë¸ì„ ìœ„í•œ ìµœì†Œí•œì˜ ì½”ë”©.

#### ğŸ“šTransmogrifAI
> Apache Sparkì—ì„œ ì›Œí¬í”Œë¡œë¥¼ ìë™í™”í•©ë‹ˆë‹¤.

#### ğŸ“šFLAML
> ìµœì†Œí•œì˜ ê³„ì‚° ë¹„ìš©ìœ¼ë¡œ ì •í™•í•œ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.

#### ğŸ“šLudwig
> ì½”ë”©ì´ í•„ìš” ì—†ëŠ” êµ¬ì„± íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¹Œë“œí•©ë‹ˆë‹¤.

#### ğŸ“šGAMA
> ìœ ì—°í•œ AutoML íŒŒì´í”„ë¼ì¸ ì§€ì›.

#### ğŸ“šHyperoptSklearn
> sklearn íŒŒì´í”„ë¼ì¸ì— ëŒ€í•œ í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜ íŠœë‹.

#### ğŸ“šAutoGluon
> ë”¥ëŸ¬ë‹ ì‘ì—…ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.

#### ğŸ“šMNI
> í¬ê´„ì ì¸ ê¸°ëŠ¥ ì—”ì§€ë‹ˆì–´ë§ ë° ëª¨ë¸ íŠœë‹ ë„êµ¬.

#### ğŸ“šPyCaret
> ML ì›Œí¬í”Œë¡œë¥¼ ìë™í™”í•˜ëŠ” ë¡œìš° ì½”ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

#### ğŸ“šMerlion
> ì‹œê³„ì—´ ê¸°ê³„ í•™ìŠµì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

#### ğŸ“šZenML
> í”„ë¡œë•ì…˜ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” MLOps íŒŒì´í”„ë¼ì¸ì„ ë¹Œë“œí•©ë‹ˆë‹¤.

#### ğŸ“šAuto-PyTorch
> PyTorchë¥¼ ìœ„í•œ ìë™í™”ëœ ì•„í‚¤í…ì²˜ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”.

#### ğŸ“šStatsforecase
> í†µê³„ ëª¨ë¸ì— ëŒ€í•œ ë¹ ë¥¸ ì˜ˆì¸¡.

#### ğŸ“šAdanet
> ì‹ ê²½ë§ í•™ìŠµì„ ìë™í™”í•©ë‹ˆë‹¤.

#### ğŸ“šIgel
> ì½”ë”© ì—†ì´ ëª¨ë¸ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ğŸ“šMLJAR Supervised
> í…Œì´ë¸” í˜•ì‹ ë°ì´í„°ì— ëŒ€í•œ ML ì‘ì—…ì„ ìë™í™”í•©ë‹ˆë‹¤.

#### ğŸ“šKeras Tuner
> Kerasì— ëŒ€í•œ í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜ íŠœë‹.

#### ğŸ“šLazy Predict
> ê¸°ë³¸ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ë¹Œë“œí•˜ê³  ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ğŸ“šSparseML
> ë” ì‘ê³  ë¹ ë¥¸ ì‹ ê²½ë§ì„ ë§Œë“­ë‹ˆë‹¤.

#### ğŸ“šPySR
> Python ë° Julia ê¸°ë°˜ ê¸°í˜¸ íšŒê·€.

#### ğŸ“šMetarank
> ê¸°ê³„ í•™ìŠµìœ¼ë¡œ ìˆœìœ„ë¥¼ ê°œì¸í™”í•©ë‹ˆë‹¤.

#### ğŸ“šAutoML-ì œë¡œ
> ML ì•Œê³ ë¦¬ì¦˜ì„ ì²˜ìŒë¶€í„° ë°œì „ì‹œí‚µë‹ˆë‹¤.

#### ğŸ“šì´ë¯¸ì§€ìš© AutoML
> ì´ë¯¸ì§€ ë°ì´í„° ì›Œí¬í”Œë¡œìš° ìë™í™”ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•©ë‹ˆë‹¤.

#### ğŸ“šMNI
> í¬ê´„ì ì¸ ìë™í™”ë¥¼ ìœ„í•´ ML í”„ë ˆì„ì›Œí¬ì™€ í†µí•©ë©ë‹ˆë‹¤.

#### ğŸ“šAutoGL
> ìë™í™”ë¥¼ í†µí•´ ê·¸ë˜í”„ ê¸°ë°˜ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤

</details>
---
title: Release Chameleon Model
description: LLM, Chameleon
categories: [Script, Chameleon]
tags: [Chameleon, LLM]
# author: foDev_jeong
date: 2024-05-25 22:40:00 +0800
# mermaid: true
# render_with_liquid: false
image:
  path: /assets/img/llm/LLM_chameleon.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: [ Chameleon Architecture ]
---


## Chameleon: Mixed-Modal Early-Fusion Foundation Models

Will Chameleon be [Meta](https://www.linkedin.com/company/meta/) Llama 4? ğŸ¦ ğŸ¦™ Meta proposes â€œChameleon: Mixed-Modal Early-Fusion Foundation Modelsâ€ with a unified approach for fully token-based representations of both image and text. No Encoders or connectors. ğŸ‘€

### Implementation:
- 1ï¸âƒ£ Trained 2 tokenizers, an image Tokenizer that encodes a 512 Ã— 512 image into 1024 tokens from a codebook (8192) and a BPE with a vocab of 65,536, which includes the 8192 image codebook token.
- 2ï¸âƒ£ uses a Decoder architecture based on Llama 2 but incorporates query-key normalization and reordering of layer norms to stabilize training in the mixed-modal setting.
- 3ï¸âƒ£ Pretraining stage 1 (80%) unsupervised training on text-only (Llama 2, CodeLlama â‡’ 2.9T tokens), text-image (1.4B pairs/1.5T tokens), Text/Image Interleaved (400B tokens);
- 4ï¸âƒ£ Pretraining stage 2 (20%) Halved the dataset of first stage and include higher quality data and instruction data.
- 5ï¸âƒ£ Fine-tuned on ~1.8 million samples with ~100k vision samples.

### Insights:
- ğŸ”— Previous MLLM (Idefics, GPT-4v, Flamingo) used encoders and connectors for multimodality, which limited their ability to generate multimodal documents (image + text outputs).
- ğŸ¦ Chameleon can understand and generate both text and images using discrete tokens
- ğŸ“š Chameleon-34B trained for 2.1 epochs over our full training dataset for a total of 9.2T tokens.
- ğŸ”§ Code Data improved text-only reasoning tasks performance.
- âš–ï¸ Challenging to maintain stable training when scaling the Chameleon models above 8B parameters and 1T tokens.
- ğŸš€ The last 20% of pre-training with high-quality data significantly boosted performance.
- ğŸ† Chameleon-34B outperforms Llama2-70B and approaches Mixtral 8x7B/Gemini-Pro, GSM8K, MATH, and MMLU.
- ğŸ“Š Chameleon-34B outperforms Flamingo-80B and IDEFICS-80B on MS-COCO and matches on Flickr30k.
- ğŸ¯ Chameleon-34B achieves 60.4% win rate against Gemini-Pro and a 51.6% against GPT-4V.
- âš–ï¸ Balanced modality datasets are important for Fine-tuning and Alignment.

> Paper: <https://huggingface.co/papers/2405.09818>
{: .prompt-info }

Note: Chameleon looks to be closer to [OpenAI](https://www.linkedin.com/company/openai/) GPT-4o than Uni-MoE (shared yesterday) with its native multi-modal tokens. ğŸ’¡


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## Chameleon: Mixed-Modal Early-Fusion Foundation Models

ì¹´ë©œë ˆì˜¨ì€ ë¼ë§ˆ 4Meta ë ê¹Œìš”? ğŸ¦ ğŸ¦™ [Meta](https://www.linkedin.com/company/meta/)ëŠ” ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ëª¨ë‘ë¥¼ ì™„ì „íˆ í† í° ê¸°ë°˜ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•œ í†µí•© ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ "Chameleon: Mixed-Modal Early-Fusion Foundation Models"ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì¸ì½”ë” ë˜ëŠ” ì»¤ë„¥í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ‘€

### Implementation:
- 1ï¸âƒ£ í›ˆë ¨ëœ 2ê°œì˜ í† í¬ë‚˜ì´ì €, 512 Ã— 512 ì´ë¯¸ì§€ë¥¼ ì½”ë“œë¶(8192)ì—ì„œ 1024ê°œì˜ í† í°ìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” ì´ë¯¸ì§€ í† í¬ë‚˜ì´ì €ì™€ 8192 ì´ë¯¸ì§€ ì½”ë“œë¶ í† í°ì„ í¬í•¨í•˜ëŠ” 65,536ì˜ ì–´íœ˜ë¥¼ ê°€ì§„ BPE.
- 2ï¸âƒ£ëŠ” Llama 2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë””ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ì¿¼ë¦¬ í‚¤ ì •ê·œí™” ë° ë ˆì´ì–´ ê·œë²”ì˜ ì¬ì •ë ¬ì„ í†µí•©í•˜ì—¬ í˜¼í•© ëª¨ë‹¬ ì„¤ì •ì—ì„œ í›ˆë ¨ì„ ì•ˆì •í™”í•©ë‹ˆë‹¤.
- 3ï¸âƒ£ í…ìŠ¤íŠ¸ ì „ìš©(Llama 2, CodeLlama â‡’ 2.9T í† í°), í…ìŠ¤íŠ¸ ì´ë¯¸ì§€(1.4B ìŒ/1.5T í† í°), í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì¸í„°ë¦¬ë¸Œ(400B í† í°)ì— ëŒ€í•œ ì‚¬ì „ í•™ìŠµ 1ë‹¨ê³„(80%);
- 4ï¸âƒ£ ì‚¬ì „ í•™ìŠµ 2ë‹¨ê³„ (20%) ì²« ë²ˆì§¸ ë‹¨ê³„ì˜ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ê³  ë” ë†’ì€ í’ˆì§ˆì˜ ë°ì´í„°ì™€ ì§€ì¹¨ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
- 5ï¸âƒ£ ~100k ë¹„ì „ ìƒ˜í”Œë¡œ ~180ë§Œ ê°œì˜ ìƒ˜í”Œì— ë¯¸ì„¸ ì¡°ì •.

### Insights:
- ğŸ”— ì´ì „ MLLM(Idefics, GPT-4v, Flamingo)ì€ ë©€í‹°ëª¨ë‹¬ë¦¬í‹°ë¥¼ ìœ„í•´ ì¸ì½”ë”ì™€ ì»¤ë„¥í„°ë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ(ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ì¶œë ¥)ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤.
- ğŸ¦ ì¹´ë©œë ˆì˜¨ì€ ê°œë³„ í† í°ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ğŸ“š Chameleon-34BëŠ” ì´ 9.2T í† í°ì— ëŒ€í•´ ì „ì²´ í›ˆë ¨ ë°ì´í„° ì„¸íŠ¸ì—ì„œ 2.1 epoch ë™ì•ˆ í›ˆë ¨í–ˆìŠµë‹ˆë‹¤.
- ğŸ”§ ì½”ë“œ ë°ì´í„°ëŠ” í…ìŠ¤íŠ¸ ì „ìš© ì¶”ë¡  ì‘ì—… ì„±ëŠ¥ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
- âš–ï¸ ì¹´ë©œë ˆì˜¨ ëª¨ë¸ì„ 8B ë§¤ê°œë³€ìˆ˜ ë° 1T í† í° ì´ìƒìœ¼ë¡œ í™•ì¥í•  ë•Œ ì•ˆì •ì ì¸ í›ˆë ¨ì„ ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤.
- ğŸš€ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì‚¬ì „ í•™ìŠµì˜ ë§ˆì§€ë§‰ 20%ëŠ” ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.
- ğŸ† Chameleon-34BëŠ” Llama2-70Bë¥¼ ëŠ¥ê°€í•˜ë©° Mixtral 8x7B/Gemini-Pro, GSM8K, MATH ë° MMLUì— ê·¼ì ‘í•©ë‹ˆë‹¤.
- ğŸ“Š Chameleon-34BëŠ” MS-COCOì—ì„œ Flamingo-80B ë° IDEFICS-80Bë¥¼ ëŠ¥ê°€í•˜ë©° Flickr30kì—ì„œë„ ì¼ì¹˜í•©ë‹ˆë‹¤.
- ğŸ¯ Chameleon-34BëŠ” Gemini-Proë¥¼ ìƒëŒ€ë¡œ 60.4%, GPT-4Vë¥¼ ìƒëŒ€ë¡œ 51.6%ì˜ ìŠ¹ë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.
- âš–ï¸ ê· í˜• ì¡íŒ ëª¨ë‹¬ë¦¬í‹° ë°ì´í„° ì„¸íŠ¸ëŠ” ë¯¸ì„¸ ì¡°ì • ë° ì •ë ¬ì— ì¤‘ìš”í•©ë‹ˆë‹¤.

> Paper: <https://huggingface.co/papers/2405.09818>
{: .prompt-info }

ì°¸ê³ : ì¹´ë©œë ˆì˜¨ì€ ê¸°ë³¸ ë©€í‹°ëª¨ë‹¬ í† í°ì´ ìˆëŠ” Uni-MoE(ì–´ì œ ê³µìœ )ë³´ë‹¤ [OpenAI](https://www.linkedin.com/company/openai/) GPT-4oì— ë” ê°€ê¹Œì›Œ ë³´ì…ë‹ˆë‹¤. ğŸ’¡

</details>
---
title: ğ‹ğ‹ğŒ ğ‘ğ€ğ† ğğğ¬ğ­ ğğ«ğšğœğ­ğ¢ğœğğ¬
description: Rag, Practices
categories: [LLM, RAG]
tags: [RAG, Practices]
# author: foDev_jeong
date: 2024-07-04 22:10:00 +0800
pin: true
# math: true
mermaid: true
image:
  path: /assets/img/llm/The-Evolution-of-RAG-Models.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: [ The Evolution of RAG Models ]
---

## Generative large language models are prone to producing outdated information or fabricating facts.

*Curiosity:* Retrieval-augmented generation (RAG) techniques address the LLM limitations by integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains.



### ğŸ˜… The pace of RAG research is super impressive, but not all of it is practical for real-world use cases. 

*Curiosity:* What insights can we retrieve from this? How does this connect to innovation in the field?

Many latest research works seek to improve performance over basic RAG architectures, however, they struggle with complex implementation and long response times.

This new paper investigates existing RAG approaches and their potential combinations to identify optimal practices. Through extensive experiments, the authors suggest several strategies for deploying RAG that balance both performance and efficiency.

The infographic in itself (below) is extremely useful too. It breaks down the pipeline into smaller stages and lists methods for each stage.

> - Github : <https://github.com/FudanDNN-NLP/RAG>
> - Paper : <https://arxiv.org/pdf/2407.01219>
{: .prompt-info}

### ğ‘ğ€ğ† ğ–ğ¨ğ«ğ¤ğŸğ¥ğ¨ğ°

A typical RAG workflow usually contains multiple intervening processing steps: 
- ğ’’ğ’–ğ’†ğ’“ğ’š ğ’„ğ’ğ’‚ğ’”ğ’”ğ’Šğ’‡ğ’Šğ’„ğ’‚ğ’•ğ’Šğ’ğ’ (determining whether retrieval is necessary for a given input query), 
- ğ’“ğ’†ğ’•ğ’“ğ’Šğ’†ğ’—ğ’‚ğ’ (efficiently obtaining relevant documents for the query), 
- ğ’“ğ’†ğ’“ğ’‚ğ’ğ’Œğ’Šğ’ğ’ˆ (refining theorder of retrieved documents based on their relevance to the query), 
- ğ’“ğ’†ğ’‘ğ’‚ğ’„ğ’Œğ’Šğ’ğ’ˆ (organizing the retrieved documents into a structured one for better generation), 
- ğ’”ğ’–ğ’ğ’ğ’‚ğ’“ğ’Šğ’›ğ’‚ğ’•ğ’Šğ’ğ’ (extracting key information for response generation from the repacked document and eliminating redundancies)

### ğ‘ğ€ğ† ğ›ğğ¬ğ­ ğ©ğ«ğšğœğ­ğ¢ğœğğ¬

- ğ‘©ğ’†ğ’”ğ’• ğ‘·ğ’†ğ’“ğ’‡ğ’ğ’“ğ’ğ’‚ğ’ğ’„ğ’† ğ‘·ğ’“ğ’‚ğ’„ğ’•ğ’Šğ’„ğ’† : To achieve the highest performance, it is recommended to incorporate query classification module, use the â€œHybrid with HyDEâ€ method for retrieval, employ monoT5 for reranking, opt for Reverse for repacking, and leverage Recomp for summarization

- ğ‘©ğ’‚ğ’ğ’‚ğ’ğ’„ğ’†ğ’… ğ‘¬ğ’‡ğ’‡ğ’Šğ’„ğ’Šğ’†ğ’ğ’„ğ’š ğ‘·ğ’“ğ’‚ğ’„ğ’•ğ’Šğ’„ğ’†: In order to achieve a balance between performance and efficiency, it is recommended to incorporate the query classification module, implement the Hybrid method for retrieval, use TILDEv2 for reranking, opt for Reverse for repacking, and employ Recomp for
summarization.

RAG Best Practices paper details (refer to the comments)

![ LLM RAG Best Practices ](/assets/img/llm/LLM_RAG_Best_Practices.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }


### Let's understand RAG with a simple workflow.

{% include embed/youtube.html id='TNUbBPdbsLA' %}

RAG can help prevent hallucinations by providing LLMs with the most recent proprietary and contextual data, allowing them to generate a response based on both their inherent external knowledge and up-to-date internal data. 

This approach can improve accuracy and reduce hallucinations.

* * *

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > The vector database space  </summary>

![ The Vector DB Landscape ](/assets/img/llm/The-Vector-DB-Landscape.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

## ğŸ”Š The vector database space is populated with numerous players! How do you choose the best one for your use-case?

ğŸš€ In the last year, there has been a huge surge in the variety of vector database options. I've compiled the most popular ones in the image below, although it may not encompass the entire list.


ğŸ˜µ With such a large number of options, how do you navigate and discover the ideal one for your needs?
ğŸ’¡ Keep in mind that there isn't a one-size-fits-all "best" vector databaseâ€”selecting the right one depends on your unique requirements

Here are some factors to consider:

### ğŸ“ˆ Scalability
Scalability is crucial for determining a vector database's ability to effectively handle rapidly expanding data volumes. 

Evaluating scalability involves considering factors such as load balancing, multiple replications, and the database's ability to handle high-dimensional data and growing query loads over time.

### ğŸ† Performance
Performance is crucial in assessing vector databases, using metrics like QPS, recall and latency. Benchmark tools like ANN-Benchmark and VectorDBBench offer comprehensive evaluations.

### ğŸ’° Cost
Factor in the total cost of ownership, encompassing licensing fees, cloud hosting charges, and associated infrastructure costs. A cost-effective system should deliver satisfactory speed and accuracy at a reasonable price.

### âœ Developer Experience
Evaluate the ease of setup, documentation clarity, and availability of SDKs for smooth development. Ensure compatibility with preferred cloud providers, LLMs, and seamless integration with existing infrastructure.

### ğŸ“² Support and Ops
Ensure your provider meets security and compliance standards while offering expertise tailored to your needs. Confirm their availability and technical support, and assess their monitoring capabilities for efficient database management.

### ğŸ’« Additional Features
Various vector databases differ in their feature offerings, influencing your decision-making process depending on your application's long-term objectives. For example, while most vector databases support features like multi-tenant and disk index, only a few support ephemeral indexing. However, you might require only specific features from this subset for your application.

Even after factoring in these considerations, it may still be necessary to conduct individual research on each option.

ğŸ“– For example, some commonly known information:

- â›³ Pinecone is well known for efficiently handling extensive collections of vectors, particularly in NLP and computer vision applications, but is a bit on the pricier side.
- â›³ Qdrant is an pretty lightweight and works best for geospatial data.
- â›³ Milvus is an is optimized for large-scale ML applications and excels in building search systems
- â›³ pgvector is the most straightforward choice if you have a Postgres database 


and so on!

</details>

* * *

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

ğŸ“š 'RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ í¬ê´„ì  ì—°êµ¬' - RAGì˜ ì´ì •ë¦¬

ğŸ” ì´ ë…¼ë¬¸ì˜ í•µì‹¬ í¬ì¸íŠ¸:
- RAG ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ëª¨ë“ˆë³„ë¡œ ìƒì„¸ ë¶„ì„
- ê° ëª¨ë“ˆ(ê²€ìƒ‰, ì¬ìˆœìœ„í™”, ìš”ì•½ ë“±)ì˜ ìµœì  êµ¬í˜„ ë°©ë²• ì œì‹œ
- ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì—ì„œ RAG ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ê³µê°œ
- ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ëª¨ë‘ ê³ ë ¤í•œ ìµœì  êµ¬í˜„ ì „ëµ ì œì•ˆ
- ë©€í‹°ëª¨ë‹¬ RAGë¡œì˜ í™•ì¥ ê°€ëŠ¥ì„± íƒêµ¬
- ìƒì„±ê¸° ë¯¸ì„¸ì¡°ì •ì„ ìœ„í•œ ìµœì ì˜ ì ‘ê·¼ë²• ì œì‹œ

ğŸ’¡ ì´ëŸ° ë¶„ë“¤ì—ê²Œ ì¶”ì²œí•©ë‹ˆë‹¤:
- AI ê°œë°œì: RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì‹œ ì‹¤ì§ˆì  ê°€ì´ë“œë¼ì¸ì„ ì–»ê³  ì‹¶ì€ ë¶„
- ì—°êµ¬ì: RAGì˜ ìµœì‹  íŠ¸ë Œë“œì™€ ì„±ëŠ¥ ê°œì„  ë°©ë²•ì„ íŒŒì•…í•˜ê³  ì‹¶ì€ ë¶„
- ê¸°ì—… ì˜ì‚¬ê²°ì •ì: RAG ë„ì…ì„ ê³ ë ¤ ì¤‘ì´ì‹  ë¶„

ğŸ¤” RAGì— ê´€ì‹¬ ìˆëŠ” ëª¨ë“  ë¶„ë“¤ì´ ì¢‹ì•„í• ë§Œí•œ ì •ë¦¬ê°€ ë˜ì–´ìˆëŠ”ë°ìš”. ë§ì€ ê¸°ì—…ì—ì„œ ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆëŠ” ë§Œí¼ ì¢‹ì€ ìë£Œë¼ê³  ìƒê°í•´ì„œ ê³µìœ í•©ë‹ˆë‹¤. 

</details>
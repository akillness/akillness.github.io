---
title: Pytorch 로 VAE 짜보기
description: pytorch, vae, concept
categories: [Blogging, Pytorch, VAE]
tags: [VAE, study, PoC, Pytorch]
author: foDev_jeong
date: 2024-04-17 15:10:00 +0800
# pin: true
# math: true
# mermaid: true
# image:
#   path: /assets/img/cover/programming.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [2024 programming curriculum by honglab]
---

VAE ( Variable Auto Encoder ) 의 개념 구조를 파악하면서 코드를 짜보려고 한다. Pytorch 의 버전업 2.x 에 따라서, 동적 그래프 생성 방식의 구조 및 코드 구조에도 많은 변화가 있었다. Tensorflow 와 경쟁적으로 효율적인 구조를 따라하면서 점차 사용성이 좋아지고 있는 것인데, 흐름을 따라 모델을 코드화 하는 방법 중 이번의 경우는 VAE 를 짜본다. 

<h3>개념정리</h3>

+ VAE는 q(z∣x)을 학습하는 encoder, z, 그리고 p(x∣z)를 학습하는 decoder로 이루어져 있으며, encoder의 output과 decoder의 input에서 reparametrization trick이 사용된다.
  + Encoder는 이미지 또는 입력데이터를 차원축소 ( downsampling ) 하여 입력 feature(z) 의 분포를 학습하는 것
  + Decoder는 feature의 분포로부터 upsampling하여 입력 feature를 reconstruction 를 학습하는 것
+ 참고 : [https://velog.io/@iissaacc/Upsampling](https://velog.io/@iissaacc/Upsampling)
  + 다시 정리해야지
 

{: .box-success}
**용어정리**
+ z: Discrete latent random variable (latent space)
+ q(z∣x): input x의 posterior distribution(x가 주어졌을 때 z의 distribution)
+ p(z): Prior distribution
+ p(x∣z): input x의 true distribution(z가 주어졌을 때 x의 distribution) 



{: .box-note}
**Note:** 항시 마인드 셋을 갖고, 새롭게 도전전하는 일에 대해 "왜?" 해야하는지 스스로의 동기가 필요합니다 :D

아래의 코드는 residual convolution layer을 두어 vanila VAE 보다 성능이 좋은 모델을 짜보는 중이다. 

VQ-VAE 와 Residual-VAE 샘플 테스트 

<h3>Vector Quantization</h3>

![VQ-VAE](/assets/img/vae/vq-vae.png)
VQ-VAE는 Autoencoder 구조에 discrete 한 codebook을 더했습니다. Codebook은 기본적으로 벡터를 요소로 가지는 리스트입니다. Encoder의 출력으로 어떤 벡터가 나오면, codebook의 모든 벡터들 간 거리를 계산합니다. Codebook의 벡터들 중 encoder의 출력 벡터와 가장 거리가 짧은 벡터를 찾습니다. 그리고 그 벡터를 decoder에 넣어 학습합니다.

VAE에 vector quantisation(VQ) 방식을 추가하여, p(z)는 discrete latent variables로 학습되고 p(z)에서 추출된 embedding vector는 decoder를 통과합니다.

__prior__
VQ-VAE 논문에서는 Discrete latents p(z)에 대한 prior distribution은 categorical distribution이며, feature map의 다른 z에 따라 autoregressive하게 만들수 있습니다.
본 논문에서는 image에서 PixelCNN, raw audio에서 WaveNet을 사용합니다.

**실제 구동 코드는 Github** 

+ [VQ-VAE](https://github.com/akillness/SPTTC/blob/main/vq_vae.py)
+ [Residual-VAE](https://github.com/akillness/SPTTC/blob/main/vae_residual.py)


<h4> 참고 </h4>

+ 개념 VAE : [https://avandekleut.github.io/vae/](https://avandekleut.github.io/vae/)
+ 응용 VAE : [https://github.com/awjuliani/DeepRL-Agents/blob/master/Vanilla-Policy.ipynb](https://github.com/awjuliani/DeepRL-Agents/blob/master/Vanilla-Policy.ipynb)
+ 개념 VQ-VAE 
  + [https://nrhan.tistory.com/entry/VQ-VAE%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4](https://nrhan.tistory.com/entry/VQ-VAE%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4)
  + [https://velog.io/@dien-eaststar/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-SSL-Neural-Discrete-Representation-Learning](https://velog.io/@dien-eaststar/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-SSL-Neural-Discrete-Representation-Learning)

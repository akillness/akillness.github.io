---
title: Llama 3 implemented in pure NumPy
description: Llama, Numpy
categories: [LLM, LLama]
tags: [Llama, Numpy]
# author: foDev_jeong
date: 2024-05-18 15:20:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## ğŸ¦™ Llama 3 implemented in pure NumPy ğŸ‘©â€ğŸ”¬

ğŸš€ Exciting discovery! Came across a fascinating article on Llama 3 model implemented in NumPy, inspired by @Andrej Karpathy. The Llama 3 model at AI at Meta is making waves with its impressive scale and performance. ğŸŒŸ

ğŸ§‘â€ğŸ’» Code : <https://github.com/likejazz/llama3.np>

ğŸ” With 24K GPUs, 15T training data, 10M instruction data, and 1.3M GPU hours, the numbers are truly overwhelming. Despite the transition to using GQA, the model structure remains unchanged from Llama 2, making it a familiar yet powerful framework.

ğŸ§  To enhance understanding, Author are focusing on an accurate implementation using NumPy. Leveraging the stories15M model trained by Andrej Karpathy, we're converting it to a NumPy compressed format for a more intuitive model structure. Stay tuned as we transform the Karpathy-trained Llama 2 model into executable code, maintaining clarity and precision in our approach.

ğŸ“Š While incorporating GQA into our code, Author won't apply it to model behavior, ensuring a seamless implementation of NumPy for enhanced interpretability. Stay tuned for more insights into this innovative approach! 


<object data="/assets/img/llm/Llama3_implemeted_in_pure_Numpy.pdf" width="100%" height="450" type='application/pdf'></object>


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

ğŸ¦™ ìˆœìˆ˜ NumPyğŸ‘© ğŸ”¬ë¡œ êµ¬í˜„ëœ ë¼ë§ˆ 3

ğŸš€ í¥ë¯¸ ì§„ì§„í•œ ë°œê²¬! @Andrej Karpathyì—ì„œ ì˜ê°ì„ ë°›ì•„ NumPyì—ì„œ êµ¬í˜„ ëœ Llama 3 ëª¨ë¸ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ê¸°ì‚¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. AI at Meta ì˜ ë¼ë§ˆ 3 ëª¨ë¸ì€ ì¸ìƒì ì¸ ê·œëª¨ì™€ ì„±ëŠ¥ìœ¼ë¡œ íŒŒì¥ì„ ì¼ìœ¼í‚¤ê³  ìˆìŠµë‹ˆë‹¤. ğŸŒŸ

ğŸ§‘ ì½”ë“œ : <https://github.com/likejazz/llama3.np>

ğŸ” 24K GPU, 15T í›ˆë ¨ ë°ì´í„°, 10M ëª…ë ¹ ë°ì´í„° ë° 1.3M GPU ì‹œê°„ì„ ì‚¬ìš©í•˜ë©´ ê·¸ ìˆ˜ì¹˜ëŠ” ì •ë§ ì••ë„ì ì…ë‹ˆë‹¤. GQAë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ì „í™˜í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ëª¨ë¸ êµ¬ì¡°ëŠ” Llama 2ì—ì„œ ë³€ê²½ë˜ì§€ ì•Šì•„ ì¹œìˆ™í•˜ë©´ì„œë„ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ§  ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ì €ìëŠ” NumPyë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•˜ê²Œ êµ¬í˜„í•˜ëŠ” ë° ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. Andrej Karpathyê°€ í›ˆë ¨í•œ stories15M ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë³´ë‹¤ ì§ê´€ì ì¸ ëª¨ë¸ êµ¬ì¡°ë¥¼ ìœ„í•´ NumPy ì••ì¶• í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. Karpathyê°€ í›ˆë ¨í•œ Llama 2 ëª¨ë¸ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¡œ ë³€í™˜í•˜ì—¬ ì ‘ê·¼ ë°©ì‹ì˜ ëª…í™•ì„±ê³¼ ì •ë°€ë„ë¥¼ ìœ ì§€í•˜ëŠ” ë™ì•ˆ ê³„ì† ì§€ì¼œë´ ì£¼ì‹­ì‹œì˜¤.

ğŸ“Š GQAë¥¼ ì½”ë“œì— í†µí•©í•˜ëŠ” ë™ì•ˆ ì‘ì„±ìëŠ” GQAë¥¼ ëª¨ë¸ ë™ì‘ì— ì ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ NumPyë¥¼ ì›í™œí•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì‹ ì ì¸ ì ‘ê·¼ ë°©ì‹ì— ëŒ€í•œ ë” ë§ì€ í†µì°°ë ¥ì„ ê³„ì† ì§€ì¼œë´ ì£¼ì‹­ì‹œì˜¤! 

</details>


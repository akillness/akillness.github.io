---
title: ğŸ•¹ï¸ NVIDIA introduces RankRAG 8B & 70B
description: NVIDIA, RankRAG
categories:
- LLM & Language Models
tags:
- nvidia
- rankrag
- llm
- language-model
date: 2024-07-13 15:00:00 +0800
mermaid: true
---
## RankRAG: NVIDIA's Dual-Purpose Re-Ranker/Generation Models

*Curiosity:* How can a single model handle both context re-ranking and answer generation? What happens when we instruction-tune for both tasks?

**NVIDIA introduces RankRAG 8B & 70B**â€”dual-purpose re-ranker/generation models that outperform GPT-4 across 9 RAG benchmarks.

![ NVIDIA RankRAG ](/assets/img/llm/NVIDIA-RankRAG.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

> **Paper**: <https://arxiv.org/pdf/2407.02485>
{: .prompt-info}

### The Challenge

*Retrieve:* Traditional RAG limitations.

| Problem | Description | Impact |
|:--------|:------------|:-------|
| **Too Many Contexts** | Exceed generation context window | âš ï¸ Truncation |
| **Too Few Contexts** | Poor recall when k is small | âš ï¸ Missing information |
| **Separate Models** | Re-ranker and generator separate | âš ï¸ Complexity |

**Result**: Suboptimal RAG performance.

### RankRAG Solution

*Innovate:* Single model for both tasks.

**Key Innovation**: Instruction-tune a single LLM for both:
- Context re-ranking
- Answer generation

**Benefits**:
- âœ… Identify relevant contexts from larger k
- âœ… Deliver high-quality answers
- âœ… Simplified architecture
- âœ… Better performance

### RankRAG Architecture

*Retrieve:* How RankRAG works.

```mermaid
graph TB
    A[Query] --> B[Dragon Retriever]
    B --> C[Top-K Contexts]
    C --> D[RankRAG Model]
    D --> E[Re-Ranking]
    D --> F[Answer Generation]
    E --> G[Ranked Contexts]
    G --> F
    F --> H[Final Answer]
    
    style A fill:#e1f5ff
    style D fill:#fff3cd
    style H fill:#d4edda
```

### Training Method

*Retrieve:* RankRAG's training process.

| Step | Process | Purpose |
|:-----|:---------|:--------|
| **1. Instruction Tuning** | Multiple datasets (Flan, Dolly) | â¬†ï¸ Base capabilities |
| **2. Data Merging** | Combine instruction, QA, RAG QA, ranking data | â¬†ï¸ Specialized training |
| **3. Fine-Tuning** | Combined specialized datasets | â¬†ï¸ Dual-purpose optimization |
| **4. Evaluation** | Open QA, fact verification, conversational QA | â¬†ï¸ Performance assessment |
| **5. Deployment** | Dragon retriever + RankRAG | â¬†ï¸ Production system |

### Performance Results

*Innovate:* RankRAG's impressive achievements.

**Benchmark Performance**:

| Model | Average Score | vs. GPT-4 |
|:------|:--------------|:----------|
| **GPT-4** | 43.5 | Baseline |
| **RankRAG 8B** | 52.6 | +9.1 points |
| **RankRAG 70B** | 56.1 | +12.6 points |

**Key Achievements**:
- âœ… Surpasses GPT-4 across 9 RAG benchmarks
- âœ… Notable gains over ChatQA 1.5
- âœ… Strong generalization (matches GPT-4 on 5 biomedical benchmarks)
- âœ… Exceeds specialized re-ranking models
- âœ… Significant improvements with just 1% ranking data

### Key Insights

*Retrieve:* What makes RankRAG effective.

| Insight | Description | Impact |
|:--------|:------------|:-------|
| **Dual-Purpose** | Single model for both tasks | â¬†ï¸ Efficiency |
| **Instruction Tuning** | Specialized training data | â¬†ï¸ Performance |
| **Generalization** | Works across domains | â¬†ï¸ Versatility |
| **Data Efficiency** | 1% ranking data helps | â¬†ï¸ Practical |

### Key Takeaways

*Retrieve:* RankRAG demonstrates that a single instruction-tuned LLM can handle both context re-ranking and answer generation, outperforming GPT-4 across 9 RAG benchmarks.

*Innovate:* By training a dual-purpose model with specialized datasets combining instruction, QA, and ranking data, RankRAG achieves superior performance while simplifying the RAG architecture.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about improving RAG performance, retrieve insights from RankRAG's dual-purpose approach, and innovate by implementing unified re-ranking and generation models in your RAG systems.

**Next Steps**:
- Read the full paper
- Understand RankRAG architecture
- Experiment with dual-purpose training
- Deploy RankRAG in your systems

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## 8ê°œì˜ RAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ GPT-4ë¥¼ ëŠ¥ê°€í•˜ëŠ” ì´ì¤‘ ëª©ì  ì¬ë­ì»¤/ìƒì„± ëª¨ë¸ ğŸ‘‡ğŸ‘‡ğŸ‘‡

ê¸°ì¡´ì˜ RAG ë°©ë²•ì€ LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ top-k ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ì§€ë§Œ, ìƒì„± ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ì´ˆê³¼í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ kê°€ ë„ˆë¬´ ì‘ì„ ë•Œ ì¬í˜„ìœ¨ì´ ë‚®ì„ ë•Œ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. 

RankRAG í”„ë ˆì„ì›Œí¬ëŠ” ì»¨í…ìŠ¤íŠ¸ ì¬ìˆœìœ„ ì§€ì •ê³¼ ë‹µë³€ ìƒì„± ëª¨ë‘ë¥¼ ìœ„í•´ ë‹¨ì¼ LLMì„ ëª…ë ¹ì–´ íŠœë‹í•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê³ , ë” í° ê²€ìƒ‰ëœ kì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹ë³„í•˜ê³  ê³ í’ˆì§ˆ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

ë©”ì„œë“œ:
- 1ï¸âƒ£ ì—¬ëŸ¬ ë°ì´í„° ì„¸íŠ¸(ì˜ˆ: Flan, Dolly ë“±)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…ë ¹ì–´ íŠœë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- 2ï¸âƒ£ ì›ë³¸ ì§€ì¹¨ ë°ì´í„°ë¥¼ QA ë°ì´í„°, RAG QA ë°ì´í„°, ì»¨í…ìŠ¤íŠ¸ ìˆœìœ„ ë°ì´í„° ë° RAG ìˆœìœ„ ë°ì´í„°ì™€ ë³‘í•©í•©ë‹ˆë‹¤.
- 3ï¸âƒ£ ì´ëŸ¬í•œ ê²°í•©ëœ íŠ¹ìˆ˜ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì„ ë‹¤ì‹œ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.
- 4ï¸âƒ£ ê°œë°©í˜• QA, ì‚¬ì‹¤ í™•ì¸ ë° ëŒ€í™”í˜• QA ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ í‰ê°€í•©ë‹ˆë‹¤.
- 5ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ì—ëŠ” ë“œë˜ê³¤ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì‚¬ìš©í•˜ê³  ìˆœìœ„ ë° ë‹µë³€ ìƒì„±ì—ëŠ” RankRAGë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

í†µì°°:
- ğŸ”¸ RankRAG 8B ë° 70B ëª¨ë¸ì€ 9ê°œì˜ RAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ GPT-4ë¥¼ ëŠ¥ê°€í•©ë‹ˆë‹¤.
- ğŸ”¸ í‰ê·  ì ìˆ˜: GPT-4 = 43.5, RankRAG 8B = 52.6, RankRAG 70B = 56.1.
- ğŸ”¸ RankRAGëŠ” ChatQA 1.5ì— ë¹„í•´ íŠ¹íˆ ì´ˆê¸° ê²€ìƒ‰ì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ì¸í•´ ê¹Œë‹¤ë¡œìš´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ëˆˆì— ë„ëŠ” ì„±ëŠ¥ í–¥ìƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ğŸ”¸ RankRAGëŠ” 5ê°œì˜ ìƒë¬¼ì˜í•™ RAG ë²¤ì¹˜ë§ˆí¬ì—ì„œ GPT-4ì˜ ì„±ëŠ¥ê³¼ ì¼ì¹˜í•˜ëŠ” ê°•ë ¥í•œ ì¼ë°˜í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
- ğŸ”¸ RankRAGëŠ” ë˜í•œ ë” í° ë°ì´í„° ì„¸íŠ¸ì—ì„œ í›ˆë ¨ëœ íŠ¹ìˆ˜ ìˆœìœ„ ì¬ì§€ì • ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤.
- ğŸ”¸ 1%ì˜ ìˆœìœ„ ë°ì´í„°ë§Œ ì§€ì¹¨ ë°ì´í„°ì™€ í†µí•©í•˜ë©´ ìƒë‹¹í•œ ê°œì„ ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

</details>
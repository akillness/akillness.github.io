---
title: RAG or Fine Tuning? Fine-tune Embedding models for Retrieval Augmented Generation
  (RAG)
description: Finetune, Embedding Model, RAG
categories:
- RAG & Retrieval Systems
- LLM & Language Models
tags:
- finetune
- embedding-model
- rag
date: 2024-06-05 11:00:00 +0800
pin: true
mermaid: true
---
# RAG or Fine Tuning? A simple feature comparision to decide which technique you should use!

For customizing LLMs, in addition to RAG, another optimization technique is fine-tuning.

> **ğ—¥ğ—”ğ—š** is akin to providing a textbook to the model, allowing it to retrieve information based on specific queries. This approach is suitable for scenarios where the model needs to address particular information retrieval tasks. However, RAG is not suitable for teaching the model to understand broad domains or learn new languages, formats, or styles.
{: .prompt-info }

> **ğ—™ğ—¶ğ—»ğ—²-ğ˜ğ˜‚ğ—»ğ—¶ğ—»ğ—´** is similar to enabling students to internalize knowledge through extensive learning. Fine-tuning can enhance the performance of non-fine-tuned models and make interactions more efficient. It is particularly suitable for emphasizing existing knowledge in the base model, modifying or customizing the modelâ€™s output, and providing complex directives to the model. 
{: .prompt-info }

Sometimes it may not seem straightforward to choose one approach or the other, that's why this guide will help you to differentiate which technique fits better your use case!

![ Finetuning or RAG ? ](/assets/img/llm/LLM_fintuning_RAG.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

# RAG in Production: The importance of a Solid Data Strategy ğŸ’¥

Retrieval-Augmented Generation (RAG) has become one of the hottest topics in Generative AI, providing powerful ways to enhance model responses with real-world data. But letâ€™s be honest, without a solid data strategy, youâ€™re setting yourself up for a meme-worthy fail. ğŸ˜‚

ğŸ“ˆ ğ—ªğ—µğ˜† ğ—¥ğ—”ğ—š ğ—¡ğ—²ğ—²ğ—±ğ˜€ ğ—® ğ——ğ—®ğ˜ğ—® ğ—¦ğ˜ğ—¿ğ—®ğ˜ğ—²ğ—´ğ˜†: 

1. ğ——ğ—®ğ˜ğ—® ğ—¤ğ˜‚ğ—®ğ—¹ğ—¶ğ˜ğ˜†: Garbage in, garbage out. Your model is only as good as the data it retrieves.
2. ğ—¥ğ—²ğ—¹ğ—²ğ˜ƒğ—®ğ—»ğ—°ğ—²: Ensure your data is relevant to your use case.
3. ğ—¦ğ—°ğ—®ğ—¹ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†: Manage and scale your data efficiently to keep up with growing demands.

Remember, a well-thought-out data strategy is the backbone of any successful RAG implementation.

ğŸš€ ğ—–ğ—¼ğ—»ğ—°ğ—¹ğ˜‚ğ˜€ğ—¶ğ—¼ğ—»: Donâ€™t let your RAG use case fall flat. Invest in your data strategy and watch your AI soar! ğŸŒŸ

## Fine-Tuning Embedding Models for RAG: Significant Performance Gains

*Retrieve:* How can we improve RAG performance through embedding model fine-tuning? What techniques enable domain-specific optimization?

**Embedding models** are crucial for RAG applications, but general models often fall short of domain-specific tasks. Fine-tuning embedding models can significantly boost retrieval performance, as demonstrated in a comprehensive study using financial RAG applications.

### Performance Improvements

| Metric | Improvement | Impact |
|:-------|:------------|:-------|
| **Overall Performance** | 7.4% to 22.55% boost | â¬†ï¸ Significant |
| **Training Samples** | Only 6.3k samples needed | â¬‡ï¸ Efficient |
| **Training Time** | ~5 minutes on consumer GPUs | âš¡ Fast |
| **Model Size** | 6x smaller with Matryoshka | â¬‡ï¸ Efficient |
| **Dimension Efficiency** | 128-dim > 768-dim baseline | â¬†ï¸ Better |

### Fine-Tuning Workflow

```mermaid
graph TB
    A[Base Embedding Model] --> B[Domain Data]
    B --> C[Fine-Tuning Process]
    C --> D[Matryoshka Learning]
    D --> E[Optimized Embeddings]
    
    F[Synthetic Data] --> C
    G[Evaluation] --> C
    H[Sentence Transformers v3] --> C
    
    E --> I[RAG System]
    I --> J[Improved Retrieval]
    
    style A fill:#e1f5ff
    style C fill:#fff3cd
    style E fill:#d4edda
    style J fill:#f8d7da
```

### Key Techniques

#### 1. Matryoshka Representation Learning (MRL)

*Innovate:* MRL enables variable-dimension embeddings that maintain performance at smaller sizes.

```python
from sentence_transformers import SentenceTransformer, losses
from sentence_transformers.training_args import BatchSamplers

# Initialize model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Matryoshka loss enables variable dimensions
train_loss = losses.MultipleNegativesRankingLoss(model)

# Training with Matryoshka
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    output_path='./fine-tuned-embedding-model'
)

# Use different dimensions
embeddings_128 = model.encode(texts, output_value='sentence_embedding', 
                              convert_to_numpy=True)[:, :128]
embeddings_256 = model.encode(texts, output_value='sentence_embedding',
                              convert_to_numpy=True)[:, :256]
```

**Benefits**:
- ğŸª† 99% performance at 6x smaller size
- ğŸ“ˆ 128-dim model outperforms 768-dim baseline by 6.51%
- ğŸ’¾ Reduced storage and compute requirements

#### 2. Synthetic Data Generation

*Retrieve:* Generate training data automatically for fine-tuning:

```python
from sentence_transformers import InputExample
import random

def generate_synthetic_pairs(base_texts, num_pairs=1000):
    """Generate synthetic query-document pairs"""
    pairs = []
    for _ in range(num_pairs):
        # Create variations
        query = create_query_variation(random.choice(base_texts))
        document = find_relevant_document(query, base_texts)
        pairs.append(InputExample(texts=[query, document], label=1.0))
    return pairs

# Use synthetic data for fine-tuning
synthetic_pairs = generate_synthetic_pairs(financial_documents, num_pairs=6300)
```

#### 3. Baseline Creation & Evaluation

**During Training**:
- âœ… Continuous evaluation
- âœ… Performance tracking
- âœ… Early stopping
- âœ… Best model selection

### Implementation Example

```python
from sentence_transformers import SentenceTransformer, losses, evaluation
from sentence_transformers.datasets import NoDuplicatesDataLoader

# Load base model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Prepare training data
train_examples = [
    InputExample(texts=["Query about revenue", "Document about financial revenue"]),
    # ... more examples
]

train_dataloader = NoDuplicatesDataLoader(train_examples, batch_size=16)
train_loss = losses.MultipleNegativesRankingLoss(model)

# Evaluation during training
evaluator = evaluation.InformationRetrievalEvaluator(
    queries=test_queries,
    corpus=test_corpus,
    relevant_docs=test_relevant_docs
)

# Fine-tune
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=3,
    warmup_steps=100,
    evaluator=evaluator,
    evaluation_steps=500,
    output_path='./financial-embedding-model'
)
```

### Results Summary

| Dimension | Performance | vs. Baseline | Storage |
|:----------|:------------|:-------------|:--------|
| **128-dim** | 6.51% better | Outperforms 768-dim | 6x smaller |
| **256-dim** | Near-optimal | 99% of full performance | 3x smaller |
| **512-dim** | Optimal | Full performance | 1.5x smaller |
| **768-dim** | Baseline | Reference | Full size |

### Use Case: Financial RAG

**Dataset**: NVIDIA's 2023 SEC Filing dataset

**Results**:
- ğŸš€ 7.4% to 22.55% performance improvement
- â±ï¸ Fast training (5 minutes on consumer GPUs)
- ğŸ§¬ Synthetic data generation
- ğŸª† Matryoshka efficiency

### Resources

**ğŸ‘‰ Original Article**: <https://www.philschmid.de/fine-tune-embedding-model-for-rag>

**ğŸ‘‰ Code Repository**: <https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/fine-tune-embedding-model-for-rag.ipynb>

**ğŸ‘‰ Hugging Face RAG Documentation**: <https://huggingface.co/docs/transformers/model_doc/rag>
{: .prompt-info}

### Key Takeaways

*Retrieve:* Fine-tuning embedding models with domain-specific data can boost RAG performance by 7-22%, even with small datasets (6.3k samples).

*Innovate:* Techniques like Matryoshka Representation Learning enable efficient embeddings that maintain performance at smaller sizes, reducing computational requirements while improving results.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about improving RAG performance, retrieve knowledge about embedding fine-tuning techniques, and innovate by applying these methods to your specific domain.

**Next Steps**:
- Explore the implementation code
- Fine-tune embeddings for your domain
- Experiment with Matryoshka learning
- Measure performance improvements


# How to Select an Embedding Model for Your RAG Application?

Embeddings form the foundation for achieving precise and contextually relevant LLM outputs across different tasks.

Which encoder you select to generate embeddings is a critical decision, hugely impacting the overall success of the RAG system. Low quality embeddings lead to poor retrieval.

When selecting an embedding model, consider the vector dimension, average retrieval performance, and model size.

Companies such as OpenAI, Cohere, and Voyage consistently release enhanced embedding models.

Different types of embeddings are designed to address unique challenges and requirements in different domains.

![ Types of Embedding Models For RAG ](/assets/img/llm/Types-Embedding-Models-for-RAG.jpeg){: .light .shadow .rounded-10 w='1212' h='668' }

### â®• Dense embeddings are continuous, real-valued vectors that represent information in a high-dimensional space. 

*Curiosity:* In the context of RAG applications, dense embeddings, such as those generated by models like OpenAIâ€™s Ada or sentence transformers, contain non-zero values for every element.



### â®• Sparse embeddings, on the other hand, are representations where most values are zero, emphasizing only relevant information. 
In RAG applications, sparse vectors are essential for scenarios with many rare keywords or specialized terms. 

### â®• Multi-vector embedding models like ColBERT feature late interaction, where the interaction between query and document representations occurs late in the process, after both have been independently encoded. 

### â®• Long documents have always posed a particular challenge for embedding models. 
The limitation on maximum sequence lengths, often rooted in architectures like BERT, leads to practitioners segmenting documents into smaller chunks. Unfortunately, this segmentation can result in fragmented semantic meanings and misrepresentation of entire paragraphs. 

### â®• Variable dimension embeddings are a unique concept built on Matryoshka Representation Learning (MRL).
 MRL learns lower-dimensional embeddings that are nested into the original embedding, akin to a series of Matryoshka Dolls. 

### â®• Code embeddings are a recent development used to integrate AI-powered capabilities into Integrated Development Environments (IDEs), fundamentally transforming how developers interact with codebases. 

*Curiosity:* What insights can we retrieve from this? How does this connect to innovation in the field?

There are several factors that need to be considered while selecting an embedding model.

> Know more about embeddings and models in this article: <https://www.rungalileo.io/blog/mastering-rag-how-to-select-an-embedding-model>
{: .prompt-info}


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

## RAG ë˜ëŠ” ë¯¸ì„¸ ì¡°ì •? ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ ê²°ì •í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ ê¸°ëŠ¥ ë¹„êµ!

LLMì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê¸° ìœ„í•´ RAG ì™¸ì—ë„ ë˜ ë‹¤ë¥¸ ìµœì í™” ê¸°ìˆ ì´ ë¯¸ì„¸ ì¡°ì •ì…ë‹ˆë‹¤.

> **RAGëŠ”** ëª¨ë¸ì— êµê³¼ì„œë¥¼ ì œê³µí•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬í•˜ì—¬ íŠ¹ì • ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ëª¨ë¸ì´ íŠ¹ì • ì •ë³´ ê²€ìƒ‰ ì‘ì—…ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ RAGëŠ” ëª¨ë¸ì´ ê´‘ë²”ìœ„í•œ ë„ë©”ì¸ì„ ì´í•´í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì–¸ì–´, í˜•ì‹ ë˜ëŠ” ìŠ¤íƒ€ì¼ì„ í•™ìŠµí•˜ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë°ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
{: .prompt-info }

> **ë¯¸ì„¸ ì¡°ì •ì€** í•™ìƒë“¤ì´ ê´‘ë²”ìœ„í•œ í•™ìŠµì„ í†µí•´ ì§€ì‹ì„ ë‚´ë©´í™”í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ë¯¸ì„¸ ì¡°ì •ì€ ë¯¸ì„¸ ì¡°ì •ë˜ì§€ ì•Šì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ìƒí˜¸ ì‘ìš©ì„ ë³´ë‹¤ íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì˜ ê¸°ì¡´ ì§€ì‹ì„ ê°•ì¡°í•˜ê³ , ëª¨ë¸ì˜ ì¶œë ¥ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì‚¬ìš©ì ì§€ì •í•˜ê³ , ëª¨ë¸ì— ë³µì¡í•œ ì§€ì‹œë¬¸ì„ ì œê³µí•˜ëŠ” ë° íŠ¹íˆ ì í•©í•©ë‹ˆë‹¤. 
{: .prompt-info }

ë•Œë¡œëŠ” í•œ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ ë˜ëŠ” ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ê°„ë‹¨í•˜ì§€ ì•Šì€ ê²ƒì²˜ëŸ¼ ë³´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ ê°€ì´ë“œëŠ” ì‚¬ìš© ì‚¬ë¡€ì— ë” ì í•©í•œ ê¸°ìˆ ì„ êµ¬ë³„í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤!

## ìƒì‚° í˜„ì¥ì—ì„œì˜ RAG: ê²¬ê³ í•œ ë°ì´í„° ì „ëµğŸ’¥ì˜ ì¤‘ìš”ì„±

RAG(Retrieval-Augmented Generation)ëŠ” ì œë„ˆë ˆì´í‹°ë¸Œ AIì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì£¼ì œ ì¤‘ í•˜ë‚˜ê°€ ë˜ì—ˆìœ¼ë©°, ì‹¤ì œ ë°ì´í„°ë¡œ ëª¨ë¸ ì‘ë‹µì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì†”ì§íˆ ë§í•´ì„œ ê²¬ê³ í•œ ë°ì´í„° ì „ëµì´ ì—†ìœ¼ë©´ ë°ˆì— ì–´ìš¸ë¦¬ëŠ” ì‹¤íŒ¨ë¥¼ ë§ì´í•˜ê²Œ ë©ë‹ˆë‹¤. ğŸ˜‚

ğŸ“ˆ RAGì— ë°ì´í„° ì „ëµì´ í•„ìš”í•œ ì´ìœ :

1. ë°ì´í„° í’ˆì§ˆ: ì“°ë ˆê¸° ìœ ì…, ì“°ë ˆê¸° ë°°ì¶œ. ëª¨ë¸ì€ ê²€ìƒ‰í•˜ëŠ” ë°ì´í„°ë§Œí¼ë§Œ ìš°ìˆ˜í•©ë‹ˆë‹¤.
2. ê´€ë ¨ì„±: ë°ì´í„°ê°€ ì‚¬ìš© ì‚¬ë¡€ì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
3. í™•ì¥ì„±: ì¦ê°€í•˜ëŠ” ìˆ˜ìš”ë¥¼ ë”°ë¼ì¡ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  í™•ì¥í•©ë‹ˆë‹¤.

ì‹ ì¤‘í•œ ë°ì´í„° ì „ëµì€ ì„±ê³µì ì¸ RAG êµ¬í˜„ì˜ ì¤‘ì¶”ë¼ëŠ” ì ì„ ê¸°ì–µí•˜ì‹­ì‹œì˜¤.

ğŸš€ ê²°ë¡ : RAG ì‚¬ìš© ì‚¬ë¡€ê°€ ì‹¤íŒ¨í•˜ì§€ ì•Šë„ë¡ í•˜ì‹­ì‹œì˜¤. ë°ì´í„° ì „ëµì— íˆ¬ìí•˜ê³  AIê°€ ê¸‰ì¦í•˜ëŠ” ê²ƒì„ ì§€ì¼œë³´ì‹­ì‹œì˜¤! ğŸŒŸ

##  ë¯¸ì„¸ ì¡°ì •ì€ ê²€ìƒ‰ ì†ë„ë¥¼ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‘€

ì„ë² ë”© ëª¨ë¸ì€ RAG(Retrieval-Augmented Generation) ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë§¤ìš° ì¤‘ìš”í•˜ì§€ë§Œ ì¼ë°˜ ëª¨ë¸ì€ ë„ë©”ì¸ë³„ ì‘ì—…ì— ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. 

Matryoshka Representation Learningê³¼ ê°™ì€ ìµœì‹  ì—°êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ NVIDIAì˜ 2023 SEC Filing ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸ˆìœµ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ìš© ì„ë² ë”© ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ë¥¼ ê³µìœ í•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.

- ğŸš€ ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ë‹¨ 6.3k ìƒ˜í”Œë¡œ 7.4%ì—ì„œ 22.55%ê¹Œì§€ ì„±ëŠ¥ í–¥ìƒ
- âœ… ê¸°ì¤€ ìƒì„± + í•™ìŠµ ì¤‘ í‰ê°€
- ğŸ§¬ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©ë˜ëŠ” ìƒì„±ëœ í•©ì„± ë°ì´í„°
- â±ï¸ ~10,000ì— ëŒ€í•œ êµìœ¡, ì†Œë¹„ììš© GPUì—ì„œ ë‹¨ 5ë¶„
- ğŸª† MatryoshkaëŠ” 6ë°° ë” ì‘ì€ í¬ê¸°ë¡œ 99%ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- ğŸ“ˆ ë¯¸ì„¸ ì¡°ì •ëœ 128-dim ëª¨ë¸ì€ ê¸°ì¤€ 768-dimë³´ë‹¤ 6.51% ë” ìš°ìˆ˜í•©ë‹ˆë‹¤.
- ğŸ†• ìƒˆë¡œìš´ ë¬¸ì¥ ë³€í™˜ê¸° v3 ì‚¬ìš©

ë¹Œë“œí•˜ëŸ¬ ê°€ì„¸ìš”! ğŸ¤—

</details>
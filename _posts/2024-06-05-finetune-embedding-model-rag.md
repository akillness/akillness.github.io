---
title: Fine-tune Embedding models for Retrieval Augmented Generation (RAG)
description: NVIDIA, Embedding Model, RAG
categories: [Script, RAG]
tags: [NVIDIA, Embedding Model, RAG]
# author: foDev_jeong
date: 2024-06-05 11:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

## Fine-tuning can significantly boost retrieval. ğŸ‘€

Embedding models are crucial for Retrieval-Augmented Generation (RAG) applications, but general models often fall short of domain-specific tasks. 

Excited to share a new blog on how to fine-tune embedding models for financial RAG applications using NVIDIA's 2023 SEC Filing dataset using latest research, like Matryoshka Representation Learning:

- ğŸš€ Fine-tuning boosts performance between 7.4% to 22.55% with just 6.3k samples
- âœ… Baseline creation + evaluation during training
- ğŸ§¬ Synthetic data generated used for fine-tuning
- â±ï¸ Training on ~10,000 only 5 minutes on consumer-grade GPUs
- ğŸª† Matryoshka keeps 99% performance at 6x smaller size
- ğŸ“ˆ Fine-tuned 128-dim model outperforms baseline 768-dim by 6.51%
- ğŸ†• Uses the new Sentence Transformers v3


ğŸ‘‰ Original Article : <https://www.philschmid.de/fine-tune-embedding-model-for-rag>

ğŸ‘‰ Code : <https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/fine-tune-embedding-model-for-rag.ipynb>

Go build! ğŸ¤—

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

##  ë¯¸ì„¸ ì¡°ì •ì€ ê²€ìƒ‰ ì†ë„ë¥¼ í¬ê²Œ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‘€

ì„ë² ë”© ëª¨ë¸ì€ RAG(Retrieval-Augmented Generation) ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë§¤ìš° ì¤‘ìš”í•˜ì§€ë§Œ ì¼ë°˜ ëª¨ë¸ì€ ë„ë©”ì¸ë³„ ì‘ì—…ì— ë¯¸ì¹˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. 

Matryoshka Representation Learningê³¼ ê°™ì€ ìµœì‹  ì—°êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ NVIDIAì˜ 2023 SEC Filing ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸ˆìœµ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ìš© ì„ë² ë”© ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ë¥¼ ê³µìœ í•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.

- ğŸš€ ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ ë‹¨ 6.3k ìƒ˜í”Œë¡œ 7.4%ì—ì„œ 22.55%ê¹Œì§€ ì„±ëŠ¥ í–¥ìƒ
- âœ… ê¸°ì¤€ ìƒì„± + í•™ìŠµ ì¤‘ í‰ê°€
- ğŸ§¬ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©ë˜ëŠ” ìƒì„±ëœ í•©ì„± ë°ì´í„°
- â±ï¸ ~10,000ì— ëŒ€í•œ êµìœ¡, ì†Œë¹„ììš© GPUì—ì„œ ë‹¨ 5ë¶„
- ğŸª† MatryoshkaëŠ” 6ë°° ë” ì‘ì€ í¬ê¸°ë¡œ 99%ì˜ ì„±ëŠ¥ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- ğŸ“ˆ ë¯¸ì„¸ ì¡°ì •ëœ 128-dim ëª¨ë¸ì€ ê¸°ì¤€ 768-dimë³´ë‹¤ 6.51% ë” ìš°ìˆ˜í•©ë‹ˆë‹¤.
- ğŸ†• ìƒˆë¡œìš´ ë¬¸ì¥ ë³€í™˜ê¸° v3 ì‚¬ìš©

ë¹Œë“œí•˜ëŸ¬ ê°€ì„¸ìš”! ğŸ¤—

</details>
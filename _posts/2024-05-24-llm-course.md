---
title: Large Language Model Course
description: LLM, Course
categories: [LLM, Cookbook]
tags: [Cookbook, LLM]
# author: foDev_jeong
date: 2024-05-24 10:00:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## ğŸ—£ï¸ Large Language Model Course

â­ The LLM Course reached 30k stars on GitHub!

The popularity of this course is pretty amazing to me. To put things into perspective, it has more stars than big projects like vLLM (20k) or Jax (28k). We're not at llama.cpp (58k) or PyTorch (78k) level yet, but it's way bigger than anything I could have imagined.

Thanks everyone for your support. I quietly edit this course from time to time and have plans to add a new section to the LLM Engineer roadmap. I also want to update some older parts of the course that are now 6 months old (a really long time in the LLM world!).

Please let me know in the comments what you would like to see in the course and how I can improve it.

ğŸ“ LLM Course: <https://github.com/mlabonne/llm-course>

### The LLM course is divided into three parts:

- ğŸ§© LLM Fundamentals covers essential knowledge about mathematics, Python, and neural networks.
- ğŸ§‘â€ğŸ”¬ The LLM Scientist focuses on building the best possible LLMs using the latest techniques.
- ğŸ‘· The LLM Engineer focuses on creating LLM-based applications and deploying them.
  

For an interactive version of this course, I created two LLM assistants that will answer questions and test your knowledge in a personalized way:
- ğŸ¤— [HuggingChat Assistant](https://huggingface.co/chat/): Free version using Mixtral-8x7B.
- ğŸ¤– [ChatGPT Assistant](https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1): Requires a premium account.

![ LLM Course ](/assets/img/llm/LLM_course.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## ğŸ—£ï¸ í—ˆê¹… í˜ì´ìŠ¤ì™€ ë§ˆì´í¬ë¡œ ì†Œí”„íŠ¸ì˜ í˜‘ë ¥ ê°•í™”

â­ LLM ì½”ìŠ¤ëŠ” GitHubì—ì„œ ë³„ 30ê°œë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤!

ì´ ì½”ìŠ¤ì˜ ì¸ê¸°ëŠ” ì €ì—ê²Œ ê½¤ ë†€ëìŠµë‹ˆë‹¤. ì›ê·¼ë²•ìœ¼ë¡œ ë§í•˜ìë©´, vLLM(20k) ë˜ëŠ” Jax(28k)ì™€ ê°™ì€ ëŒ€í˜• í”„ë¡œì íŠ¸ë³´ë‹¤ ë” ë§ì€ ë³„ì´ ìˆìŠµë‹ˆë‹¤. ì•„ì§ llama.cpp(58k)ë‚˜ PyTorch(78k) ìˆ˜ì¤€ì€ ì•„ë‹ˆì§€ë§Œ, ì œê°€ ìƒìƒí–ˆë˜ ê²ƒë³´ë‹¤ í›¨ì”¬ í½ë‹ˆë‹¤.

ì—¬ëŸ¬ë¶„ì˜ ì„±ì›ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì €ëŠ” ë•Œë•Œë¡œ ì´ ê°•ì¢Œë¥¼ ì¡°ìš©íˆ í¸ì§‘í•˜ê³  ìˆìœ¼ë©°, LLM ì—”ì§€ë‹ˆì–´ ë¡œë“œë§µì— ìƒˆë¡œìš´ ì„¹ì…˜ì„ ì¶”ê°€í•  ê³„íšì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ì œ 6ê°œì›”ì´ ëœ ê³¼ì •ì˜ ì¼ë¶€ ì˜¤ë˜ëœ ë¶€ë¶„ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤(LLM ì„¸ê³„ì—ì„œëŠ” ì •ë§ ì˜¤ëœ ì‹œê°„ì…ë‹ˆë‹¤!).

ì½”ìŠ¤ì—ì„œ ë³´ê³  ì‹¶ì€ ê²ƒê³¼ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.

ğŸ“ LLM ê³¼ì •: <https://github.com/mlabonne/llm-course>

### LLM ì½”ìŠ¤ëŠ” ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:

- ğŸ§© LLM ê¸°ì´ˆëŠ” ìˆ˜í•™, íŒŒì´ì¬, ì‹ ê²½ë§ì— ê´€í•œ í•„ìˆ˜ ì§€ì‹ì„ ë‹¤ë£¹ë‹ˆë‹¤.
- ğŸ§‘â€ğŸ”¬ LLM ê³¼í•™ìëŠ” ìµœì‹  ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ìµœê³ ì˜ LLMì„ êµ¬ì¶•í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.
- ğŸ‘· LLM ì—”ì§€ë‹ˆì–´ëŠ” LLM ê¸°ë°˜ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ê³  ë°°í¬í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

ì´ ì½”ìŠ¤ì˜ ì¸í„°ë™í‹°ë¸Œ ë²„ì „ì„ ìœ„í•´, ì§ˆë¬¸ì— ë‹µí•˜ê³  ê°œì¸ ë§ì¶¤í˜•ìœ¼ë¡œ ì§€ì‹ì„ í…ŒìŠ¤íŠ¸í•  ë‘ ëª…ì˜ LLM ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤:

- ğŸ¤— [HuggingChat Assistant](https://huggingface.co/chat/): Mixtral-8x7Bë¥¼ ì‚¬ìš©í•˜ëŠ” ë¬´ë£Œ ë²„ì „.
- ğŸ¤– [ChatGPT Assistant](https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1): í”„ë¦¬ë¯¸ì—„ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

</details>
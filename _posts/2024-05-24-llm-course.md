---
title: Large Language Model Course
description: LLM, Course
categories: [LLM, Cookbook]
tags: [Cookbook, LLM]
# author: foDev_jeong
date: 2024-05-24 10:00:00 +0800
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## 🗣️ Large Language Model Course

⭐ The LLM Course reached 30k stars on GitHub!

The popularity of this course is pretty amazing to me. To put things into perspective, it has more stars than big projects like vLLM (20k) or Jax (28k). We're not at llama.cpp (58k) or PyTorch (78k) level yet, but it's way bigger than anything I could have imagined.

Thanks everyone for your support. I quietly edit this course from time to time and have plans to add a new section to the LLM Engineer roadmap. I also want to update some older parts of the course that are now 6 months old (a really long time in the LLM world!).

Please let me know in the comments what you would like to see in the course and how I can improve it.

📝 LLM Course: <https://github.com/mlabonne/llm-course>

### The LLM course is divided into three parts:

- 🧩 LLM Fundamentals covers essential knowledge about mathematics, Python, and neural networks.
- 🧑‍🔬 The LLM Scientist focuses on building the best possible LLMs using the latest techniques.
- 👷 The LLM Engineer focuses on creating LLM-based applications and deploying them.
  

For an interactive version of this course, I created two LLM assistants that will answer questions and test your knowledge in a personalized way:
- 🤗 [HuggingChat Assistant](https://huggingface.co/chat/): Free version using Mixtral-8x7B.
- 🤖 [ChatGPT Assistant](https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1): Requires a premium account.

![ LLM Course ](/assets/img/llm/LLM_course.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## 🗣️ 허깅 페이스와 마이크로 소프트의 협력 강화

⭐ LLM 코스는 GitHub에서 별 30개를 받았습니다!

이 코스의 인기는 저에게 꽤 놀랍습니다. 원근법으로 말하자면, vLLM(20k) 또는 Jax(28k)와 같은 대형 프로젝트보다 더 많은 별이 있습니다. 아직 llama.cpp(58k)나 PyTorch(78k) 수준은 아니지만, 제가 상상했던 것보다 훨씬 큽니다.

여러분의 성원에 감사드립니다. 저는 때때로 이 강좌를 조용히 편집하고 있으며, LLM 엔지니어 로드맵에 새로운 섹션을 추가할 계획을 가지고 있습니다. 또한 이제 6개월이 된 과정의 일부 오래된 부분을 업데이트하고 싶습니다(LLM 세계에서는 정말 오랜 시간입니다!).

코스에서 보고 싶은 것과 개선할 수 있는 방법을 댓글로 알려주세요.

📝 LLM 과정: <https://github.com/mlabonne/llm-course>

### LLM 코스는 세 부분으로 나뉩니다:

- 🧩 LLM 기초는 수학, 파이썬, 신경망에 관한 필수 지식을 다룹니다.
- 🧑‍🔬 LLM 과학자는 최신 기술을 사용하여 최고의 LLM을 구축하는 데 중점을 둡니다.
- 👷 LLM 엔지니어는 LLM 기반 응용 프로그램을 만들고 배포하는 데 중점을 둡니다.

이 코스의 인터랙티브 버전을 위해, 질문에 답하고 개인 맞춤형으로 지식을 테스트할 두 명의 LLM 어시스턴트를 만들었습니다:

- 🤗 [HuggingChat Assistant](https://huggingface.co/chat/): Mixtral-8x7B를 사용하는 무료 버전.
- 🤖 [ChatGPT Assistant](https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1): 프리미엄 계정이 필요합니다.

</details>
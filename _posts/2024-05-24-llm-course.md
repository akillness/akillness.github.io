---
title: Large Language Model Course
description: LLM, Course
categories: [LLM, Cookbook]
tags: [Cookbook, LLM]
# author: foDev_jeong
date: 2024-05-24 10:00:00 +0800
mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/llm/LLM_evaluation_rank.jpeg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Rankings of model performance change drastically depending on which LLM is used as the judge on KILT-NQ]
---


## ğŸ—£ï¸ Large Language Model Course: A Comprehensive Learning Path

*Curiosity:* How can we systematically learn to build and deploy LLM applications? What knowledge should we retrieve to become proficient in this rapidly evolving field?

â­ **The LLM Course reached 30k stars on GitHub!** This milestone reflects the growing demand for structured learning in the LLM space.

The popularity of this course demonstrates the community's hunger for comprehensive, practical LLM education. To put things into perspective, it has more stars than major projects like vLLM (20k) or Jax (28k). While we're not at llama.cpp (58k) or PyTorch (78k) level yet, this achievement shows the impact of well-structured educational content.

### Course Structure Overview

```mermaid
graph TB
    A[LLM Course] --> B[ğŸ§© LLM Fundamentals]
    A --> C[ğŸ§‘â€ğŸ”¬ LLM Scientist]
    A --> D[ğŸ‘· LLM Engineer]
    
    B --> B1[Mathematics]
    B --> B2[Python]
    B --> B3[Neural Networks]
    
    C --> C1[Model Training]
    C --> C2[Fine-tuning]
    C --> C3[Optimization]
    
    D --> D1[Application Development]
    D --> D2[Deployment]
    D --> D3[Production Systems]
    
    style A fill:#e1f5ff
    style B fill:#fff3cd
    style C fill:#d4edda
    style D fill:#f8d7da
```

### Three-Part Learning Path

| Part | Focus | Key Topics | Target Audience |
|:-----|:------|:------------|:----------------|
| **ğŸ§© LLM Fundamentals** | Foundation | Mathematics, Python, Neural Networks | Beginners |
| **ğŸ§‘â€ğŸ”¬ LLM Scientist** | Model Development | Training, Fine-tuning, Latest Techniques | Researchers, ML Engineers |
| **ğŸ‘· LLM Engineer** | Application Building | LLM-based Apps, Deployment, Production | Software Engineers, Developers |

### Part 1: LLM Fundamentals

**Essential Knowledge Areas:**

- **Mathematics**: Linear algebra, calculus, probability, statistics
- **Python**: Programming fundamentals, data structures, libraries
- **Neural Networks**: Architecture, training, optimization

**Learning Resources:**

```python
# Example: Understanding neural network basics
import torch
import torch.nn as nn

class SimpleLLM(nn.Module):
    """Simple LLM architecture for learning"""
    def __init__(self, vocab_size, embed_dim, num_heads):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(embed_dim, num_heads),
            num_layers=6
        )
        self.output = nn.Linear(embed_dim, vocab_size)
    
    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.output(x)

# Initialize model
model = SimpleLLM(vocab_size=10000, embed_dim=512, num_heads=8)
print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
```

### Part 2: LLM Scientist

**Focus Areas:**

- Building the best possible LLMs
- Latest techniques and research
- Model optimization and fine-tuning

**Key Techniques:**

| Technique | Purpose | Application |
|:----------|:--------|:------------|
| **Fine-tuning** | Adapt models to specific tasks | Domain-specific applications |
| **LoRA** | Efficient parameter updates | Resource-constrained environments |
| **Quantization** | Reduce model size | Edge deployment |
| **Distillation** | Transfer knowledge | Smaller, faster models |

### Part 3: LLM Engineer

**Application Development:**

- Creating LLM-based applications
- Deployment strategies
- Production system design

**Deployment Architecture:**

```mermaid
graph LR
    A[User Request] --> B[API Gateway]
    B --> C[LLM Service]
    C --> D[Model Inference]
    D --> E[Response]
    
    F[Vector DB] --> C
    G[Cache] --> C
    H[Monitoring] --> C
    
    style A fill:#e1f5ff
    style C fill:#fff3cd
    style D fill:#d4edda
    style E fill:#f8d7da
```

### Interactive Learning Assistants

The course includes interactive LLM assistants for personalized learning:

| Assistant | Model | Access | Features |
|:----------|:------|:-------|:---------|
| **ğŸ¤— HuggingChat Assistant** | Mixtral-8x7B | Free | Question answering, knowledge testing |
| **ğŸ¤– ChatGPT Assistant** | GPT-4 | Premium | Advanced explanations, code review |
| **â­ LangChain Tutorial** | - | Free | AWS integration, open-source apps |

**Links:**
- HuggingChat: <https://huggingface.co/chat/>
- ChatGPT Assistant: <https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1>
- LangChain Tutorial: <https://www.singlestore.com/blog/how-to-create-open-source-ai-apps-with-langchain/>

### Course Statistics & Impact

| Metric | Value | Comparison |
|:-------|:------|:-----------|
| **GitHub Stars** | 30k+ | More than vLLM (20k), Jax (28k) |
| **Course Parts** | 3 | Fundamentals, Scientist, Engineer |
| **Update Frequency** | Regular | Keeping pace with LLM evolution |

### Learning Path Recommendations

```mermaid
graph TD
    A[Start Here] --> B{Background?}
    B -->|Beginner| C[LLM Fundamentals]
    B -->|ML Experience| D[LLM Scientist]
    B -->|Software Dev| E[LLM Engineer]
    
    C --> F[Practice Projects]
    D --> G[Research Papers]
    E --> H[Build Apps]
    
    F --> I[Advanced Topics]
    G --> I
    H --> I
    
    style A fill:#e1f5ff
    style I fill:#fff3cd
```

### Key Takeaways

*Retrieve:* This comprehensive course provides structured learning across three critical areas: fundamentals, model development, and application engineering.

*Innovate:* By following this path, you can build expertise in LLMs from theory to production, enabling you to create innovative AI applications.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about LLMs, retrieve knowledge through this structured course, and innovate by building real-world applications.

**ğŸ“ Course Link**: <https://github.com/mlabonne/llm-course>

**Next Steps**: 
- Evaluate your current level
- Choose the appropriate starting point
- Engage with the interactive assistants
- Build projects to reinforce learning

![ LLM Course ](/assets/img/llm/LLM_course.jpeg){: .light .w-75 .shadow .rounded-10 w='1212' h='668' }

<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

* * * 

## ğŸ—£ï¸ í—ˆê¹… í˜ì´ìŠ¤ì™€ ë§ˆì´í¬ë¡œ ì†Œí”„íŠ¸ì˜ í˜‘ë ¥ ê°•í™”

â­ LLM ì½”ìŠ¤ëŠ” GitHubì—ì„œ ë³„ 30ê°œë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤!

ì´ ì½”ìŠ¤ì˜ ì¸ê¸°ëŠ” ì €ì—ê²Œ ê½¤ ë†€ëìŠµë‹ˆë‹¤. ì›ê·¼ë²•ìœ¼ë¡œ ë§í•˜ìë©´, vLLM(20k) ë˜ëŠ” Jax(28k)ì™€ ê°™ì€ ëŒ€í˜• í”„ë¡œì íŠ¸ë³´ë‹¤ ë” ë§ì€ ë³„ì´ ìˆìŠµë‹ˆë‹¤. ì•„ì§ llama.cpp(58k)ë‚˜ PyTorch(78k) ìˆ˜ì¤€ì€ ì•„ë‹ˆì§€ë§Œ, ì œê°€ ìƒìƒí–ˆë˜ ê²ƒë³´ë‹¤ í›¨ì”¬ í½ë‹ˆë‹¤.

ì—¬ëŸ¬ë¶„ì˜ ì„±ì›ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ì €ëŠ” ë•Œë•Œë¡œ ì´ ê°•ì¢Œë¥¼ ì¡°ìš©íˆ í¸ì§‘í•˜ê³  ìˆìœ¼ë©°, LLM ì—”ì§€ë‹ˆì–´ ë¡œë“œë§µì— ìƒˆë¡œìš´ ì„¹ì…˜ì„ ì¶”ê°€í•  ê³„íšì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ì œ 6ê°œì›”ì´ ëœ ê³¼ì •ì˜ ì¼ë¶€ ì˜¤ë˜ëœ ë¶€ë¶„ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤(LLM ì„¸ê³„ì—ì„œëŠ” ì •ë§ ì˜¤ëœ ì‹œê°„ì…ë‹ˆë‹¤!).

ì½”ìŠ¤ì—ì„œ ë³´ê³  ì‹¶ì€ ê²ƒê³¼ ê°œì„ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.

ğŸ“ LLM ê³¼ì •: <https://github.com/mlabonne/llm-course>

### LLM ì½”ìŠ¤ëŠ” ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:

- ğŸ§© LLM ê¸°ì´ˆëŠ” ìˆ˜í•™, íŒŒì´ì¬, ì‹ ê²½ë§ì— ê´€í•œ í•„ìˆ˜ ì§€ì‹ì„ ë‹¤ë£¹ë‹ˆë‹¤.
- ğŸ§‘â€ğŸ”¬ LLM ê³¼í•™ìëŠ” ìµœì‹  ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ìµœê³ ì˜ LLMì„ êµ¬ì¶•í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.
- ğŸ‘· LLM ì—”ì§€ë‹ˆì–´ëŠ” LLM ê¸°ë°˜ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ê³  ë°°í¬í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

ì´ ì½”ìŠ¤ì˜ ì¸í„°ë™í‹°ë¸Œ ë²„ì „ì„ ìœ„í•´, ì§ˆë¬¸ì— ë‹µí•˜ê³  ê°œì¸ ë§ì¶¤í˜•ìœ¼ë¡œ ì§€ì‹ì„ í…ŒìŠ¤íŠ¸í•  ë‘ ëª…ì˜ LLM ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤:

- ğŸ¤— [HuggingChat Assistant](https://huggingface.co/chat/): Mixtral-8x7Bë¥¼ ì‚¬ìš©í•˜ëŠ” ë¬´ë£Œ ë²„ì „.
- ğŸ¤– [ChatGPT Assistant](https://chatgpt.com/g/g-yviLuLqvI-llm-course?oai-dm=1): í”„ë¦¬ë¯¸ì—„ ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
- â­[LangChain Tutorial with AWS](https://www.singlestore.com/blog/how-to-create-open-source-ai-apps-with-langchain/?utm_medium=referral&utm_source=pavan&utm_term=lnkdn&utm_content=openlang)

</details>
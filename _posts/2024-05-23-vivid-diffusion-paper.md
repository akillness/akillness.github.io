---
title: ğŸ‘šğŸ‘š ViViD Diffusion Virtual Try-ON ğŸ‘šğŸ‘š
description: Paper, Generative AI, ViViD
categories: [Paper, ViViD]
tags: [Generative AI, ViViD]
# author: foDev_jeong
date: 2024-05-23 19:00:00 +0800
# pin: true
mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

{% include embed/youtube.html id='r9giQPUp1Gw' %}

## ViViD Diffusion: Virtual Try-On with Diffusion Models

*Curiosity:* How can we create realistic virtual try-on videos? What makes ViViD's approach to video virtual try-on (VTON) innovative?

**Alibaba** announces **ViViD**, a novel framework employing powerful diffusion models to tackle the virtual try-on task.

> âš ï¸ **Note**: Code announced, not released yet ğŸ˜¢
{: .prompt-warning}

### Highlights

*Retrieve:* ViViD's key features.

| Feature | Description | Impact |
|:--------|:------------|:-------|
| **Novel Architecture** | Addresses video VTON | â¬†ï¸ Innovation |
| **Diffusion Models** | Synthesizes HQ try-on videos | â¬†ï¸ Quality |
| **Pose + Temporal** | Modules for temporal consistency | â¬†ï¸ Realism |
| **Attention Fusion** | New mechanism for garments | â¬†ï¸ Accuracy |
| **Dataset** | 9,700 pairs of HQ garment-clips | â¬†ï¸ Training data |

### ViViD Architecture

*Innovate:* Framework overview.

```mermaid
graph TB
    A[Input Video] --> B[Pose Module]
    A --> C[Garment Image]
    B --> D[Temporal Module]
    C --> E[Attention Fusion]
    D --> F[Diffusion Model]
    E --> F
    F --> G[HQ Try-On Video]
    
    style A fill:#e1f5ff
    style F fill:#fff3cd
    style G fill:#d4edda
```

### Key Innovations

*Retrieve:* Technical breakthroughs.

**1. Video VTON Architecture**:
- Novel approach to video virtual try-on
- Handles temporal consistency

**2. Diffusion Models**:
- Synthesizes high-quality try-on videos
- Better than previous methods

**3. Pose + Temporal Modules**:
- Ensures temporal consistency
- Maintains realistic motion

**4. Attention Fusion**:
- New mechanism for garment integration
- Better garment-person alignment

**5. Multi-Category Dataset**:
- 9,700 pairs of high-quality garment-clips
- Comprehensive training data

### Resources

*Retrieve:* Available materials.

> **Resources**:
> - **ğŸ“„ Paper**: <https://arxiv.org/pdf/2405.11794>
> - **ğŸŒ Project Page**: <https://becauseimbatman0.github.io/ViViD>
> - **ğŸ’» Code**: Coming soon (<https://github.com/alibaba-yuanjing-aigclab/ViViD>)
> - **ğŸ’¬ Discussion**: <https://t.me/s/AI_DeepLearning>
{: .prompt-info}

**Paper Authors**: Zixun Fang, Wei Zhai, Aimin Su, Hongliang Song, Kai Zhu, Mao Wang, Yu Chen, Zhiheng Liu, Yang Cao, Zheng-Jun Zha (University of Science and Technology of China, Alibaba Group)

### Key Takeaways

*Retrieve:* ViViD is a novel framework using diffusion models for video virtual try-on, with innovations in architecture, temporal consistency, and garment fusion.

*Innovate:* By combining diffusion models with pose and temporal modules, you can create high-quality virtual try-on videos with realistic temporal consistency and accurate garment integration.

*Curiosity â†’ Retrieve â†’ Innovation:* Start with curiosity about virtual try-on, retrieve insights from ViViD's diffusion-based approach, and innovate by applying similar techniques to your video generation projects.

**Next Steps**:
- Read the full paper
- Check project page
- Wait for code release
- Experiment with diffusion VTON


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

## ğŸ‘‰ Alibaba ëŠ” ê°€ìƒ ì²´í—˜ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ê°•ë ¥í•œ í™•ì‚° ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ í”„ë ˆì„ì›Œí¬ì¸ ViViDë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. 

ì½”ë“œ ë°œí‘œ, ì•„ì§ğŸ˜¢ ê³µê°œë˜ì§€ ì•ŠìŒ

í•˜ì´ë¼ì´íŠ¸:
- âœ…ë¹„ë””ì˜¤ VTONì„ ë‹¤ë£¨ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜
- âœ…HQ ì‹œì°© ë¹„ë””ì˜¤ë¥¼ í•©ì„±í•˜ê¸° ìœ„í•œ í™•ì‚° ëª¨ë¸
- âœ…ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ„í•œ í¬ì¦ˆ + ì‹œê°„ì  ëª¨ë“ˆ
- âœ…ìƒˆë¡œìš´ ì£¼ëª© ìœ„ì—…. ì˜ë³µì„ ìœ„í•œ ìœµí•© ê¸°ê³„ì¥ì¹˜
- âœ…ë‹¤ì¤‘ ë²”ì£¼ ë°ì´í„° ì„¸íŠ¸: 9,700ì¼¤ë ˆì˜ HQ ì˜ë¥˜ í´ë¦½

</details>
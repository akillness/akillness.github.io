---
title: 👚👚 ViViD Diffusion Virtual Try-ON 👚👚
description: Paper, Generative AI, ViViD
categories: [Paper, ViViD]
tags: [Generative AI, ViViD]
# author: foDev_jeong
date: 2024-05-23 19:00:00 +0800
# pin: true
# mermaid: true
# render_with_liquid: false
# image:
#   path: /assets/img/blog/NLP_Overview.svg
#   lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
#   alt: [Overview of NLP Course]
---

{% include embed/youtube.html id='r9giQPUp1Gw' %}

## 👉Alibaba announces ViViD, a novel framework employing powerful diffusion models to tackle the virtual try-on task. 

 Code announced, not released yet😢

𝐇𝐢𝐠𝐡𝐥𝐢𝐠𝐡𝐭𝐬:
- ✅Novel architecture to address the video VTON
- ✅Diffusion models to synthesize HQ try-on videos
- ✅Pose + temporal modules for temporal consistency
- ✅New attention feats. fusion mechanism for garments
- ✅Multi-category dataset: 9,700 pairs of HQ garment-clips
  
👉Discussion <https://t.me/s/AI_DeepLearning>

> 🧙Paper Authors: Zixun Fang1,2∗ Wei Zhai1† Aimin Su2 Hongliang Song2 Kai Zhu2 Mao Wang2 Yu Chen2† Zhiheng Liu1 Yang Cao1 Zheng-Jun Zha1 1University of Science and Technology of China 2Alibaba Group
- 1️⃣Read the Full Paper here: <https://arxiv.org/pdf/2405.11794>
- 2️⃣Project Page: <https://becauseimbatman0.github.io/ViViD>
- 3️⃣Code: Coming 🔜 (<https://github.com/alibaba-yuanjing-aigclab/ViViD>)
{: .prompt-info }


<details markdown="1">
<summary style= "font-size:24px; line-height:24px; font-weight:bold; cursor:pointer;" > Translate to Korean </summary>

## 👉 Alibaba 는 가상 체험 작업을 처리하기 위해 강력한 확산 모델을 사용하는 새로운 프레임워크인 ViViD를 발표했습니다. 

코드 발표, 아직😢 공개되지 않음

하이라이트:
- ✅비디오 VTON을 다루는 새로운 아키텍처
- ✅HQ 시착 비디오를 합성하기 위한 확산 모델
- ✅시간적 일관성을 위한 포즈 + 시간적 모듈
- ✅새로운 주목 위업. 의복을 위한 융합 기계장치
- ✅다중 범주 데이터 세트: 9,700켤레의 HQ 의류 클립

</details>
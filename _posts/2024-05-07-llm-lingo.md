---
title: LLM 용어 꼭 알아야 할 것들..!
description: pytorch, LLM, ling
categories: [LLM, Lingo]
tags: [study, Simple LLM, Pytorch]
author: foDev_jeong
date: 2024-05-07 19:57:00 +0800
# mermaid: true
# render_with_liquid: false
---

# LLM Lingo: Must-Know Terms ( Created By: Aishwarya Naresh Reganti )

## Part 1 : Baseline

| LLM Lingo Type             | Description          |  |
| :--------------------------| :--------------- | :------  |
| `Foundation Model` | LLM designed to generate and understand human-like text across a wide range of use-cases | | 
| `Transformer` | A popular LLM design known for its attention mechanism and parallel processing abilities | |
| `Prompting` | Providing carefully crafted inputs to an LLM to generate desired outputs | |
| `Context-Length` | Maximum number of input words/tokens an LLM can consider when generating an output | |
| `Few-Shot Learning` | Providing very few examples to an LLM to assist it in performing a specific task. | |
| `Zero-Shot Learning` | Providing only task instructions to the LLM relying solely on its preexisting knowledge | |
| `RAG` | Retrieval-Augmented Generation. Appending retrieved information to improve LLM response | |
| `Knowledge Base(KB)` | Collection of documents from which relevant information is retrieved in RAG | |
| `Vector Database` | Stores vector representations of the KB, aiding the retrieval of relevant information in RAG, | |
| `Fine-Tuning` | Adapting an LLM to a specific task or domain by further training it on task-specific data. | |
| `Instruction Tuning` | Adjusting an LLM's behavior during fine-tuning by providing specific guidelines/directives | |
| `Hallucination` | Tendency of LLMs to sometimes generate incorrect or non-factual information. | |

## Part 2 : Fine Tuning Edition

| LLM Lingo Type             | Description          |  |
| :--------------------------| :--------------- | :------  |
| `In-Context Learning` | Integrating task examples into prompts, enabling LLMs to handle new tasks without fine-tuning. | | 
| `SFT` | Supervised Fine-Tuning. Updating a pre-trained LLM with labeled data to perform a specific task. | |
| `Contrastive Learning` | Fine-tuning method that improves LLM by teaching it to discern data similarity and differences. | |
| `Transfer Learning` | Applying pre-trained knowledge from large datasets to improve LLM performance on smaller, task specific data. | |
| `Reward Modeling ` | Designing objectives to reward LLM outputs during the reinforcement learning process. | |
| `Reinforcement Learning` | Training LLMs through trial and error, with rewards/penalties based on its generated outputs. | |
| `RLHF` | Reinforcement Learning from Human Feedback. Human feedback is used as reward/penalty for LLM. | |
| `PEFT` | Parameter-Efficient Fine-Tuning updates only few parameters of LLMs and is hence both compute and cost efficient. | |
| `Quantization` | Reducing the precision of LLM parameters to save computational resources without sacrificing performance. | |
| `Pruning` | Trimming surplus connections or parameters to make LLMs smaller and faster yet performant. | |
| `LoRA` | Low-Rank Adaption is a PEFT method that inserts a smaller set of new weights to the LLM & trains only those. | |
| `Freeze Tuning` | Fine-tune with most of the LLM's weights frozen, except for some layers, generally, the task specific layers | |
